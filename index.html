<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/Google%E9%9D%A2%E8%AF%95%E5%AE%98%E4%BA%B2%E6%8E%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/Google%E9%9D%A2%E8%AF%95%E5%AE%98%E4%BA%B2%E6%8E%88/" class="post-title-link" itemprop="url">Google面试官亲授</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>.<br>进程里有很多线程，有内存（逻辑内存），指代内存的寻址空间，并不是真正分了4G，本质是给了寻址空间；文件&#x2F;网络句柄，多个进程可以共用<br>线程里是调用栈，主线程调用会入栈，PC是下一个指令，存放在内存中。还有TLS，这里有独立内存空间。<br>进程是容器，线程是运行。</p>
<h2 id="存储层次结构"><a href="#存储层次结构" class="headerlink" title="存储层次结构"></a>存储层次结构</h2><p>硬盘、内存、缓存、寄存器，以此由慢到贵，由便宜到贵</p>
<h2 id="寻址空间"><a href="#寻址空间" class="headerlink" title="寻址空间"></a>寻址空间</h2><p>进程指针取值范围，操作系统32位就是4G，目前大多数是64位的操作系统；64JVM没有指针的概念，可以使用更大的内容，迁移需要重新编译<br>指针——&gt;逻辑内存——&gt;物理内存——&gt;虚拟内存分页（硬盘），保证数据进入物理内容。物理内存的数据取出来放到寄存器。<br>物理内存使用过多就会频繁分页</p>
<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>在不可靠不安全的环境下如何传输数据<br>数据链路层（数据包，奇偶校验正确还是错误）<br>网络层（路由器，IP地址）<br>传输层（可靠传输， TCP&#x2F;UDP）<br>应用层（HTTP）<br>七层协议、五层协议，很可能不是最优的网络方案。<br>在网络发展过程中，都在解决问题，所以在由一层一层叠加的，什么样的情况下提出的。是迭代进化的</p>
<h2 id="网络传输"><a href="#网络传输" class="headerlink" title="网络传输"></a>网络传输</h2><p>不可靠：丢包、重复、出错、乱序<br>不安全：中间人工具、窃取、篡改</p>
<h2 id="TCP解决可靠性问题的方案，滑动窗口"><a href="#TCP解决可靠性问题的方案，滑动窗口" class="headerlink" title="TCP解决可靠性问题的方案，滑动窗口"></a>TCP解决可靠性问题的方案，滑动窗口</h2><p>维持发送方和接收方的缓冲区，各自维护缓冲区来解决不可靠的问题。发一个确认一个，这样很浪费，慢慢改进。<br>滑动窗口的演示，正常情况，丢包情况<br>丢包情况，等ACK，这里有超时重传机制，一定要按顺利ACK</p>
<h2 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h2><p>基于关系代数理论<br>缺点：表结构不直观、实现复杂、速度慢<br>优点：健壮性高、社区庞大</p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>ACID<br>A原子性<br>C一致性<br>I隔离性<br>D持久性</p>
<h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><p>Read uncommitted<br>Read committed<br>Repeatable Read<br>Serializable</p>
<p>for update 加写锁，耗费资源<br>乐观锁：加一个版本保护，记录Timestamp，冲突机会不多的情况下使用</p>
<h2 id="程序设计语言"><a href="#程序设计语言" class="headerlink" title="程序设计语言"></a>程序设计语言</h2><p>类型检查分类<br>编译时：C、C++、Java、Go<br>运行时：Python、Perl、JavaScript<br>运行&#x2F;编译：<br>直接编译为机器代码：C、C++<br>编译为中间代码：Java、C#<br>解释执行：Python、Perl<br>编范范式：<br>面向过程、面向对象、函数式</p>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>boolean、byte、char<br>short、int、long、float、double<br>String、Enumerate、Array<br>Object</p>
<p>32为int的取值范围，主要是看符号位和数值位<br>补码：取反加1，为了便于和数学一致</p>
<h2 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h2><p>符号位|指数部分|基数部分</p>
<p>浮点数比较，有精度问题，差的绝对值看是否小于eps，具体分析<br>用BigDecimal算钱</p>
<h2 id="Java数据类型"><a href="#Java数据类型" class="headerlink" title="Java数据类型"></a>Java数据类型</h2><p>值类型和对象类型<br>装箱和拆箱<br>显示装箱、隐式装箱<br>拆箱</p>
<h2 id="数学归纳法"><a href="#数学归纳法" class="headerlink" title="数学归纳法"></a>数学归纳法</h2><p>用于证明断言对所有自然数成立，这是个公理<br>证明N&#x3D;1成立<br>如果N&gt;1成立，则N成立</p>
<p>递归控制<br>严格定义递归含义的作用，包括参数、返回值、全局状态<br>先一般、后特殊，先写假设和推导，再写特殊情况<br>每次调用必须缩小问题的规模<br>每次问题规模缩小程序必须为1</p>
<p>递归的缺点<br>Stack<br>函数调用开销，Stack Overflow错误</p>
<p>循环控制<br>一般化的方法仍然需要栈，代码会变复杂（入栈出栈的代码），不能根本解决问题</p>
<p>循环不变式，是一句断言定义各变量所满足的条件</p>
<h2 id="边界控制"><a href="#边界控制" class="headerlink" title="边界控制"></a>边界控制</h2><p>主要还是看经验</p>
<p>二分查找有一个隐藏10年的bug</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>树<br>容易理解、难度大、综合性强<br>二叉树的遍历（前序、中序、后续）<br>先遍历树根，<br>然后前序遍历左子树<br>再前序遍历右子树</p>
<h2 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h2><p>Singleton优缺点<br>确保全局至多只有一个对象<br>用于构造缓慢的对象，需要统一管理的资源<br>缺点，很多全局状态、线程安全性<br>双重锁模式&#x2F;使用Java类的静态变量&#x2F;使用框架提供的能力</p>
<p>继承关系，is a关系，不要用继承关系来实现复用，使用设计模式实现代码复用<br>状态模式<br>装饰器模式</p>
<p>创建对象：创建哪个类，参数不明确</p>
<p>抽象工厂模式<br>构建模式</p>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>死锁分析<br>synchronized关键字<br>在任何地方都可以线程切换，甚至在一句语句中心<br>要尽力设想对自己最不利的情况</p>
<p>死锁的四个条件：<br>互斥等待——一般无法破除<br>hold and wait——一次性获取所有资源<br>循环等待——按顺序获取资源<br>无法剥夺的等待——加入超时</p>
<p>线程池的演示</p>
<h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><p>不被引用的对象会被回收<br>垃圾回收包括Minor GC、Full GC<br>垃圾回收时所有运行暂停<br>Java和C++销毁对象</p>
<h2 id="并行计算"><a href="#并行计算" class="headerlink" title="并行计算"></a>并行计算</h2><p>如何排序10G个算法</p>
<p>扩展的归并排序，分左右两半排序后，将两个有序数据归并<br>用堆的数据结构，<br>堆——完全二叉树，根是最小的，PriorityQueue<br>最后还是10G的数据送进去<br>将一部分放进内存里</p>
<h2 id="面向对象思想"><a href="#面向对象思想" class="headerlink" title="面向对象思想"></a>面向对象思想</h2><p>类与对象<br>类的成员变量——对象状态<br>类的成员函数——对象行为<br>类的静态变量、静态函数——全局就一份<br>类的特殊函数<br>构造函数<br>Hashcode和equal 必要非充分的关系</p>
<p>接口<br>从用户角度看问题<br>是模块间协作的合约，无成员变量，没有实现<br>Java Interface关键字<br>C++ 一个全部是纯虚函数的类<br>python：依靠注释来生命</p>
<p>接口和抽象类：<br>从实现角度，抽象类可以有成员变量、部分实现<br>抽象类不可以多重继承，接口可以</p>
<p>为什么设计成这样：<br>从用户角度看问题、强调合约、、强制协作双方无法犯错<br>包装链表类，实现iteratable接口</p>
<p>继承（is-a）与封装<br>类内&#x2F;包内&#x2F;派生&#x2F;外部<br>private<br>默认<br>protected<br>public<br>尽量只是用private、public</p>
<p>不可变对象<br>可以引用传递，可以缓存；线程安全<br>final关键字无法保证不可变性<br>通过final关键字声明，不能被继承、不能重写、不能指向其他对象<br>从接口定义，类的实现上保证不可变性<br>Collections.Unmodified<br>泛型<br>第一层是结构，第二层是类型，从List到List<T><br>Java Type Erasure<br>Covariance<br>基础知识：广度优先、在兴趣点深入</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E4%BA%BF%E7%BA%A7%E6%B5%81%E9%87%8F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E4%BA%BF%E7%BA%A7%E6%B5%81%E9%87%8F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E6%88%98/" class="post-title-link" itemprop="url">亿级流量系统架构设计与实战</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E5%87%A4%E5%87%B0%E6%9E%B6%E6%9E%84/" class="post-title-link" itemprop="url">凤凰架构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>作者：周志华<br>阅读日期：20250611——20250630<br>学习网站：<a target="_blank" rel="noopener" href="https://icyfenix.cn/">https://icyfenix.cn/</a></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p><strong>墨菲定律</strong><br>Anything that can go wrong will go wrong.<br>   如果事情可能出错就总会出错。</p>
</blockquote>
<h2 id="可靠的系统："><a href="#可靠的系统：" class="headerlink" title="可靠的系统："></a>可靠的系统：</h2><p>冯诺伊曼《自复制自动机》，如何用不可靠的不见构建可靠的系统；每一个部件都可以看作一只不死鸟（Phoenix），能够涅槃重生。</p>
<h2 id="架构的演进："><a href="#架构的演进：" class="headerlink" title="架构的演进："></a>架构的演进：</h2><p>大型机（Mainframe）——&gt;原始分布式（Distributed）——&gt;大型单体（Monolithic）——&gt;面向服务（Service-Oriented）——&gt;微服务（Microservices）——&gt;服务网格（Service Mesh）——&gt;无服务（Serverless）</p>
<blockquote>
<p>只要在整体架构设计有恰当的、自动化的错误熔断、服务淘汰和重建的机制，在系统外部来观察，整体上仍然有可能表现出稳定和健壮的服务能力。</p>
</blockquote>
<h2 id="🚣凤凰架构"><a href="#🚣凤凰架构" class="headerlink" title="🚣凤凰架构"></a>🚣凤凰架构</h2><h1 id="探索起步"><a href="#探索起步" class="headerlink" title="探索起步"></a>探索起步</h1><h2 id="章节一览"><a href="#章节一览" class="headerlink" title="章节一览"></a>章节一览</h2><ol>
<li>演进中的架构——介绍服务架构演进史</li>
<li>架构师的视角——架构设计解决方案及标准</li>
<li>分布式的基石——分布式生态的一些列问题的解决方案</li>
<li>不可变基础设施——云原生基础设施不可变性</li>
<li>技术方法论——分布式、微服务、架构相关务虚话题</li>
</ol>
<h1 id="演进中的架构"><a href="#演进中的架构" class="headerlink" title="演进中的架构"></a>演进中的架构</h1><h2 id="原始分布式时代"><a href="#原始分布式时代" class="headerlink" title="原始分布式时代"></a>原始分布式时代</h2><blockquote>
<p><strong>UNIX 的分布式设计哲学</strong><br>保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。</p>
</blockquote>
<p>20世纪70年代末期到80年代初，计算机经历了从大型机为主向微型机为主的蜕变，科研设备转变为娱乐设备。但是当前微型机的处理器、内存都很有限，于是开始寻找多台计算机共同协作支撑系统运行的解决方案。</p>
<p>产生了一系列的中间成果，牵引了后续架构的演化架构：</p>
<ul>
<li>网络运算架构（惠普公司提供）——–远程服务调用雏形</li>
<li>AFS文件系统（卡内基梅隆大学提出）——-分布式文件系统雏形</li>
<li>Kerberos协议（麻省理工学院提出）——–服务认证和访问控制的基础</li>
</ul>
<p>OSF制订”分布式运算环境“（DCE）的分布式技术体系，这次尝试最大的收获就是对 RPC、DFS 等概念的开创，以及得到了一个价值千金的教训：<strong>某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果。</strong></p>
<p>20世纪80年代，摩尔定律发挥作用，算力提升速度惊人，逐步开始转向大型单体。</p>
<p>🖊为突破算力，由大型机开展向原始分布式发展，原始分布式是现代分布式诸多技术的雏形，也给出了重要教训。 后续算力逐渐提升，开展专项大型单体应用</p>
<h2 id="单体系统时代"><a href="#单体系统时代" class="headerlink" title="单体系统时代"></a>单体系统时代</h2><blockquote>
<p><strong>单体架构（Monolithic）</strong><br>“单体”只是表明系统中主要的过程调用都是进程内调用，不会发生进程间通信，仅此而已。</p>
</blockquote>
<p>单体并非”反派角色“，对于小型系统，单体易于开发、测试、部署，是效率最高的一种架构风格。它的不足，必须是基于软件性能需求超过了单机，才有讨论的价值。</p>
<p>单体架构并非意味着不进行拆分，其纵向可以进行分层架构设计，横向也可以按需求进行模块拆分。<strong>其真正的缺陷在于拆分之后的隔离和自治能力伤的欠缺</strong> 。无法隔离，即午发单独停止、更新、升级，可维护性没有优势，程序升级、修改缺陷都往往需要制定专门的停机更新计划。</p>
<p>微服务取代单体系统成为潮流趋势的根本原因：<strong>单体系统很难兼容”Phoenix的特性“</strong>。本质上是一种观念转变”追求尽量不出错”，到正视“出错是必然“。</p>
<p>🖊为了允许程序出错，让其获得隔离、自治等能力，单体应用逐步开始转向分布式架构，最早兴盛的即面向服务架构（SOA）</p>
<h2 id="SOA时代"><a href="#SOA时代" class="headerlink" title="SOA时代"></a>SOA时代</h2><blockquote>
<p><strong>SOA 架构（Service-Oriented Architecture）</strong><br>面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。</p>
</blockquote>
<p>单体系统拆分较有代表性的架构模式：</p>
<ul>
<li><strong>烟囱式架构</strong>：孤岛式信息系统，独立拆分、老死不相往来的架构，不贴近实际需求</li>
<li><strong>微内核架构</strong>：插件式架构，一个核心系统，其它业务系统以插件形式存在，适合桌面及Web应用。各插件不会直接交互是大前提</li>
<li><strong>事件驱动架构</strong>：子系统建立一套事件队列管道，外部消息发给管道，子系统按需消费，消费者高度解耦且能通过管道交互。</li>
</ul>
<p>当演化至事件驱动架构， SOAP 协议诞生，SOA开始登上软件架构舞台🎙。</p>
<p>SOA由Gartner在1994年提出，2006年成立联盟制定标准，微服务的诸多思想、概念都在SOA中可以看到，它更加系统、更加具体：</p>
<ul>
<li>更具体：有标准、有原则、有协议，包括ESB（总线）、SDO（数据访问）、SCA（数据服务）等等</li>
<li>更系统：目标是一揽子解决掉全部问题</li>
</ul>
<p><strong>边缘化的原因</strong>：过于严格的规范定义带来过度的复杂性</p>
<p>🖊SOA终究是阳春白雪，回顾过去，不忘“透明”的初心</p>
<h2 id="微服务时代"><a href="#微服务时代" class="headerlink" title="微服务时代"></a>微服务时代</h2><blockquote>
<p><strong>微服务架构（Microservices）</strong><br>微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。</p>
</blockquote>
<p>2005年由Rodgers博士提出，2014年崛起，Martin Fowler 与 James Lewis给出微服务的概念：<br><strong>微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。</strong></p>
<p>九个核心的业务与技术特征：</p>
<ol>
<li>围绕业务能力建设：团队和产品的结构</li>
<li>分散治理：谁家的孩子谁来管</li>
<li>服务来实现独立自治的组件：服务远程调用提供功能</li>
<li>产品化思维：全生命周期的持续改进、提升</li>
<li>数据去中心化：数据领域分散管理</li>
<li>强终端弱管道：能力集中在终端</li>
<li>容错性设计：可出错也可靠</li>
<li>演进式设计：服务可淘汰</li>
<li>基础设施自动化：CI&#x2F;CD</li>
</ol>
<p><strong>微服务不是 SOA 的变体或衍生品</strong></p>
<ul>
<li>摒弃约定和规定</li>
<li>分布式服务的问题没有统一的解决方案，八仙过海各显神通</li>
</ul>
<p>有什么问题、引什么工具<br>SpringCloud 胶水式的工具集，进一步屏蔽了源自于具体工具、框架的复杂性，降低了在不同工具、框架之间切换的成本</p>
<h2 id="后微服务时代"><a href="#后微服务时代" class="headerlink" title="后微服务时代"></a>后微服务时代</h2><blockquote>
<p><strong>后微服务时代（Cloud Native）</strong><br>从软件层面独力应对微服务架构问题，发展到软、硬一体，合力应对架构问题的时代，此即为“后微服务时代”。</p>
</blockquote>
<p>注册发现、跟踪治理、负载均衡、传输通信这些问题一定需要软件系统来解决吗？<br>可以考虑通过基础设施来解决，被业界广泛认可、普遍采用的通过虚拟化基础设施去解决分布式架构问题的开端，应该要从 2017 年<strong>Kubernetes</strong> 赢得容器战争的胜利开始算起。<br>同一个分布式服务的问题在传统 Spring Cloud 中提供的应用层面的解决方案与在 Kubernetes 中提供的基础设施层面的解决方案：</p>
<table>
<thead>
<tr>
<th></th>
<th>Kubernetes</th>
<th>Spring Cloud</th>
</tr>
</thead>
<tbody><tr>
<td>弹性伸缩</td>
<td>Autoscaling</td>
<td>N&#x2F;A</td>
</tr>
<tr>
<td>服务发现</td>
<td>KubeDNS &#x2F; CoreDNS</td>
<td>Spring Cloud Eureka</td>
</tr>
<tr>
<td>配置中心</td>
<td>ConfigMap &#x2F; Secret</td>
<td>Spring Cloud Config</td>
</tr>
<tr>
<td>服务网关</td>
<td>Ingress Controller</td>
<td>Spring Cloud Zuul</td>
</tr>
<tr>
<td>负载均衡</td>
<td>Load Balancer</td>
<td>Spring Cloud Ribbon</td>
</tr>
<tr>
<td>服务安全</td>
<td>RBAC API</td>
<td>Spring Cloud Security</td>
</tr>
<tr>
<td>跟踪监控</td>
<td>Metrics API &#x2F; Dashboard</td>
<td>Spring Cloud Turbine</td>
</tr>
<tr>
<td>降级熔断</td>
<td>N&#x2F;A</td>
<td>Spring Cloud Hystrix</td>
</tr>
<tr>
<td>基础设施管理粒度粗旷，只能到容器层面，对单个远程服务就很难有效管控。对于这一类的解决方案就是<strong>服务网格</strong>（18年火起来）。具体含义是由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器，相当于那个挎斗，以类似网络安全里中间人攻击的方式进行流量劫持，在应用毫无感知的情况下，悄然接管应用所有对外通信。服务网格最终会取代Spring Cloud全家桶大部分组件的能力。</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>业务、技术完全分离、远程和本地完全透明。</p>
<h2 id="无服务时代"><a href="#无服务时代" class="headerlink" title="无服务时代"></a>无服务时代</h2><blockquote>
<p><strong>无服务架构（Serverless）</strong><br>如果说微服务架构是分布式系统这条路的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。</p>
</blockquote>
<p>2012年提出，以“简单”为主要卖点的，它只涉及两块内容：后端设施（Backend）和函数（Function）。</p>
<ul>
<li><strong>后端设施</strong>：指数据库、消息队列、日志、存储，等等这一类用于支撑业务逻辑运行，但本身无业务含义的技术组件，这些后端设施都运行在云中，无服务中称其为“后端即服务”（Backend as a Service，BaaS）。</li>
<li><strong>函数</strong>：指业务逻辑代码，这里函数的概念与粒度，都已经很接近于程序编码角度的函数了，其区别是无服务中的函数运行在云端，不必考虑算力问题，不必考虑容量规划，无服务中称其为“函数即服务”（Function as a Service，FaaS）。</li>
</ul>
<p>如果说微服务架构是分布式系统这条路当前所能做到的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。</p>
<h1 id="架构师的视角"><a href="#架构师的视角" class="headerlink" title="架构师的视角"></a>架构师的视角</h1><h2 id="访问远程服务"><a href="#访问远程服务" class="headerlink" title="访问远程服务"></a>访问远程服务</h2><p><strong>远程服务</strong>将计算机程序的工作范围从单机扩展到网络，从本地延伸至远程，是构建分布式系统的首要基础</p>
<h3 id="远程服务调用"><a href="#远程服务调用" class="headerlink" title="远程服务调用"></a>远程服务调用</h3><p>Remote Procedure Call，RPC，最开始，就是<strong>为了让计算机能够跟调用本地方法一样去调用远程方法</strong>。</p>
<p>进程间通信（IPC）的常用方法：</p>
<ul>
<li>管道：通过管道在进程间传递少量的字符流或字节流</li>
<li>信号：通知目标进程有事件发生，比如kill</li>
<li>信号量：操作系统的特殊变量</li>
<li>消息队列：用于进程间数据量较多的通信</li>
<li>共享内存：多个进程访问同一块公共的内存空间，效率最高</li>
<li>套接字接口：可用于不同机器之间的进程通信</li>
</ul>
<h4 id="通信的成本"><a href="#通信的成本" class="headerlink" title="通信的成本"></a>通信的成本</h4><p>RPC就是IPC的特例，早期透明的调用形式造成程序员误以为<strong>通信无成本</strong><br>后续提出了这种透明调用形式是方向性错误，RPC不同于IPC，它是一种高层次的特征。<br>20世纪80年代，世界上第一个基于RPC的商业应用Courier。<br><strong>远程服务调用</strong>是指位于互不重合的内存地址空间中的两个程序，在语言层面上，以同步的方式使用带宽有限的信道来传输程序控制信息。</p>
<h4 id="三个基本问题"><a href="#三个基本问题" class="headerlink" title="三个基本问题"></a>三个基本问题</h4><p>RPC协议主要就是解决三个基本问题：</p>
<ul>
<li>如何表示数据：要有序列化协议把数据转化为中立的数据流格式</li>
<li>如何传递数据：应用层协议，Wire Potocol</li>
<li>如何表示方法：有跨语言的统一标准去找方法</li>
</ul>
<h4 id="统一的RPC"><a href="#统一的RPC" class="headerlink" title="统一的RPC"></a>统一的RPC</h4><ul>
<li>CORBA：太罗嗦，写一个对象请求代理大概要 200 行代码，其中大概有 170 行都是纯粹无用的废话</li>
<li>W3C Web Service：采用了 XML 作为远程过程调用的序列化、接口描述、服务发现等所有编码的载体，当时 XML 是计算机工业最新的银弹，只要是定义为 XML 的东西几乎就都被认为是好的，风头一时无两。性能有问题，而且贪婪，有一堆协议<br>简单、普适、高性能这三点，似乎真的难以同时满足</li>
</ul>
<h4 id="分裂的RPC"><a href="#分裂的RPC" class="headerlink" title="分裂的RPC"></a>分裂的RPC</h4><ul>
<li>面向对象：RMI、.NET Remoting、CORBA 和 DCOM</li>
<li>性能：gRPC、Thrift。一是专有序列化器，二是传输协议方面，gRPC 是基于 HTTP&#x2F;2 的，支持多路复用和 Header 压缩，Thrift 则直接基于传输层的 TCP 协议来实现，省去了额外应用层协议的开销</li>
<li>简化：JSON-RPC，牺牲了功能和效率，换来的是协议的简单轻便，接口与格式都更为通用</li>
</ul>
<p>目前逐渐朝着插件化的能力支持，比如Dubbo，传输协议、序列化器都可以调整。</p>
<h3 id="REST设计风格"><a href="#REST设计风格" class="headerlink" title="REST设计风格"></a>REST设计风格</h3><p> <strong>REST 并不是一种远程服务调用协议，也不是一种协议，是一种风格</strong></p>
<h4 id="理解REST"><a href="#理解REST" class="headerlink" title="理解REST"></a>理解REST</h4><p>“REST”（<strong>Re</strong>presentational <strong>S</strong>tate <strong>T</strong>ransfer）实际上是“HTT”（<strong>H</strong>yper<strong>t</strong>ext <strong>T</strong>ransfer）的进一步抽象，两者就如同接口与实现类的关系一般。超文本即能够进行分支判断和差异响应的文本。</p>
<p>一个阅读文章的例子来看REST：</p>
<ul>
<li>资源：这个文章就是资源</li>
<li>表征：文章的格式就是表征</li>
<li>状态：我要看下一篇，对于服务器分为有状态、无状态，主要看它要不要记住现在的</li>
<li>转移：服务器通过某种方式转移状态</li>
</ul>
<p>相关概念名字：</p>
<ul>
<li>统一接口：URL是资源，HTTP协议统一接口，其中基本操作，触发表征状态转移</li>
<li>超文本驱动：任何网站导航行为都是由服务器发出的请求响应信息（超文本）驱动的</li>
<li>自描述信息：消息类型和处置方法，比如互联网媒体类型、UTF-8格式</li>
</ul>
<h4 id="RESTful的系统"><a href="#RESTful的系统" class="headerlink" title="RESTful的系统"></a>RESTful的系统</h4><p>六大设计原则：</p>
<ul>
<li>服务端与客户端分离：前端技术发展</li>
<li>无状态：服务器不要负责维护状态，大多数达不到</li>
<li>可缓存：通讯传递者把部分应用缓存起来</li>
<li>分层系统：客户端一般不需要知道是否直接连接到了最终的服务器，抑或连接到路径上的中间服务器，比如CDN</li>
<li>统一接口：统一接口的方式，系统应能做到每次请求中都包含资源的 ID，所有操作均通过资源 ID 来进行；建议每个资源都应该是自描述的消息；建议通过超文本来驱动应用状态的转移</li>
<li>按需代码：可选原则，将可执行的软件程序从服务器发送到客户端的技术</li>
</ul>
<p>REST 的基本思想是面向资源来抽象问题，它与此前流行的编程思想——面向过程的编程在抽象主体上有本质的差别。在 REST 提出以前，人们设计分布式系统服务的唯一方案就只有 RPC，RPC 是将本地的方法调用思路迁移到远程方法调用上，开发者是围绕着“远程方法”去设计两个系统间交互的，譬如 CORBA、RMI、DCOM，等等。服务的每个方法都是完全独立的，服务使用者必须逐个学习才能正确地使用它们。</p>
<p>REST 提出以资源为主体进行服务设计的风格，能为它带来不少好处：</p>
<ul>
<li>降低服务接口的学习成本：统一接口，全部映射到HTTP</li>
<li>资源天然具有集合与层次结构：资源有层次关系，符合人的直觉</li>
<li>REST绑定于HTTP协议：HTTP 本来就是面向资源而设计的网络协议</li>
</ul>
<p>在互联网中，面向资源来进行网络传输是这三十年来 HTTP 协议精心培养出来的用户习惯，如果开发者能够适应 REST 不太符合人类思维习惯的抽象方式，那 REST 通常能够更好地匹配在 HTTP 基础上构建的互联网，在效率与扩展性方面会有可观的收益。</p>
<h4 id="RMM成熟度"><a href="#RMM成熟度" class="headerlink" title="RMM成熟度"></a>RMM成熟度</h4><p>如何评价服务是否 RESTful，分为0到3级：</p>
<ol start="0">
<li>The Swamp of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Plain_Old_XML">Plain Old XML</a>：完全不 REST。另外，关于 Plain Old XML 这说法，SOAP 表示<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%84%9F%E8%A7%89%E6%9C%89%E8%A2%AB%E5%86%92%E7%8A%AF%E5%88%B0">感觉有被冒犯到</a>。</li>
<li>Resources：开始引入资源的概念。</li>
<li>HTTP Verbs：引入统一接口，映射到 HTTP 协议的方法上。</li>
<li>Hypermedia Controls：超媒体控制在本文里面的说法是“超文本驱动”，在 Fielding 论文里的说法是“Hypertext As The Engine Of Application State，HATEOAS”，其实都是指同一件事情。除了第一个请求是由你在浏览器地址栏输入所驱动之外，其他的请求都应该能够自己描述清楚后续可能发生的状态转移，由超文本自身来驱动。</li>
</ol>
<h4 id="不足与争议"><a href="#不足与争议" class="headerlink" title="不足与争议"></a>不足与争议</h4><ul>
<li>面向过程编程时，为什么要以算法和处理过程为中心，输入数据，输出结果？当然是为了符合计算机世界中主流的交互方式。</li>
<li>面向对象编程时，为什么要将数据和行为统一起来、封装成对象？当然是为了符合现实世界的主流的交互方式。</li>
<li>面向资源编程时，为什么要将数据（资源）作为抽象的主体，把行为看作是统一的接口？当然是为了符合网络世界的主流的交互方式。</li>
</ul>
<h2 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a>事务处理</h2><p>数据库的经典理论：</p>
<ul>
<li><strong>原子性</strong>（<strong>A</strong>tomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。</li>
<li><strong>一致性</strong>（<strong>C</strong>onsistency）：数据都是符合期望的，且相互关联的数据之间不会产生矛盾</li>
<li><strong>隔离性</strong>（<strong>I</strong>solation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。</li>
<li><strong>持久性</strong>（<strong>D</strong>urability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。</li>
</ul>
<p>其实ACID并不正交，A、I、S是手段，C是目的。</p>
<p>内部一致性：同一个数据源<br>外部一致性：多个不同的数据源</p>
<p>外部一致性就很难通过AID解决了，将C从二元转变为多元属性</p>
<h3 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h3><p><strong>本地事务</strong>是指仅操作单一事务资源的、不需要全局事务管理器进行协调的事务。适用于单个服务使用单个数据源的场景。<br>直接依赖于数据源本身的事务能力来工作。</p>
<h4 id="实现原子性和持久性"><a href="#实现原子性和持久性" class="headerlink" title="实现原子性和持久性"></a>实现原子性和持久性</h4><p>Commit Logging方法</p>
<ul>
<li>最大困难：“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观地存在着“正在写”的中间状态。</li>
<li>实现方法：不直接该，而且写到日志里，日志再进行持久化，即Commit Logging”（提交日志）方法</li>
<li>巨大缺陷：真实修改都必须发生在事务提交以后，对提升数据库的性能十分不利。</li>
</ul>
<p>Write-Ahead方法（允许在事务提交之前，提前写入变动数据）<br>将何时写入变动数据，按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。</p>
<ul>
<li>FORCE：提交之后必须同时写入，不强制同时就是NO-FORCE</li>
<li>STEAL：提交前，允许变动数据提前写入，不允许是NO-STEAL</li>
</ul>
<p>Commit Logging允许 NO-FORCE，但不允许 STEAL。<br>Write-Ahead Logging 允许 NO-FORCE，也允许 STEAL。增加了Undo Log，表明修改情况，便于回滚。<br>Undo Log：回滚日志&#x2F; Redo Log：重做日志。</p>
<p>Write-Ahead Logging三阶段操作：</p>
<ul>
<li><strong>分析阶段</strong>：从最后一次检查点扫描，组成集合</li>
<li><strong>重做阶段</strong>：依据分析阶段中产生的待恢复的事务集合来重演历史</li>
<li><strong>回滚阶段</strong>：处理经过分析、重做阶段后剩余的恢复事务集合</li>
</ul>
<h4 id="实现隔离性"><a href="#实现隔离性" class="headerlink" title="实现隔离性"></a>实现隔离性</h4><p>并发下实现串行的数据访问——加锁，具体又有三种锁：</p>
<ul>
<li><strong>写锁</strong>（Write Lock，也叫作排他锁，eXclusive Lock，简写为 X-Lock）：如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。</li>
<li><strong>读锁</strong>（Read Lock，也叫作共享锁，Shared Lock，简写为 S-Lock）：多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。对于持有读锁的事务，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。</li>
<li><strong>范围锁</strong>（Range Lock）：对于某个范围直接加排他锁，在这个范围内的数据不能被写入。如下语句是典型的加范围锁的例子：</li>
</ul>
<p>事物的隔离级别：</p>
<ul>
<li>可串行化：对事务所有读、写的数据全都加上读锁、写锁和范围锁</li>
<li>可重复读：对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，但不再加范围锁。<strong>幻读</strong>：两次读的范围不一样</li>
<li>读已提交：对事务涉及的数据加的写锁会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。<strong>不可重复读</strong>：同一行查两次不一样</li>
<li>读未提交：对事务涉及的数据只加写锁，会一直持续到事务结束，但完全不加读锁。<strong>脏读</strong>：一个事务读取到了另一个事务未提交的数据</li>
</ul>
<p>隔离性的另一种实现方案：无锁优化方案MVCC，对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。具体的规则：</p>
<ul>
<li>插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。</li>
<li>删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。</li>
<li>修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。</li>
</ul>
<p>根据隔离级别来决定到底应该读取哪个版本的数据：</p>
<ul>
<li>隔离级别是<code>可重复读</code>：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。</li>
<li>隔离级别是<code>读已提交</code>：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。</li>
</ul>
<p>另外两个隔离级别都没有必要用到 MVCC，因为<code>读未提交</code>直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。<code>可串行化</code>本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。</p>
<p>MVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）。前面笔者介绍的加锁都属于悲观加锁策略，即认为如果不先做加锁再访问数据，就肯定会出现问题。相对地，乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。</p>
<h3 id="全局事务"><a href="#全局事务" class="headerlink" title="全局事务"></a>全局事务</h3><p><strong>全局事务</strong>：一种适用于单个服务使用多个数据源场景的事务解决方案。<br><strong>分布式事务</strong>：多服务多数据源的事务。</p>
<p>1991年，XA提出，包含全局事务管理器、局部资源管理器，一个用于协调全局事务，一个用于驱动本地事务。</p>
<p>XA并不是Java的技术规范，而且一套语言无关的通用规范。Java是实现是JTA。<br>XA 将事务提交拆分成为两阶段过程：</p>
<ul>
<li>准备阶段：协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。</li>
<li>提交阶段：协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。</li>
</ul>
<p>XA是<strong>两阶段提交协议</strong>，它的成功还有两个前期：</p>
<ul>
<li>网络在提交阶段是可靠的，不会丢消息，不会有错消息</li>
<li>网络分区、机器崩溃导致失联的节点最终能恢复，不会永久失联<br>![[1750745377838.png]]<br>两阶段提交的显著问题：</li>
<li>单点问题：协调者故障，参与者一直等待</li>
<li>性能问题：两次服务调用，三次数据持久化（写Redolog、协调者状态持久化、提交阶段写Commit Record）</li>
<li>一致性风险：网络不稳定、宕机恢复能力</li>
</ul>
<p>为了解决单点问题和准备阶段的性能问题，发展出<strong>三阶段提交</strong>，准备阶段再细分，具体包括：</p>
<ul>
<li>CanCommit阶段：让参与者评估是否有可能顺利完成</li>
<li>PreCommit阶段：开始写重做日志</li>
<li>DoCommit阶段：进行写Commit Record</li>
</ul>
<p>不需要回滚的场景下，三阶段更差，需要回滚的场景下，三阶段更优。另外如果协调者宕机，默认让参与者提交事务。同样也有一致性问题。</p>
<p>![[1750746104506.png]]</p>
<h3 id="共享事务"><a href="#共享事务" class="headerlink" title="共享事务"></a>共享事务</h3><p><strong>共享事务</strong>：多个服务共用同一个数据源。</p>
<p>由于数据库连接的基础是网络连接，它是与 IP 地址和端口号绑定的，字面意义上的“不同服务节点共享数据库连接”很难做到，所以为了实现共享事务，就必须新增一个“交易服务器”的中间角色。转化为了本地事务</p>
<p>伪需求，因为往往都是数据库压力最大，需要拓展。有一种常见的变种形式就是：使用消息队列服务器来代替交易服务器。</p>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><p><strong>分布式事务</strong>：多个服务同时访问多个数据源的事务处理机制</p>
<h4 id="CAP与ACID"><a href="#CAP与ACID" class="headerlink" title="CAP与ACID"></a>CAP与ACID</h4><p>2000年证明了CAP猜想，成为著名的定理，三个特性最多只能满足其中两个：</p>
<ul>
<li><strong>一致性</strong>（<strong>C</strong>onsistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。一致性在分布式研究中是有严肃定义、有多种细分类型的概念，以后讨论分布式共识算法时，我们还会再提到一致性，那种面向副本复制的一致性与这里面向数据库状态的一致性严格来说并不完全等同，具体差别我们将在后续分布式共识算法中再作探讨。</li>
<li><strong>可用性</strong>（<strong>A</strong>vailability）：代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标：可靠性（Reliability）和可维护性（Serviceability）。</li>
<li><strong>分区容忍性</strong>（<strong>P</strong>artition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。</li>
</ul>
<p>不可兼得的影响分析：</p>
<ul>
<li><strong>如果放弃分区容忍性</strong>（CA without P）：节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的。Oracle RAC通过共享此判来避免出现网络分区。</li>
<li><strong>如果放弃可用性</strong>（CP without A）：一旦网络发生分区，节点之间的信息同步时间可以无限制地延长。在现实中，选择放弃可用性的 CP 系统情况一般用于对数据质量要求很高的场合中。HBase也是CP系统。</li>
<li><strong>如果放弃一致性</strong>（AP without C）：目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃；而 A 通常是建设分布式的目的。大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，比如Redis。</li>
</ul>
<p>在 CAP、ACID 中讨论的一致性称为<strong>强一致性</strong>，有时也称为<strong>线性一致性</strong>。牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求<strong>弱一致性</strong>。如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，即<strong>最终一致性</strong>。刚性事务&#x2F;柔性事务。</p>
<h4 id="可靠事件队列"><a href="#可靠事件队列" class="headerlink" title="可靠事件队列"></a>可靠事件队列</h4><p>BASE 分别是基本可用性（<strong>B</strong>asically <strong>A</strong>vailable）、柔性事务（<strong>S</strong>oft State）和最终一致性（<strong>E</strong>ventually Consistent）的缩写。其实就是靠持续重试来保障可靠性，也叫做最大努力交付。</p>
<h4 id="TCC事务"><a href="#TCC事务" class="headerlink" title="TCC事务"></a>TCC事务</h4><p>2007年提出，Try Confirm Cancel<br>可靠消息队列简单、相对可靠，但是没有任何隔离性。<br>使用场景：如果业务需要隔离，那架构师通常就应该重点考虑 TCC 方案，该方案天生适合用于需要强隔离性的分布式事务中。<br>整体分为三个阶段：</p>
<ul>
<li><strong>Try</strong>：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），并且预留好全部需用到的业务资源（保障隔离性）。</li>
<li><strong>Confirm</strong>：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。</li>
<li><strong>Cancel</strong>：取消执行阶段，释放 Try 阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。</li>
</ul>
<p>TCC 其实有点类似 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面，这为它的实现带来了较高的灵活性，可以根据需要设计资源锁定的粒度。TCC 在业务执行时只操作预留资源，几乎不会涉及锁和资源的争用，具有很高的性能潜力。<br>业务侵入性强，一般通过分布式事务中间件来完成。</p>
<h4 id="SAGA事务"><a href="#SAGA事务" class="headerlink" title="SAGA事务"></a>SAGA事务</h4><p>1987年提出，把一个大事务分解为可以交错运行的一系列子事务集合。<br>目的：避免大事务长时间锁定数据库的资源，后来才发展成将一个分布式环境中的大事务分解为一系列本地事务的设计模式。SAGA 由两部分操作组成。</p>
<ul>
<li>大事务拆分若干个小事务，将整个分布式事务 T 分解为 n 个子事务，命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该是或者能被视为是原子行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。</li>
<li>为每一个子事务设计对应的补偿动作，命名为 C1，C2，…，Ci，…，Cn。Ti与 Ci必须满足以下条件：<ul>
<li>Ti与 Ci都具备幂等性。</li>
<li>Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。</li>
<li>Ci必须能成功提交，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须持续重试直至成功，或者要人工介入。</li>
</ul>
</li>
</ul>
<p>两种恢复策略：</p>
<ul>
<li><p><strong>正向恢复</strong>（Forward Recovery）：如果 Ti事务提交失败，则一直对 Ti进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。</p>
</li>
<li><p><strong>反向恢复</strong>（Backward Recovery）：如果 Ti事务提交失败，则一直执行 Ci对 Ti进行补偿，直至成功为止（最大努力交付）。这里要求 Ci必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。</p>
<ol>
<li>Saga不需要为资源设计冻结状态。</li>
<li>必须保证所有子事务都得以提交或者补偿</li>
</ol>
</li>
</ul>
<p>还有AT事务，也是基于数据补偿来代替回滚的思路</p>
<h2 id="透明多级分流系统"><a href="#透明多级分流系统" class="headerlink" title="透明多级分流系统"></a>透明多级分流系统</h2><p>对系统进行流量规划时，有两条普适、简单的原则指导设计：</p>
<ul>
<li>尽可能减少单点部件</li>
<li>奥卡姆剃须刀原则，满足需求的情况下，最简单的系统就是最好的系统</li>
</ul>
<h3 id="客户端缓存"><a href="#客户端缓存" class="headerlink" title="客户端缓存"></a>客户端缓存</h3><blockquote>
<p><strong>客户端缓存（Client Cache）</strong><br>HTTP 协议的无状态性决定了它必须依靠客户端缓存来解决网络传输效率上的缺陷。</p>
</blockquote>
<p>HTTP设计之初无状态，但是每次都要携带重复数据，网络性能会降低。针对这个问题引入客户端缓存，逐步形成了“状态缓存“”强制缓存“”协商缓存“的机制。</p>
<h4 id="强制缓存"><a href="#强制缓存" class="headerlink" title="强制缓存"></a>强制缓存</h4><p>强制缓存：假设在某个时点到来以前，譬如收到响应后的 10 分钟内，资源的内容和状态一定不会被改变，因此客户端可以无须经过任何请求，在该时点前一直持有和使用该资源的本地缓存副本。<br>两类实现：</p>
<ul>
<li>Expires： HTTP&#x2F;1.0 协议中开始提供的 Header，后面跟随一个截至时间参数。存在问题<ol>
<li>受限于客户端本地时间，客户端修改本地时间</li>
<li>无法处理涉及到用户身份的私有资源，被其它代理服务器缓存</li>
<li>无法描述不缓存的语义</li>
</ol>
</li>
<li>Cache-Control：HTTP&#x2F;1.1 协议中定义的强制缓存 Header，两个同时存在，以它为准</li>
</ul>
<h4 id="协商缓存"><a href="#协商缓存" class="headerlink" title="协商缓存"></a>协商缓存</h4><p>协商缓存：基于变化检测的缓存机制，在一致性上会有比强制缓存更好的表现，但需要一次变化检测的交互开销，性能上就会略差一些。两种变动检查机制，分别是根据资源的修改时间进行检查，以及根据资源唯一标识是否发生变化来进行检查，它们都是靠一组成对出现的请求、响应 Header 来实现的：</p>
<ul>
<li><strong>Last-Modified 和 If-Modified-Since</strong>：Last-Modified 是服务器的响应 Header，用于告诉客户端这个资源的最后修改时间。对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-Modified-Since 把之前收到的资源最后修改时间发送回服务端。</li>
<li><strong>Etag 和 If-None-Match</strong>：Etag 是服务器的响应 Header，用于告诉客户端这个资源的唯一标识。对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-None-Match 把之前收到的资源唯一标识发送回服务端。</li>
</ul>
<p>Etag 是 HTTP 中一致性最强的缓存机制，却又是 HTTP 中性能最差的缓存机制</p>
<p>对于多类资源，HTTP 协议设计了以 Accept*开头的一套请求 Header 和对应的以 Content-*开头的响应 Header，这些 Headers 被称为 HTTP 的内容协商机制。</p>
<h3 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h3><p>DNS的解析步骤：</p>
<ol>
<li>客户端先检查本地DNS缓存，DNS会有TTL检查有效情况。</li>
<li>客户端把地址发给本地DNS，可以手工配置，也可以DHCP分配</li>
<li>本地DNS收到请求后，依次查询地址记录<ul>
<li><strong>权威域名服务器</strong>：负责翻译特定域名的 DNS 服务器</li>
<li><strong>根域名服务器</strong>：固定的、无需查询的顶级域名服务器</li>
</ul>
</li>
<li>不存在任何权威域名服务器，找到根，根再到权威服务器</li>
<li>通过权威服务器找域名的地址记录，不一定是IP，有十多种</li>
</ol>
<p>可以根据地区、服务商等因素确定返回记录，找到最合适的数据中心</p>
<ul>
<li>性能问题：DNS预取，如果有使用需求就预解释</li>
<li>劫持问题：HTTPDCN，基于HTTPS的查询服务器，绕过传统DNS</li>
</ul>
<h3 id="传输链路"><a href="#传输链路" class="headerlink" title="传输链路"></a>传输链路</h3><p>程序发出的请求能否与应用层、传输层协议提倡的方式相匹配，对传输的效率也会有极大影响。</p>
<h4 id="连接数优化"><a href="#连接数优化" class="headerlink" title="连接数优化"></a>连接数优化</h4><p>HTTP over TCP 这种搭配未必合适，TCP有三次握手还有慢启动，建立链接时速度最低，后面才稳定，在长时间的尺度下，连接才不是瓶颈。<br>因此开展减少请求数量、增加连接数量去优化。</p>
<p>节省TCP连接也有很多副作用，比如传输容量膨胀、大图片等问题。因此衍生连接复用技术，即“keep alive机制”</p>
<p><strong>持久连接</strong>：让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接。在客户端维护一个 FIFO 队列，每次取完数据之后一段时间内不自动断开连接，以便获取下一个资源时直接复用，避免创建 TCP 连接的成本。</p>
<p>这样又会有阻塞等待问题，2014年又提出了“HTTP管道”复用技术，让客户端一次将所有要请求的资源名单全部发给服务端，由服务端来安排返回顺序，管理传输队列。服务端能够较为准确地评估资源消耗情况，进而能够更紧凑地安排资源传输，保证队列中两项工作之间尽量减少空隙，甚至做到并行化传输，从而提升链路传输的效率。<br>协调复杂，推广不太成功。</p>
<p>HTTP&#x2F;2解决，用帧来作为信息单位，HTTP&#x2F;2多路复用技术。</p>
<h4 id="传输压缩"><a href="#传输压缩" class="headerlink" title="传输压缩"></a>传输压缩</h4><p>HTTP支持gzip，最开始是静态预压缩，看客户端的接受情况返回，后来是即时压缩，不等资源压缩完成。<br>持久链接和即时压缩只能二选其一<br>HTTP&#x2F;1.1增加分块传输编码的资源结束判断机制，彻底解决了 Content-Length 与持久链接的冲突问题。</p>
<h4 id="快速UDP网络连接"><a href="#快速UDP网络连接" class="headerlink" title="快速UDP网络连接"></a>快速UDP网络连接</h4><p>HTTP&#x2F;3 设计重点： HTTP over UDP，叫做QUIC：其不仅能满足 HTTP 传输协议，日后还能支持 SMTP、DNS、SSH、Telnet、NTP 等多种其他上层协议。</p>
<ul>
<li>QUIC可靠性完全由自己来实现，能对每个流能做单独的控制，如果在一个流中发生错误，协议栈仍然可以独立地继续为其他流提供服务。</li>
<li>QUIC 提出了连接标识符的概念，该标识符可以唯一地标识客户端与服务器之间的连接，而无须依靠 IP 地址。这样，切换网络后，只需向服务端发送一个包含此标识符的数据包即可重用既有的连接，因为即使用户的 IP 地址发生变化，原始连接连接标识符依然是有效的。</li>
</ul>
<p>Google 在 Chromium 的网络协议栈中同时启用了 QUIC 和传统 TCP 连接，并在 QUIC 连接失败时以零延迟回退到 TCP 连接，尽可能让用户无感知地逐步地扩大 QUIC 的使用面。</p>
<h3 id="内容分发网络"><a href="#内容分发网络" class="headerlink" title="内容分发网络"></a>内容分发网络</h3><p>影响互联网系统速度的四点因素：</p>
<ol>
<li>网站服务器接入网络运营商的出口带宽</li>
<li>用户客户端接入网络运营商的链路所能提供的入口带宽。</li>
<li>从网站到用户之间经过的不同运营商之间互联节点的带宽</li>
<li>从网站到用户之间的物理链路传输时延</li>
</ol>
<p> CDN可以显著改善1、3、4的问题</p>
<h4 id="路由解析"><a href="#路由解析" class="headerlink" title="路由解析"></a>路由解析</h4><p>没有内容分发网络参与的解析过程：<br>![[1750989315200.png]]<br>有内容分发网络的解析过程：<br>![[1750989558268.png]]</p>
<h4 id="内容分发"><a href="#内容分发" class="headerlink" title="内容分发"></a>内容分发</h4><p>CDN 获取源站资源的过程被称为“内容分发”，“内容分发网络”的名字正是由此而来，有两种分发方式：</p>
<ul>
<li>主动分发：源站主动发起，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上。可以采用任何传输方式、推送策略。双十一这种就会主动分发</li>
<li>被动回源：由用户访问所触发全自动、双向透明的资源缓存过程。当某个资源首次被用户请求的时候，CDN 缓存节点发现自己没有该资源，就会实时从源站中获取，这时资源的响应时间可粗略认为是资源从源站到 CDN 缓存节点的时间，再加上资源从 CDN 发送到用户的时间之和。小型站点一般是这样。</li>
</ul>
<h4 id="CDN应用"><a href="#CDN应用" class="headerlink" title="CDN应用"></a>CDN应用</h4><ul>
<li>加速静态资源</li>
<li>安全防御：源站只对CDN提供服务，CDH对外界提供服务，防御DDos攻击很有效</li>
<li>协议升级：对外提供的协议升级</li>
<li>状态缓存：可以缓存源站的状态</li>
<li>修改资源：返回资源给用户得时候可以修改内容，比如压缩、比如跨域</li>
<li>访问控制：实现黑白名单功能</li>
<li>注入功能：不该源站代码，注入各种功能</li>
<li>绕过网络措施</li>
</ul>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><blockquote>
<p><strong>负载均衡（Load Balancing）</strong><br>调度后方的多台机器，以统一的接口对外提供服务，承担此职责的技术组件被称为“负载均衡”。</p>
</blockquote>
<p>负载均衡往往是多级的，组要聚焦于网络请求进入数据中心入口之后的其它层级的负载均衡。</p>
<ul>
<li>四层负载均衡的优势是性能高，七层负载均衡的优势是功能强。</li>
<li>做多级混合负载均衡，通常应是低层的负载均衡在前，高层的负载均衡在后</li>
</ul>
<p>四层负载均衡：统称，胃痛维持着一个TCP连接，不是说只工作在第四层。只要工作在二层、三层，单纯只处理第四层的数据无法做到负载均衡的转发，因为上四层是主机层，已经到了目标主机了，谈不上转发，最多就是代理。</p>
<table>
<thead>
<tr>
<th></th>
<th>层</th>
<th>数据单元</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>7</td>
<td>应用层</td>
<td>数据</td>
<td>提供为应用软件提供服务的接口，用于与其他应用软件之间的通信。典型协议：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 等</td>
</tr>
<tr>
<td>6</td>
<td>表达层</td>
<td>数据</td>
<td>把数据转换为能与接收者的系统格式兼容并适合传输的格式。</td>
</tr>
<tr>
<td>5</td>
<td>会话层</td>
<td>数据</td>
<td>负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。</td>
</tr>
<tr>
<td>4</td>
<td>传输层</td>
<td>数据段</td>
<td>把传输表头加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。典型协议：TCP、UDP、RDP、SCTP、FCP 等</td>
</tr>
<tr>
<td>3</td>
<td>网络层</td>
<td>数据包</td>
<td>决定数据的传输路径选择和转发，将网络表头附加至数据段后以形成报文（即数据包）。典型协议：IPv4&#x2F;IPv6、IGMP、ICMP、EGP、RIP 等</td>
</tr>
<tr>
<td>2</td>
<td>数据链路层</td>
<td>数据帧</td>
<td>负责点对点的网络寻址、错误侦测和纠错。当表头和表尾被附加至数据包后，就形成数据帧（Frame）。典型协议：WiFi（802.11）、Ethernet（802.3）、PPP 等。</td>
</tr>
<tr>
<td>1</td>
<td>物理层</td>
<td>比特流</td>
<td>在物理网络上传送数据帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机接口卡等。</td>
</tr>
</tbody></table>
<h4 id="数据链路层负载均衡"><a href="#数据链路层负载均衡" class="headerlink" title="数据链路层负载均衡"></a>数据链路层负载均衡</h4><p>数据链路层传输：数据帧。</p>
<p>数据帧中有MAC源地址、MAC目标地址。<strong>数据链路层负载均衡，核心就是修改请求数据帧中的MAC目标地址，转发到对应服务器的网卡上。</strong></p>
<p>使用这种负载均衡模式时，需要把真实物理服务器集群所有机器的<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Virtual_IP_address">虚拟 IP 地址</a>（Virtual IP Address，VIP）配置成与负载均衡器的虚拟 IP 一样</p>
<p>![[Pasted image 20250627111727.png]]<br>整个请求、转发、响应的链路形成一个“三角关系”，所以这种负载均衡模式也常被很形象地称为“三角传输模式”（Direct Server Return，DSR）</p>
<h4 id="网络层负载均衡"><a href="#网络层负载均衡" class="headerlink" title="网络层负载均衡"></a>网络层负载均衡</h4><p>网络层传输：分组数据包。</p>
<p>分组数据包中包含源IP和目的IP，也是同样的思路，<strong>通过改变IP地址来实现数据包的转发</strong>。</p>
<ul>
<li><strong>IP隧道传输</strong>：新建数据包，把原来的做为新数据包的Payload，新包中写入目标IP，服务器收到包后，进行拆包，是“套娃式”的传输。效率低，依然还是三角传输，可以跨越VLAN。<br>![[Pasted image 20250627140319.png]]<br>一是要求真实服务器必须支持IP隧道协议，二十必须通过专门配置，都有相同的虚拟IP，需要系统管理员介入。</li>
<li><strong>NAT（网络地址转换）</strong>：改变目标数据包，不需要拆包。修改了之后，客户端不可能认识该IP，还得必须再返回到负载均衡。<br>![[Pasted image 20250627140927.png]]<br>流量压力比较大的时候，会有性能损失</li>
<li><strong>SNAT</strong>：在转发时候，不仅修改目标的IP，源IP也一起改，改成均衡器自己的IP。好处就是不配网关就可以正常三层路由到负载均衡商，缺点是所有流量都来自负载均衡器，有一些需要根据目标IP控制的约为逻辑无法进行。</li>
</ul>
<h4 id="应用层负载均衡"><a href="#应用层负载均衡" class="headerlink" title="应用层负载均衡"></a>应用层负载均衡</h4><p>四层负载均衡工作模式，本质还是转发；<br>四层以上的负载均衡，只能进行代理。<br>![[Pasted image 20250627142731.png]]</p>
<p>代理，根据”哪一方能感知到“的原则，分正向代理、反向代理、透明代理。</p>
<ul>
<li>正向代理：在客户端设置的，正向代理服务，VPN</li>
<li>反向代理：在服务器设置的，对客户端透明</li>
<li>透明代理：对双方都透明，比如架设在路由器上的透明翻墙代理。</li>
</ul>
<p>七层负载均衡器属于反向代理，网络性能肯定比不过四层均衡器。由于它至少多一轮TCP握手。主要的应用就是利用它在应用层通信的优势，进行决策。七层代理的功能：</p>
<ul>
<li>CDN缓存</li>
<li>智能化路由</li>
<li>安全防御</li>
<li>链路治理</li>
</ul>
<h4 id="均衡策略与实现"><a href="#均衡策略与实现" class="headerlink" title="均衡策略与实现"></a>均衡策略与实现</h4><p>负载均衡的两大职责是“选择谁来处理用户请求”和“将用户请求转发过去”，转发前面已经介绍，处理策略如下：</p>
<ul>
<li>轮询均衡：从1到N平均分配</li>
<li>权重轮询均衡：分权重分配</li>
<li>随机均衡：随机分配给多个服务器</li>
<li>一致性哈希均衡：算法保证同一个特征值一定落在相同的服务器上</li>
<li>响应速度均衡：向服务器发出探测请求，哪个块给哪个</li>
<li>最少连接数均衡：对每一台服务器都有数据记录，分给连接数最小的服务器。</li>
</ul>
<p>按照实现具体可以分为软负载和硬负载：</p>
<ul>
<li>软负载：操作系统（LVS）、应用程序（Nginx、HAproxy）</li>
<li>硬负载：F5、A10</li>
</ul>
<h3 id="服务端缓存"><a href="#服务端缓存" class="headerlink" title="服务端缓存"></a>服务端缓存</h3><p>引入缓存的两大理由：</p>
<ol>
<li>为缓解CPU压力而做缓存：把原来实时计算的内容提前算好，节省CPU算力</li>
<li>为缓解I&#x2F;O压力而做缓存：网络、磁盘慢介质变为内存这类快介质</li>
</ol>
<p>缓存，空间换时间，出发点就是缓解CPU和I&#x2F;O的压力。</p>
<h4 id="缓存属性"><a href="#缓存属性" class="headerlink" title="缓存属性"></a>缓存属性</h4><p>设计缓存至少考虑四个维度：</p>
<ul>
<li><strong>吞吐量</strong>：缓存的吞吐量使用 OPS 值（每秒操作数，Operations per Second，ops&#x2F;s）来衡量，反映了对缓存进行<strong>并发</strong>读、写操作的效率，即缓存本身的工作效率高低。</li>
<li><strong>命中率</strong>：缓存的命中率即成功从缓存中返回结果次数与总请求次数的比值，反映了引入缓存的价值高低，命中率越低，引入缓存的收益越小，价值越低。</li>
<li><strong>扩展功能</strong>：缓存除了基本读写功能外，还提供哪些额外的管理功能，譬如最大容量、失效时间、失效事件、命中率统计，等等。</li>
<li><strong>分布式支持</strong>：缓存可分为“进程内缓存”和“分布式缓存”两大类，前者只为节点本身提供服务，无网络访问操作，速度快但缓存的数据不能在各个服务节点中共享，后者则相反</li>
</ul>
<h5 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h5><p>JDK 8 改进之后的 ConcurrentHashMap 基本上就是你能找到的吞吐量最高的缓存容器</p>
<p>对读写操作的状态维护，有两种思路：</p>
<ul>
<li>同步处理，Guava Cache，在访问数据时一并完成缓存淘汰、统计、失效等状态变更操作，通过分段加锁优化减少竞争。</li>
<li>异步处理，Caffeine，将对数据的读、写过程看作是日志（即对数据的操作指令）的提交过程。</li>
</ul>
<h5 id="命中率与淘汰策略"><a href="#命中率与淘汰策略" class="headerlink" title="命中率与淘汰策略"></a>命中率与淘汰策略</h5><p><strong>淘汰策略</strong>：缓存如何自动地实现淘汰低价值目标，最基础的淘汰策略实现方案有以下三种：</p>
<ul>
<li>FIFO：优先淘汰最早进入被缓存的数据</li>
<li>LRU：优先淘汰最久未被使用访问过的数据，HashMap+Linkedlist实现，热点有点时间没访问过，可能也会被淘汰</li>
<li>LFU：优先淘汰最不经常使用的数据，访问计数，解决惹点问题，但是需要额外维护计数器<ul>
<li><strong>TinyLFU</strong>：为了缓解 LFU 每次访问都要修改计数器所带来的性能负担，用相对小得多的记录频率和空间来近似地找出缓存中的低价值数据</li>
<li><strong>W-TinyLFU</strong>：应对稀疏突发访问</li>
</ul>
</li>
</ul>
<h5 id="扩展功能"><a href="#扩展功能" class="headerlink" title="扩展功能"></a>扩展功能</h5><p>专业的缓存往往还会提供很多额外的功能：</p>
<ul>
<li>加载器：让缓存从只能被动存储外部放入的数据，变为能够主动通过加载器去加载指定 Key 值的数据，加载器也是实现自动刷新功能的基础前提。</li>
<li>淘汰策略：支持用户自己根据需要选择不同的淘汰策略。</li>
<li>失效策略：要求缓存的数据在一定时间后自动失效或者自动刷新。</li>
<li>事件通知：提供一些事件监听器</li>
<li>并发级别：对于通过分段加锁来实现的缓存（以 Guava Cache 为代表），往往会提供并发级别的设置。</li>
<li>容量控制：缓存通常都支持指定初始容量和最大容量，初始容量目的是减少扩容频率</li>
<li>持久化：支持将缓存的内容存储到数据库或者磁盘中</li>
</ul>
<h5 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h5><ul>
<li>复制式缓存：甚少更新但频繁读取的数据。缓存中所有数据在分布式集群的每个节点里面都存在有一份副本，读取数据时无须网络访问，直接从当前节点的进程内存中返回，理论上可以做到与进程内缓存一样高的读取性能</li>
<li>集中式缓存：更新和读取都较为频繁的数据。Redis成为了分布式缓存的实质上的首选，几乎到了不必管读取、写入哪种操作更频繁，都可以无脑上 Redis 的程度。</li>
</ul>
<p>一致性方面，一般也不会追求强一致性的数据使用缓存来处理。比如Redis就是典型的AP式，不保证强一致性。</p>
<p> ZooKeeper、Doozerd、Etcd是能够保证强一致性的分布式协调框架，其常与 Redis 和其他分布式缓存搭配工作，用来实现其中的通知、协调、队列、分布式锁等功能。</p>
<p>分布式缓存和进程内缓存各有所长，可以搭配形成透明多级缓存<br>![[Pasted image 20250630144540.png]]</p>
<h4 id="缓存风险"><a href="#缓存风险" class="headerlink" title="缓存风险"></a>缓存风险</h4><ul>
<li><strong>缓存穿透</strong>：查询不存在数据，有两种办法，一是本身无法避免的，返回空值，二是恶意攻击的，设置布隆过滤器，最小代价判断元素是否存在集合</li>
<li><strong>缓存击穿</strong>：单个热点数据失效，导致其都到真实的数据源重。有两种办法，一是以请求该数据的 Key 值为锁，使得只有第一个请求可以流入到真实的数据源中；二是代码管理热点数据，自动管理</li>
<li><strong>缓存雪崩</strong>：大批数据在短时间内一起失效，导致压力据增。有三种办法：一是提升可用性；二是多级透明缓存，分散过期时间；三是生存期改成随机时间。</li>
<li><strong>缓存污染</strong>：缓存数据与真实数据不一致。应该遵循更新缓存规范，比如Cache Aside模式，先读缓存，没有读源，放入再响应，写时先写数据源，然后失效缓存。一定是<strong>先数据源后缓存</strong>。</li>
</ul>
<h2 id="架构安全性"><a href="#架构安全性" class="headerlink" title="架构安全性"></a>架构安全性</h2><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><blockquote>
<p><strong>认证（Authentication）</strong><br>系统如何正确分辨出操作用户的真实身份？</p>
</blockquote>
<p>代码认证的研究发展方向已经很固定，基本上都统一到证书签名上，本书主要研究用户认证。</p>
<h4 id="认证的标准"><a href="#认证的标准" class="headerlink" title="认证的标准"></a>认证的标准</h4><p>主流的三种认证方式</p>
<ul>
<li>通信信道上的认证：传输得时候证明你是谁（SSL&#x2F;TSL认证）</li>
<li>通信协议上的认证：请求我资源前证明你是谁（HTTP认证）</li>
<li>通信内容上的认证：使用我服务器证明你是谁（Web内容认证）</li>
</ul>
<h5 id="HTTP认证"><a href="#HTTP认证" class="headerlink" title="HTTP认证"></a>HTTP认证</h5><p>HTTP 认证框架提出认证方案是希望能把认证“要产生身份凭证”的目的与“具体如何产生凭证”的实现分离开来。</p>
<p>![[1751337254849.png]]</p>
<h5 id="Web认证"><a href="#Web认证" class="headerlink" title="Web认证"></a>Web认证</h5><p>采用HTTP认证的比例很低，因为HTTP本质时传输资源，只能面向传输协议设计认证框架。</p>
<p><strong>Web认证</strong>：由系统本身的功能完成，实现形式上登录表单占了主流，因此也被称为“表单认证”</p>
<p>WebAuthn注册流程：<br>![[1751339849482.png]]</p>
<h4 id="认证的实现"><a href="#认证的实现" class="headerlink" title="认证的实现"></a>认证的实现</h4><p>在今时今日，实际活跃于 Java 安全领域的是两个私有的安全框架：Apache Shiro 和 Spring Security</p>
<ul>
<li>Shiro：便捷易用</li>
<li>Security：复杂强大<br>包含功能：认证、安全上下文、授权、密码的存储与验证。</li>
</ul>
<h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><blockquote>
<p><strong>授权（ Authorization）</strong><br>系统如何控制一个用户该看到哪些数据、能操作哪些功能？</p>
</blockquote>
<p>4A（Authentication、Authorization、Audit、Account），安全领域的授权具体涉及两个问题：</p>
<ul>
<li><strong>授权过程可靠</strong>：多方授权协议：OAuth2、SAML2.0</li>
<li><strong>授权结果可控</strong>：自主访问控制DAC、基于属性访问控制ABAC、基于角色访问控制RBAC</li>
</ul>
<h4 id="RBAC"><a href="#RBAC" class="headerlink" title="RBAC"></a>RBAC</h4><p>所有的访问控制模型，实质上都是在解决同一个问题：“<strong>谁</strong>（User）拥有什么<strong>权限</strong>（Authority）去<strong>操作</strong>（Operation）哪些<strong>资源</strong>（Resource）”。</p>
<p>RBAC 将权限从用户身上剥离，改为绑定到“<strong>角色</strong>”（Role）上，将权限控制变为对“<strong>角色</strong>拥有操作哪些<strong>资源</strong>的<strong>许可</strong>”这个逻辑表达式的值是否为真的求解过程。</p>
<p>![[1751445826794.png]]</p>
<p>天然满足“最小特权原则”，允许角色之间定义关联与约束（继承关系）、不同角色之间也可以具有互斥性。</p>
<h4 id="OAuth2"><a href="#OAuth2" class="headerlink" title="OAuth2"></a>OAuth2</h4><p> OAuth2 是<strong>面向于解决第三方应用</strong>（Third-Party Application）的认证授权协议。<br> 关键术语：<br> - 第三方应用：需要得到授权访问我资源的那个应用<br> - 授权服务器：能够根据我的意愿提供授权的服务器<br> - 资源服务器：能够提供第三方应用所需资源的服务器<br> - 资源所有者：拥有授权权限的人，即此场景中的“我”。<br> - 操作代理：指用户用来访问服务器的工具</p>
<p>OAuth2 一共提出了四种不同的授权方式</p>
<ol>
<li>授权码模式：最严谨，考虑了所有敏感信息泄露的预防和后果</li>
<li>隐式授权模式：略掉了通过授权码换取令牌的步骤，整个授权过程都不需要服务端支持</li>
<li>密码模式：认证和授权就被整合成了同一个过程</li>
<li>客户端模式：没有了“第二方”的存在</li>
</ol>
<h3 id="凭证"><a href="#凭证" class="headerlink" title="凭证"></a>凭证</h3><blockquote>
<p><strong>凭证（Credentials）</strong><br>系统如何保证它与用户之间的承诺是双方当时真实意图的体现，是准确、完整且不可抵赖的？</p>
</blockquote>
<p>共享状态信息在服务端还是客户端，分化为Cookies、Session以及JWT。</p>
<h4 id="Cookie-Session"><a href="#Cookie-Session" class="headerlink" title="Cookie-Session"></a>Cookie-Session</h4><p> HTTP 协议无状态，最有悖于常见的网络应用场景就是认证授权。<br> RFC 6265规范定义了HTTP状态管理机制，在协议种增加了Set-Cookie指令。一般来说，系统会把状态信息保存在服务端，在Cookie里只传输一个无意义的字符串，以sessionid为名。<br> Cookie-Session 也是最传统的，由服务端与客户端联动来完成的状态管理机制。</p>
<p>当服务器水平拓展时，设计者必须在CAP中选择牺牲</p>
<p><strong>分布式下的认证授权问题，不一定只能依靠共享信息实现</strong><br>JWT 令牌与 Cookie-Session 并不是完全对等的解决方案，它只用来处理认证授权问题，充其量能携带少量非敏感的信息，只是 Cookie-Session 在认证授权问题上的替代品</p>
<h4 id="JWT"><a href="#JWT" class="headerlink" title="JWT"></a>JWT</h4><p>当服务器存在多个，客户端只有一个时，把状态信息存储在客户端，每次随着请求发回服务器去。标准答案就是JWT。<br>最常见的使用方式是附在名为 Authorization 的 Header 发送给服务端</p>
<p>JWT令牌以JSON结构存储，分三个部分：</p>
<ul>
<li>令牌头：展示令牌类型和签名算法</li>
<li>负载：真正需要向服务端传递的信息，告诉服务器用户是谁，拥有什么权限</li>
<li>签名：使用在对象头中公开的特定签名算法，通过特定的密钥对前面两部分内容进行加密计算，保证信息可信。<br>JWT的缺点：</li>
<li>令牌难以主动失效</li>
<li>相对更容易遭受重放攻击</li>
<li>只能携带相当有限的数据</li>
<li>必须考虑令牌在客户端如何存储</li>
<li>无状态不也总是好的</li>
</ul>
<h3 id="保密"><a href="#保密" class="headerlink" title="保密"></a>保密</h3><blockquote>
<p><strong>保密（Confidentiality）</strong><br>系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？</p>
</blockquote>
<p>加密和解密的统称<br>按照缓解可以分为“端的保密”和“链路的保密”两类</p>
<h4 id="保密的强度"><a href="#保密的强度" class="headerlink" title="保密的强度"></a>保密的强度</h4><p>分级开展信息保密。以用户登录为例，例举了几种不同强度的保密手段：</p>
<ul>
<li>摘要代替明文：无法防止弱密码被彩虹表攻击</li>
<li>加盐再哈希：不能防止加密被监听、冒认等问题</li>
<li>物理设备U盾：开辟独立于网络的信息通道</li>
</ul>
<h4 id="客户端加密"><a href="#客户端加密" class="headerlink" title="客户端加密"></a>客户端加密</h4><p>真正防御性的密码加密存储确实应该在服务端中进行</p>
<h4 id="密码存储和验证"><a href="#密码存储和验证" class="headerlink" title="密码存储和验证"></a>密码存储和验证</h4><p>介绍对一个普通安全强度的信息系统，密码如何从客户端传输到服务端，然后存储进数据库的全过程。</p>
<ol>
<li>输入明文密码</li>
<li>简单哈希摘要</li>
<li>加盐处理</li>
<li>引入慢哈希函数</li>
<li>引入随机盐值</li>
<li>将动态盐值混入客户端传来的哈希值再做一次哈希</li>
</ol>
<h3 id="传输"><a href="#传输" class="headerlink" title="传输"></a>传输</h3><blockquote>
<p><strong>传输（Transport Security）</strong><br>系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充？</p>
</blockquote>
<h4 id="摘要、加密与签名"><a href="#摘要、加密与签名" class="headerlink" title="摘要、加密与签名"></a>摘要、加密与签名</h4><p>摘要称之为数字摘要（Digital Digest）或数字指纹（Digital Fingerprint）。JWT 令牌中默认的签名信息是对令牌头、负载和密钥三者通过令牌头中指定的哈希算法（HMAC SHA256）计算出来的摘要值</p>
<p>理想和哈希算法有易变性、不可逆性两大特点。摘要的意义是在源信息不泄漏的前提下辨别其真伪。摘要也会用来做加密和签名。</p>
<ul>
<li><p>与加密的区别，加密是可逆的。现代密码学不依靠机密性，加解密算法都是完全公开的，安全建立在特定问题的计算复杂度之上，具体是指算法根据输入端计算输出结果耗费的算力资源很小，但根据输出端的结果反过来推算原本的输入，耗费的算力就极其庞大。</p>
</li>
<li><p>在签名方面，现在一般会结合摘要与非对称加密的优点，以对摘要结果做加密的形式来保证签名的适用性。由于对任何长度的输入源做摘要之后都能得到固定长度的结果，所以只要对摘要的结果进行签名，即相当于对整个输入源进行了背书，保证一旦内容遭到篡改，摘要结果就会变化，签名也就马上失效了。</p>
</li>
</ul>
<p> ![[1751785359667.png]]</p>
<h4 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h4><p>无法以“签名”的手段来达成信任时——公开密钥基础设施PKI，借助数字证书认证中心CA将用户和公开密钥连接。<br>PKI是负责发放和管理数字证书的权威机构</p>
<p>证书（Certificate），证书是权威 CA 中心对特定公钥信息的一种公证载体，也可以理解为是权威 CA 对特定公钥未被篡改的签名背书。证书有具体标准和包含的信息项</p>
<h4 id="传输安全层"><a href="#传输安全层" class="headerlink" title="传输安全层"></a>传输安全层</h4><p>这里介绍了TLS通信的保障过程。</p>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>提倡的做法是把校验行为从分层中剥离出来，不是在哪一层做，而是在 Bean 上做。即 Java Bean Validation。</p>
<h1 id="分布式的基石"><a href="#分布式的基石" class="headerlink" title="分布式的基石"></a>分布式的基石</h1><h2 id="分布式共识算法"><a href="#分布式共识算法" class="headerlink" title="分布式共识算法"></a>分布式共识算法</h2><p>如何重要数据的可靠性（多台机器数据一致）、可用性（多台机器数据可访问）</p>
<p>❓如果你有一份会随时变动的数据，要确保它正确地存储于网络中的几台不同机器之上，你会怎么做？</p>
<ul>
<li>将同步视为事务性操作：2PC、3PC实现，完成同步操作</li>
<li>主从全同步复制（<strong>状态转移</strong>）：Mysql，等待所有 Slave 节点的 Binlog 都完成写入后，Master 节点的事务才进行提交</li>
</ul>
<p>可靠性与可用性矛盾，在分布式系统里主流的数据复制方法是以<strong>操作转移（Operation Transfer）</strong> 为基础，类似于状态机，提出状态机复制。</p>
<p><strong>Quorum机制</strong>：一旦系统中过半数的节点中完成了状态的转换，就认为数据的变化已经被正确地存储在系统当中，这样就可以容忍少数（通常是不超过半数）的节点失联，使得增加机器数量对系统整体的可用性变成是有益的。</p>
<p><strong>协商共识算法</strong>：需要设计出一种算法，能够让分布式系统内部暂时容忍存在不同的状态，但最终能够保证大多数节点的状态达成一致；同时，能够让分布式系统在外部看来始终表现出整体一致的结果。</p>
<p>Tips：共识是达成一致性的方法和过程，一致性是数据不同副本之间的差异</p>
<h3 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h3><blockquote>
<p><strong>Distributed Consensus Algorithm</strong><br>世界上只有一种共识协议，就是 Paxos，其他所有共识算法都是 Paxos 的退化版本。</p>
</blockquote>
<p>Leslie Lamport提出Paxox，一种基于消息传递的协商共识算法</p>
<h4 id="Paxos的诞生"><a href="#Paxos的诞生" class="headerlink" title="Paxos的诞生"></a>Paxos的诞生</h4><p>虚构了“Paxos”希腊城邦，要制定法律，需要靠兼职议会来完成，无法保证所有城邦居民都能够及时地了解新的法律提案、也无法保证居民会及时为提案投票。</p>
<p>目标：让城邦能够在每一位居民都不承诺一定会及时参与的情况下，依然可以按照少数服从多数的原则，最终达成一致意见。（不考虑错传）</p>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li><strong>提案节点</strong>：称为 Proposer，提出对某个值进行设置操作的节点，设置值这个行为就被称之为<strong>提案</strong>（Proposal），值一旦设置成功，就是不会丢失也不可变的。请注意，Paxos 是典型的基于操作转移模型而非状态转移模型来设计的算法，这里的“设置值”不要类比成程序中变量赋值操作，应该类比成日志记录操作，在后面介绍的 Raft 算法中就直接把“提案”叫作“日志”了。</li>
<li><strong>决策节点</strong>：称为 Acceptor，是应答提案的节点，决定该提案是否可被投票、是否可被接受。提案一旦得到过半数决策节点的接受，即称该提案被<strong>批准</strong>（Accept），提案被批准即意味着该值不能再被更改，也不会丢失，且最终所有节点都会接受该它。</li>
<li><strong>记录节点</strong>：被称为 Learner，不参与提案，也不参与决策，只是单纯地从提案、决策节点中学习已经达成共识的提案，譬如少数派节点从网络分区中恢复时，将会进入这种状态。</li>
</ul>
<p>![[c9c77ab9-785d-4a81-b812-b4eb1b7dad20.png]]（需要反复看）</p>
<h3 id="Multi-Paxos"><a href="#Multi-Paxos" class="headerlink" title="Multi Paxos"></a>Multi Paxos</h3><p><strong>核心改进</strong>：</p>
<ul>
<li>增加了“选主”的过程，提案节点会通过定时轮询（心跳），确定当前网络中的所有节点里是否存在有一个主提案节点，一旦没有发现主节点存在，节点就会在心跳超时后使用 Basic Paxos 中定义的准备、批准的两轮网络交互过程，向所有其他节点广播自己希望竞选主节点的请求，希望整个分布式系统对“由我作为主节点”这件事情协商达成一致共识，如果得到了决策节点中多数派的批准，便宣告竞选成功。</li>
<li>通俗理解为选主过后，就不会再有其他节点与它竞争，相当于是处于无并发的环境当中进行的有序操作，所以此时系统中要对某个值达成一致，只需要进行一次批准的交互即可，</li>
</ul>
<p>![[213d39e5-7f0b-4a89-b39a-27ab3920a36e.png]]<br>“分布式系统中如何对某个值达成一致” 转化为如下三个子问题：</p>
<ul>
<li>如何选主</li>
<li>如何把数据复制到各个节点上</li>
<li>如何保证过程是安全的<br><strong>Raft 算法</strong> ：就是这种解题思路， Etcd、LogCabin、Consul 等重要分布式程序的实现基础</li>
</ul>
<h3 id="Gossip-协议"><a href="#Gossip-协议" class="headerlink" title="Gossip 协议"></a>Gossip 协议</h3><p>分布式共识协议：</p>
<ul>
<li>强一致性：Paxos、Raft、ZAB 等分布式算法（从系统外部看来，不一致的情况并不会被观察到，所以整体上看系统是强一致性的）</li>
<li>最终一致性：Gossip 协议，不一致的状态有可能会在一定时间内被外部直接观察到</li>
</ul>
<p>区块链、DNS中所有使用到。<br>![[file-20250725003457545.png]]</p>
<p>步骤：</p>
<ul>
<li>如果有某一项信息需要在整个网络中所有节点中传播，那从信息源开始，选择一个固定的传播周期（譬如 1 秒），随机选择它相连接的 k 个节点（称为 Fan-Out）来传播消息。</li>
<li>每一个节点收到消息后，如果这个消息是它之前没有收到过的，将在下一个周期内，选择除了发送消息给它的那个节点外的其他相邻 k 个节点发送相同的消息，直到最终网络中所有节点都收到了消息，尽管这个过程需要一定时间，但是理论上最终网络的所有节点都会拥有相同的消息。<br>缺点：一是不知道什么时候能全部一致，二是可能重复可能取消，增加网络压力<br>对应又设计了两种可能的传播模式：反熵（Anti-Entropy）和传谣（Rumor-Mongering）</li>
</ul>
<h2 id="从类库到服务"><a href="#从类库到服务" class="headerlink" title="从类库到服务"></a>从类库到服务</h2><ul>
<li>类库：在编译期静态链接到程序中的，通过调用本地方法来使用其中的功能</li>
<li>服务：进程外组件，通过调用远程方法来使用其中的功能</li>
</ul>
<p>采用服务来构建程序，获得的收益是软件系统“整体”与“部分”在物理层面的真正隔离，但是也带来了复杂度和性能问题：</p>
<ul>
<li><strong>服务发现</strong>：对消费者来说，外部的服务由谁提供？具体在什么网络位置？</li>
<li><strong>服务的网关路由</strong>：对生产者来说，内部哪些服务需要暴露？哪些应当隐藏？应当以何种形式暴露服务？以什么规则在集群中分配请求？</li>
<li><strong>服务的负载均衡</strong>对调用过程来说，如何保证每个远程服务都接收到相对平均的流量，获得尽可能高的服务质量与可靠性？</li>
</ul>
<h3 id="服务发现的意义"><a href="#服务发现的意义" class="headerlink" title="服务发现的意义"></a>服务发现的意义</h3><p>远程服务调用坐标：权限定名、端口号、服务标识</p>
<ul>
<li>全限定名：网络中某台主机的精确位置</li>
<li>端口号：主机上某一个提供了 TCP&#x2F;UDP 网络服务的程序</li>
<li>服务标识：该程序所提供的某个具体的方法入口。与应用层协议相关，具有多样性。</li>
</ul>
<p>服务发现的两种理解：</p>
<ul>
<li>UDDI百科全书式的服务发现：啥都在管辖范围内</li>
<li>“门牌号码式”的服务发现（<strong>主流</strong>）：只满足从某个代表服务提供者的全限定名到服务实际主机 IP 地址的翻译转换</li>
</ul>
<p>演进过程：DNS+负载均衡——&gt;Zookeeper——&gt;Eureka——&gt;基础设施</p>
<h3 id="可用和可靠"><a href="#可用和可靠" class="headerlink" title="可用和可靠"></a>可用和可靠</h3><p>服务发现的必须过程：</p>
<ul>
<li><strong>服务注册</strong>：当服务启动的时候，它应该通过某些形式将自己的坐标信息通知到服务注册中心，这个过程可能由应用程序本身来完成，称为自注册模式</li>
<li><strong>服务维护</strong>：保证所维护的服务列表的正确性，以避免告知消费者服务的坐标后，得到的服务却不能使用的尴尬情况。</li>
<li><strong>服务发现</strong>：把一个符号（譬如 Eureka 中的 ServiceID、Nacos 中的服务名、或者通用的 FQDN）转换为服务实际坐标的过程</li>
</ul>
<p>概念模型中的服务发现：<br>![[file-20250726023346666.png]]</p>
<p>真实系统中的服务发现：<br>![[file-20250726023704759.png]]</p>
<p>不同框架CAP的选择：</p>
<ul>
<li>Eureka 的选择是优先保证高可用性，相对牺牲系统中服务状态的一致性。（通过 Ribbon 和 Hystrix 模块配合来兜底，实现故障转移（Failover）或者快速失败（Failfast））</li>
<li>Consul 的选择是优先保证高可靠性，相对牺牲系统服务发现的可用性。（Raft算法、Gossip）</li>
</ul>
<h3 id="注册中心实现"><a href="#注册中心实现" class="headerlink" title="注册中心实现"></a>注册中心实现</h3><p>有三类工具&#x2F;组件：</p>
<ul>
<li>在分布式 K&#x2F;V 存储框架上自己开发的服务发现（提供了分布式环境下读写操作的共识算法，都是CP）</li>
<li>以基础设施（主要是指 DNS 服务器）来实现服务发现，这类的代表是 SkyDNS、CoreDNS。</li>
<li>专门用于服务发现的框架和工具，这类的代表是 Eureka、Consul 和 Nacos。</li>
</ul>
<h3 id="网关路由"><a href="#网关路由" class="headerlink" title="网关路由"></a>网关路由</h3><p>单体架构：为各个单体系统的副本分发流量的负载均衡器实质上承担了内部服务与外部请求之间的网关角色。</p>
<p>微服务环境：微服务架构下，每个服务节点都可能由不同团队负责，都有着自己独立的、互不相同的接口，如果服务集群缺少一个统一对外交互的代理人角色，那外部的服务消费者就必须知道所有微服务节点在集群中的精确坐标</p>
<p><strong>微服务网关</strong>（“服务网关”或者“API 网关”）的首要职责就是作为统一的出口对外提供服务，将外部访问网关地址的流量，根据适当的规则路由到内部集群中正确的服务节点之上。</p>
<p>网关 &#x3D; 路由器（基础职能） + 过滤器（可选职能）</p>
<ul>
<li>路由器：“网络协议层次”和“性能与可用性”<ul>
<li>四层流量转发与七层流量代理，本质和负载均衡器差不多（从目的角度看，负载均衡器与服务网关会有一些区别，具体在于前者是为了根据均衡算法对流量进行平均地路由，后者是为了根据流量中的某种特征进行正确地路由。）</li>
<li>网关的性能与它的工作模式和自身实现算法都有关系，但毫无疑问工作模式是最关键的因素，如果能够采用 DSR 三角传输模式，原理上就决定了性能一定会比代理模式来的强</li>
</ul>
</li>
</ul>
<h3 id="网关IO模型"><a href="#网关IO模型" class="headerlink" title="网关IO模型"></a>网关IO模型</h3><p>网络 I&#x2F;O 的出入口就是 Socket 的读和写</p>
<p>当发生一次网络请求发生后，将会按顺序经历“等待数据从远程主机到达缓冲区”和“将数据从缓冲区拷贝到应用程序地址空间”两个阶段，根据实现这两个阶段的不同方法，人们把网络 I&#x2F;O 模型总结为两类、五种模型：</p>
<ul>
<li>两类是指<strong>同步 I&#x2F;O</strong>与<strong>异步 I&#x2F;O</strong></li>
<li>五种是指在同步 IO 中又分有划分出<strong>阻塞 I&#x2F;O</strong>、<strong>非阻塞 I&#x2F;O</strong>、<strong>多路复用 I&#x2F;O</strong>和<strong>信号驱动 I&#x2F;O</strong>四种细分模型。</li>
</ul>
<p>同步：调用端发出请求之后，得到结果之前必须一直等待；<br>异步：发出调用请求之后将立即返回，不会马上得到处理结果，结果将通过状态变化和回调来通知调用者。<br>阻塞和非阻塞：针对请求处理过程，指收到调用请求之后，返回结果之前，当前处理线程是否会被挂起。</p>
<ul>
<li><strong>异步 I&#x2F;O</strong>：订盒饭，做好通知我，一定是非阻塞</li>
<li><strong>同步 I&#x2F;O</strong>：去食堂打饭<ul>
<li><strong>阻塞 I&#x2F;O</strong>：发现饭还没做好，你也干不了别的，只能打个瞌睡（线程休眠）</li>
<li><strong>非阻塞 I&#x2F;O</strong>：你去到饭堂，发现饭还没做好，你就回去了，然后每隔 3 分钟来一次饭堂看饭做好了没，直到饭做好</li>
<li><strong>多路复用 I&#x2F;O</strong>：可以在同一条阻塞线程上处理多个不同端口的监听。代表整个宿舍去饭堂打饭，去到饭堂，发现饭还没做好，还是继续打瞌睡，但哪个舍友的饭好了，你就马上把那份饭送回去。可以细分 select、epoll、kqueue</li>
<li><strong>信号驱动 I&#x2F;O</strong>：你去到饭堂，发现饭还没做好，但你跟厨师熟，跟他说饭做好了叫你，然后回去该干嘛干嘛，等收到厨师通知后，你把饭从饭堂拿回宿舍。这里厨师的通知就是那个“信号“。</li>
</ul>
</li>
</ul>
<p>异步 I&#x2F;O 模型是最方便的，但是目前不是很完善，当下以多路复用 I&#x2F;O 模型模式为主。</p>
<p>网关的可用性：</p>
<ul>
<li>网关应尽可能轻量，过度增加网关的职责是危险的</li>
<li>应该尽可能选择较成熟的产品实现</li>
<li>虑在网关之前部署负载均衡器</li>
</ul>
<p>BFF网关：应该针对不同的前端，聚合不同的服务，提供不同的接口和网络访问协议支持。</p>
<h3 id="客户端负载均衡"><a href="#客户端负载均衡" class="headerlink" title="客户端负载均衡"></a>客户端负载均衡</h3><h3 id="客户端负载均衡器"><a href="#客户端负载均衡器" class="headerlink" title="客户端负载均衡器"></a>客户端负载均衡器</h3><p>![[file-20250730050927848.png]]<br>服务端负载均衡器&#x2F;客户端负载均衡器</p>
<p>客户端负载均衡器的好处：</p>
<ul>
<li>均衡器与服务之间信息交换是进程内的方法调用，不存在任何额外的网络开销。</li>
<li>不依赖集群边缘的设施，所有内部流量都仅在服务集群的内部循环<br>缺点：</li>
<li>它与服务运行于同一个进程之内，意味着它的选型受到服务所使用的编程语言的限制</li>
<li>k从个体服务来看，由于是共用一个进程，均衡器的稳定性会直接影响整个服务进程的稳定性</li>
</ul>
<p>客户端均衡器中最具代表性的产品是 Netflix Ribbon 和 Spring Cloud Load Balancer</p>
<h3 id="代理负载均衡器"><a href="#代理负载均衡器" class="headerlink" title="代理负载均衡器"></a>代理负载均衡器</h3><p>最近两三年，服务网格（Service Mesh）开始逐渐盛行，提出了代理均衡器</p>
<p><strong>代理均衡器</strong>：对此前的客户端负载均衡器的改进是将原本嵌入在服务进程中的均衡器提取出来，作为一个进程之外，同一 Pod 之内的特殊服务。<br>![[file-20250731002326833.png]]<br>代理均衡器的优势：</p>
<ul>
<li>不再受编程语言的限制</li>
<li>在服务拓扑感知方面代理均衡器也要更有优势</li>
<li>在安全性、可观测性上，由于边车代理都是一致的实现，有利于在服务间建立双向 TLS 通信，也有利于对整个调用链路给出更详细的统计信息。</li>
</ul>
<p>目前还不太成熟，但未来会是微服务主流的通讯方式。</p>
<h3 id="地域和区域"><a href="#地域和区域" class="headerlink" title="地域和区域"></a>地域和区域</h3><ul>
<li><strong>Region</strong>：地域，譬如华北、东北、华东、华南，这些都是地域范围。不同地域之间是没有内网连接的，所有流量都只能经过公众互联网相连，如果微服务的流量跨越了地域，实际就跟调用外部服务商提供的互联网服务没有任何差别了。</li>
<li><strong>Zone</strong>：区域，地理上位于同一地域内，但电力和网络是互相独立的物理区域，譬如在华东的上海、杭州、苏州的不同机房就是同一个地域的几个可用区域。同一个地域的可用区域之间具有内网连接，流量不占用公网带宽，因此区域是微服务集群内流量能够触及的最大范围。<ul>
<li>高可用即多区域部署</li>
<li>低延迟即同区域部署<br>对于没有使用云计算设施的系统，不涉及地域、区域的概念。</li>
</ul>
</li>
</ul>
<h2 id="流量治理"><a href="#流量治理" class="headerlink" title="流量治理"></a>流量治理</h2><p>随着拆分出的服务越来越多，也会有两个问题的困扰：</p>
<ul>
<li>某一个服务崩溃，导致雪崩效应</li>
<li>服务没有崩溃，但是大部分请求都超时无法治理</li>
</ul>
<h3 id="服务容错"><a href="#服务容错" class="headerlink" title="服务容错"></a>服务容错</h3><p>容错性设计：无法妥协的构建微服务的指导性原则</p>
<h3 id="容错策略"><a href="#容错策略" class="headerlink" title="容错策略"></a>容错策略</h3><p>常见的容错策略：</p>
<table>
<thead>
<tr>
<th>容错策略</th>
<th>优点</th>
<th>缺点</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>故障转移</strong></td>
<td>系统自动处理，调用者对失败的信息不可见</td>
<td>增加调用时间，额外的资源开销</td>
<td>调用幂等服务  对调用时间不敏感的场景</td>
</tr>
<tr>
<td><strong>快速失败</strong></td>
<td>调用者有对失败的处理完全控制权，不依赖服务的幂等性</td>
<td>调用者必须正确处理失败逻辑，如果一味只是对外抛异常，容易引起雪崩</td>
<td>调用非幂等的服务，超时阈值较低的场景</td>
</tr>
<tr>
<td><strong>安全失败</strong></td>
<td>不影响主路逻辑</td>
<td>只适用于旁路调用</td>
<td>调用链中的旁路服务</td>
</tr>
<tr>
<td><strong>沉默失败</strong></td>
<td>控制错误不影响全局</td>
<td>出错的地方将在一段时间内不可用</td>
<td>频繁超时的服务</td>
</tr>
<tr>
<td><strong>故障恢复</strong></td>
<td>调用失败后自动重试，也不影响主路逻辑</td>
<td>重试任务可能产生堆积，重试仍然可能失败</td>
<td>调用链中的旁路服务  对实时性要求不高的主路逻辑也可以使用</td>
</tr>
<tr>
<td><strong>并行调用</strong></td>
<td>尽可能在最短时间内获得最高的成功率</td>
<td>额外消耗机器资源，大部分调用可能都是无用功</td>
<td>资源充足且对失败容忍度低的场景</td>
</tr>
<tr>
<td><strong>广播调用</strong></td>
<td>支持同时对批量的服务提供者发起调用</td>
<td>资源消耗大，失败概率高</td>
<td>只适用于批量操作的场景</td>
</tr>
</tbody></table>
<h3 id="容错设计模式"><a href="#容错设计模式" class="headerlink" title="容错设计模式"></a>容错设计模式</h3><p><strong>断路器</strong>：通过代理（断路器对象）来一对一地（一个远程服务对应一个断路器对象）接管服务调用者的远程请求。断路器会持续监控并统计服务返回的成功、失败、超时、拒绝等各种结果，当出现故障（失败、超时、拒绝）的次数达到断路器的阈值时，它状态就自动变为“OPEN”，后续此断路器代理的远程访问都将直接返回调用失败，而不会发出真正的远程服务请求。<br>![[29141bb3-e5b4-447b-8629-470d9d559350.png]]</p>
<p>断路器服务熔断，上有系统服务降级</p>
<h3 id="舱壁隔离模式"><a href="#舱壁隔离模式" class="headerlink" title="舱壁隔离模式"></a>舱壁隔离模式</h3><p>服务隔离的意义：为了不让某一个远程服务的局部失败演变成全局性的影响，就必须设置某种止损方案</p>
<ul>
<li>局部线程池：能够隔离影响，但存在问题。根据 Netflix 官方给出的数据，一旦启用 Hystrix 线程池来进行服务隔离，大概会为每次服务调用增加约 3 毫秒至 10 毫秒的延时，如果调用链中有 20 次远程服务调用，那每次请求就要多付出 60 毫秒至 200 毫秒的代价来换取服务隔离的安全保障。</li>
<li>信号量机制：只为每个远程服务维护一个线程安全的计数器即可。单纯维护一个作为计数器的信号量的性能损耗，相对于局部线程池来说几乎可以忽略不计。</li>
</ul>
<h3 id="重试模式"><a href="#重试模式" class="headerlink" title="重试模式"></a>重试模式</h3><p>故障转移、故障恢复</p>
<p>重试模式应该满足以下几个前提条件：</p>
<ul>
<li>仅在主路逻辑的关键服务上进行同步的重试</li>
<li>对由瞬时故障导致的失败进行重试</li>
<li>仅对具备幂等性的服务进行重试</li>
<li>重试必须有明确的终止条件，常用的终止条件有两种，超时终止、次数终止</li>
</ul>
<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>一个健壮的系统需要做到恰当的流量控制，需要妥善解决以下三个问题：</p>
<ul>
<li>依据什么限流：要不要做，要做哪些，做到什么程度</li>
<li>具体如何限流：掌握常用的服务限流算法和设计模式</li>
<li>超额流量如何处理：否定式限流&#x2F;阻塞式限流</li>
</ul>
<h3 id="流量统计指标"><a href="#流量统计指标" class="headerlink" title="流量统计指标"></a>流量统计指标</h3><ul>
<li><strong>每秒事务数</strong>（Transactions per Second，TPS）：TPS是衡量信息系统吞吐量的最终标准。</li>
<li><strong>每秒请求数</strong>（Hits per Second，HPS）：HPS 是指每秒从客户端发向服务端的请求数。如果只要一个请求就能完成一笔业务，那 HPS 与 TPS 是等价的。</li>
<li><strong>每秒查询数</strong>（Queries per Second，QPS）：QPS 是指一台服务器能够响应的查询次数。如果只有一台服务器来应答请求，那 QPS 和 HPS 是等价的。</li>
</ul>
<p>主流系统大多倾向使用 HPS 作为首选的限流指标。但限流指标并不存在任何必须遵循的权威法则，根据系统的实际需要，哪怕完全不选择基于调用计数的指标都是有可能的。</p>
<h3 id="限流设计模式"><a href="#限流设计模式" class="headerlink" title="限流设计模式"></a>限流设计模式</h3><ul>
<li>流量计数器：设置一个计数器来进行限流，但是有问题，流量计数器的缺陷根源在于它只是针对时间点进行离散的统计。</li>
<li>滑动窗口算法：可以保证任意时间片段内，只需经过简单的调用计数比较，就能控制住请求次数一定不会超过限流的阈值，在单机限流或者分布式服务单点网关中的限流中很常用。<br>![[file-20250731055039601.png]]</li>
<li>漏桶模式：一个以请求对象作为元素的先入先出队列（FIFO Queue），队列长度就相当于漏桶的大小，当队列已满时便拒绝新的请求进入。漏桶实现起来很容易，困难在于如何确定漏桶的两个参数：桶的大小和水的流出速率。</li>
<li>令牌桶模式：漏桶是从水池里往系统出水，令牌桶则是系统往排队机中放入令牌。限制系统在 X 秒内最大请求次数不超过 Y，那就每间隔 X&#x2F;Y 时间就往桶中放一个令牌，当有请求进来时，首先要从桶中取得一个准入的令牌，然后才能进入系统处理。</li>
<li>分布式限流：前面都是单机限流，精细控制分布式集群中每个服务消耗量的限流算法称为分布式限流。核心差别在于如何管理限流的统计指标</li>
</ul>
<h2 id="可靠通讯"><a href="#可靠通讯" class="headerlink" title="可靠通讯"></a>可靠通讯</h2><h3 id="零信任网络"><a href="#零信任网络" class="headerlink" title="零信任网络"></a>零信任网络</h3><p>基于边界的安全模型：把网络划分为不同的区域，不同的区域对应于不同风险级别和允许访问的网络资源权限，将安全防护措施集中部署在各个区域的边界之上，重点关注跨区域的网络流量。</p>
<p>2010年提出了<strong>零信任安全模型</strong>的概念。<br>中心思想：不应当以某种固有特征来自动信任任何流量，除非明确得到了能代表请求来源（不一定是人，更可能是另一个服务）的身份凭证，否则一律不会有默认的信任关系。</p>
<table>
<thead>
<tr>
<th>传统、边界安全模型</th>
<th>云原生、零信任安全模型</th>
<th>具体需求</th>
</tr>
</thead>
<tbody><tr>
<td>基于防火墙等设施，认为边界内可信</td>
<td>服务到服务通信需认证，环境内的服务之间默认没有信任</td>
<td>保护网络边界（仍然有效）；服务之间默认没有互信</td>
</tr>
<tr>
<td>用于特定的 IP 和硬件（机器）</td>
<td>资源利用率、重用、共享更好，包括 IP 和硬件</td>
<td>受信任的机器运行来源已知的代码</td>
</tr>
<tr>
<td>基于 IP 的身份</td>
<td>基于服务的身份</td>
<td>同上</td>
</tr>
<tr>
<td>服务运行在已知的、可预期的服务器上</td>
<td>服务可运行在环境中的任何地方，包括私有云&#x2F;公有云混合部署</td>
<td>同上</td>
</tr>
<tr>
<td>安全相关的需求由应用来实现，每个应用单独实现</td>
<td>由基础设施来实现，基础设施中集成了共享的安全性要求。</td>
<td>集中策略实施点（Choke Points），一致地应用到所有服务</td>
</tr>
<tr>
<td>对服务如何构建、评审、实施的安全需求的约束力较弱</td>
<td>安全相关的需求一致地应用到所有服务</td>
<td>同上</td>
</tr>
<tr>
<td>安全组件的可观测性较弱</td>
<td>有安全策略及其是否生效的全局视图</td>
<td>同上</td>
</tr>
<tr>
<td>发布不标准，发布频率较低</td>
<td>标准化的构建和发布流程，每个微服务变更独立，变更更频繁</td>
<td>简单、自动、标准化的变更发布流程</td>
</tr>
<tr>
<td>工作负载通常作为虚拟机部署或部署到物理主机，并使用物理机或管理程序进行隔离</td>
<td>封装的工作负载及其进程在共享的操作系统中运行，并有管理平台提供的某种机制来进行隔离</td>
<td>在共享的操作系统的工作负载之间进行隔离</td>
</tr>
<tr>
<td>零信任网络的主要观点：</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>零信任网络不等同于放弃在边界上的保护设施</li>
<li>身份只来源于服务</li>
<li>服务之间也没有固有的信任关系</li>
<li>集中、共享的安全策略实施点</li>
</ul>
<p>如何构建零信任网络安全是一个非常大而且比较前沿的话题</p>
<h3 id="服务安全"><a href="#服务安全" class="headerlink" title="服务安全"></a>服务安全</h3><p>基于权威公证人（PKI）建立信任</p>
<ul>
<li><strong>单向 TLS 认证</strong>：只需要服务端提供证书，客户端通过服务端证书验证服务器的身份，但服务器并不验证客户端的身份。单向 TLS 用于公开的服务，即任何客户端都被允许连接到服务进行访问，它保护的重点是客户端免遭冒牌服务器的欺骗。</li>
<li><strong>双向 TLS 认证</strong>：客户端、服务端双方都要提供证书，双方各自通过对方提供的证书来验证对方的身份。双向 TLS 用于私密的服务，即服务只允许特定身份的客户端访问，它除了保护客户端不连接到冒牌服务器外，也保护服务端不遭到非法用户的越权访问。</li>
</ul>
<p>根据认证对象分为<strong>服务认证</strong>和<strong>请求认证</strong></p>
<ul>
<li>服务认证：Istio——mTLS认证；Spring Cloud—— OAuth 2</li>
<li>用户认证：Istio——JWKS；Spring Cloud——JWT</li>
</ul>
<p>授权：Istio——完备的工具；Spring Cloud——Spring Security</p>
<h2 id="可观测性"><a href="#可观测性" class="headerlink" title="可观测性"></a>可观测性</h2><p>可观测性可以分解为三个具体方向：事件日志、链路追踪、聚合度量<br>![[file-20250731092727827.png]]</p>
<ul>
<li><strong>日志</strong>：日志的职责是记录离散事件，通过这些记录事后分析出程序的行为，譬如曾经调用过什么方法，曾经操作过哪些数据，等等。</li>
<li><strong>追踪</strong>：单体系统时代追踪的范畴基本只局限于栈追踪，分布式系统中的追踪在国内常被称为“全链路追踪”，追踪的主要目的是排查故障，如分析调用链的哪一部分、哪个方法出现错误或阻塞，输入输出是否符合预期，等等。</li>
<li><strong>度量</strong>：度量是指对系统中某一类信息的统计聚合。</li>
</ul>
<p>工业界的情况：</p>
<ul>
<li><strong>日志</strong>：大多被统一到 Elastic Stack（ELK）技术栈上，如果说未来还能出现什么变化的话，也就是其中的 Logstash 能看到有被 Fluentd 取代的趋势，让 ELK 变成 EFK，但整套 Elastic Stack 技术栈的地位已是相当稳固。</li>
<li><strong>度量</strong>：Prometheus 也击败了度量领域里以 Zabbix 为代表的众多前辈，即将成为云原生时代度量监控的事实标准</li>
<li><strong>追踪</strong>：追踪是与具体网络协议、程序语言密切相关的，近年来各种链路追踪产品层出不穷，市面上主流的工具既有像 Datadog 这样的一揽子商业方案，也有 AWS X-Ray 和 Google Stackdriver Trace 这样的云计算厂商产品，还有像 SkyWalking、Zipkin、Jaeger 这样来自开源社区的优秀产品。</li>
</ul>
<h3 id="事件日志"><a href="#事件日志" class="headerlink" title="事件日志"></a>事件日志</h3><p>日志处理的过程<br>![[file-20250731095813194.jpg]]<br>以最成熟的 Elastic Stack 技术栈为例子，介绍该链条每个步骤的目的与方法。</p>
<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><p>日志中不应当出现的：<strong>避免打印敏感信息</strong>、<strong>避免引用慢操作</strong>、<strong>避免打印追踪诊断信息</strong>；应该要出现的：<strong>处理请求时的 TraceID</strong>、<strong>系统运行过程中的关键事件</strong>、<strong>启动时输出配置信息</strong>。</p>
<h4 id="收集与缓冲"><a href="#收集与缓冲" class="headerlink" title="收集与缓冲"></a>收集与缓冲</h4><p>最初，ELK 中日志收集与下一节要讲的加工聚合的职责都是由 Logstash 来承担的，但作为每个节点都要部署的日志收集器就显得太过负重了。后来，Elastic.co 公司将所有需要在服务节点中处理的工作整理成以Libbeat为核心的Beats 框架。</p>
<p>日志收集器不仅要保证能覆盖全部数据来源，还要尽力保证日志数据的连续性，这其实并不容易做到。</p>
<p>不必追求ELK与生产日志完全一致，只追求在代价可承受的范围内保证尽可能地保证较高的数据质量。一种最常用的缓解压力的做法是将日志接收者从 Logstash 和 Elasticsearch 转移至抗压能力更强的队列缓存，譬如在 Logstash 之前架设一个 Kafka 或者 Redis 作为缓冲层，面对突发流量，Logstash 或 Elasticsearch 处理能力出现瓶颈时自动削峰填谷，甚至当它们短时间停顿，也不会丢失日志数据。</p>
<h4 id="加工与聚合"><a href="#加工与聚合" class="headerlink" title="加工与聚合"></a>加工与聚合</h4><p>Logstash 的基本职能是把日志行中的非结构化数据，通过 Grok 表达式语法转换，以 JSON 格式输出到 Elasticsearch 中，Elasticsearch 便可针对不同的数据项来建立索引，进行条件查询、统计、聚合等操作的了。</p>
<h4 id="存储与查询"><a href="#存储与查询" class="headerlink" title="存储与查询"></a>存储与查询</h4><p>Elasticsearch 在日志分析这方面完全没有什么值得一提的竞争者，几乎就是解决此问题的唯一答案。</p>
<ul>
<li>从数据特征的角度看，日志是典型的基于时间的数据流，日志的数据特征决定了所有用于日志分析的 Elasticsearch 都会使用时间范围作为索引</li>
<li>从数据价值的角度看，日志基本上只会以最近的数据为检索目标，点决定了可以很容易区分出冷数据和热数据，进而对不同数据采用不一样的硬件策略。</li>
<li>从数据使用的角度看，分析日志很依赖全文检索和即席查询，对实时性的要求是处于实时与离线两者之间的“近实时”，也正好都是 Elasticsearch 的强项。</li>
</ul>
<p>Elasticsearch 只提供了 API 层面的查询能力，它通常搭配同样出自 Elastic.co 公司的 Kibana 一起使用，可以将 Kibana 视为 Elastic Stack 的 GUI 部分。</p>
<h3 id="链路追踪"><a href="#链路追踪" class="headerlink" title="链路追踪"></a>链路追踪</h3><p>广义上讲，一个完整的分布式追踪系统应该由数据收集、数据存储和数据展示三个相对独立的子系统构成，而狭义上讲的追踪则就只是特指链路追踪数据的收集部分。</p>
<h4 id="追踪与跨度"><a href="#追踪与跨度" class="headerlink" title="追踪与跨度"></a>追踪与跨度</h4><p>Dapper 提出了“追踪”与“跨度”两个概念：<br><strong>追踪</strong>：从客户端发起请求抵达系统的边界开始，记录请求流经的每一个服务，直到到向客户端返回响应为止，这整个过程就称为一次“追踪”<br><strong>跨度</strong>：由于每次 Trace 都可能会调用数量不定、坐标不定的多个服务，为了能够记录具体调用了哪些服务，以及调用的顺序、开始时点、执行时长等信息，每次开始调用服务前都要先埋入一个调用记录，这个记录称为一个“跨度”、</p>
<p>每一次 Trace 实际上都是由若干个有顺序、有层级关系的 Span 所组成一颗“追踪树”（Trace Tree）<br>![[file-20250731103715032.png]]<br>链路追踪面临的挑战：<strong>低性能损耗</strong>、<strong>对应用透明</strong>、<strong>随应用扩缩</strong>、<strong>持续的监控</strong></p>
<h4 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h4><p>追踪系统根据数据收集方式的差异，可分为三种主流的实现方式，分别是<strong>基于日志的追踪</strong>（Log-Based Tracing），<strong>基于服务的追踪</strong>（Service-Based Tracing）和<strong>基于边车代理的追踪</strong>（Sidecar-Based Tracing）：</p>
<ul>
<li>基于日志的追踪：将 Trace、Span 等信息直接输出到应用日志中，然后随着所有节点的日志归集过程汇聚到一起，再从全局日志信息中反推出完整的调用链拓扑关系。缺点是直接依赖于日志归集过程，代表产品是 Spring Cloud Sleuth</li>
<li>基于服务的追踪：通过某些手段给目标应用注入追踪探针（Probe），针对 Java 应用一般就是通过 Java Agent 注入的。探针在结构上可视为一个寄生在目标服务身上的小型微服务系统，它一般会有自己专用的服务注册、心跳检测等功能，有专门的数据收集协议，把从目标系统中监控得到的服务调用信息，通过另一次独立的 HTTP 或者 RPC 请求发送给追踪系统。消耗资源，侵入性强。目前服务追踪的其中一个发展趋势是轻量化，国产的 SkyWalking 正是这方面的佼佼者。</li>
<li>基于边车代理的追踪：服务网格的专属方案，它对应用完全透明，无论是日志还是服务本身都不会有任何变化；目前还不够普及。占有率最好的边车代理：Envoy</li>
</ul>
<h4 id="追踪规范化"><a href="#追踪规范化" class="headerlink" title="追踪规范化"></a>追踪规范化</h4><p>为了推进追踪领域的产品的标准化，2016 年 11 月，CNCF 技术委员会接受了 OpenTracing 作为基金会第三个项目。OpenTracing 是一套与平台无关、与厂商无关、与语言无关的追踪协议规范，只要遵循 OpenTracing 规范，任何公司的追踪探针、存储、界面都可以随时切换，也可以相互搭配使用。</p>
<p>OpenTracing 规范公布后，几乎所有业界有名的追踪系统，譬如 Zipkin、Jaeger、SkyWalking 等都很快宣布支持 OpenTracing，Google 自己却在此时出来表示反对，并提出了与 OpenTracing 目标类似的 OpenCensus 规范，随后又得到了巨头 Microsoft 的支持和参与。</p>
<p>OpenTracing 和 OpenCensus 迅速形成了可观测性的两大阵营，一边是在这方面深耕多年的众多老牌 APM 系统厂商，另一边是分布式追踪概念的提出者 Google，以及与 Google 同样庞大的 Microsoft。</p>
<p>2019年发布终极解决方案：OpenTelemetry，目前还不太成熟。</p>
<h3 id="聚合度量"><a href="#聚合度量" class="headerlink" title="聚合度量"></a>聚合度量</h3><p>度量（Metrics）的目的是揭示系统的总体运行状态。</p>
<p>度量总体上可分为客户端的指标收集、服务端的存储查询以及终端的监控预警三个相对独立的过程</p>
<h3 id="指标收集"><a href="#指标收集" class="headerlink" title="指标收集"></a>指标收集</h3><p>“如何定义指标”以及“如何将这些指标告诉服务端”</p>
<p>指标的数据类型可数：<strong>计数度量器</strong>、<strong>瞬态度量器</strong>、<strong>吞吐率度量器</strong>、<strong>直方图度量器</strong>、<strong>采样点分位图度量器</strong></p>
<p>告诉服务端的方式：<strong>拉取式采集</strong>、<strong>推送式采集</strong></p>
<p>![[file-20250731110627537.png]]</p>
<p>这是一个位于 Prometheus Server 外部的相对独立的中介模块，将外部推送来的指标放到 Push Gateway 中暂存，然后再等候 Prometheus Server 从 Push Gateway 中去拉取。Prometheus 设计 Push Gateway 的本意是为了解决 Pull 的一些固有缺陷，譬如目标系统位于内网，通过 NAT 访问外网，外网的 Prometheus 是无法主动连接目标系统的，这就只能由目标系统主动推送数据；又譬如某些小型短生命周期服务，可能还等不及 Prometheus 来拉取，服务就已经结束运行了，因此也只能由服务自己 Push 来保证度量的及时和准确。</p>
<p>Exporter 是 Prometheus 提出的概念，它是目标应用的代表，既可以独立运行，也可以与应用运行在同一个进程中，只要集成 Prometheus 的 Client Library 便可。Exporter 以 HTTP 协议返回符合 Prometheus 格式要求的文本数据给 Prometheus 服务器。</p>
<h3 id="存储查询"><a href="#存储查询" class="headerlink" title="存储查询"></a>存储查询</h3><p>时序数据库用于存储跟随时间而变化的数据，并且以时间（时间点或者时间区间）来建立索引的数据库。</p>
<p>Prometheus 服务端自己就内置了一个强大时序数据库实现，该时序数据库提供了名为 PromQL 的数据查询语言，能对时序数据进行丰富的查询、聚合以及逻辑运算。</p>
<h3 id="监控预警"><a href="#监控预警" class="headerlink" title="监控预警"></a>监控预警</h3><p>指标度量是手段，最终目的是做分析和预警。</p>
<p>在生产环境下，大多是 Prometheus 配合 Grafana 来进行展示的，这是 Prometheus 官方推荐的组合方案，但该组合也并非唯一选择，如果要搭配 Kibana 甚至 SkyWalking来使用也都是完全可行的。</p>
<p>Prometheus 提供了专门用于预警的 Alert Manager，将 Alert Manager 与 Prometheus 关联后，可以设置某个指标在多长时间内达到何种条件就会触发预警状态，触发预警后，根据路由中配置的接收器，譬如邮件接收器、Slack 接收器、微信接收器、或者更通用的WebHook接收器等来自动通知用户。</p>
<h1 id="不可变基础设施"><a href="#不可变基础设施" class="headerlink" title="不可变基础设施"></a>不可变基础设施</h1><h2 id="从微服务到云原生"><a href="#从微服务到云原生" class="headerlink" title="从微服务到云原生"></a>从微服务到云原生</h2><p>在云原生基金会定义的“云原生”概念中，“不可变基础设施”提升到了与微服务平级的重要程度，此时它的内涵已不再局限于方便运维、程序升级和部署的手段，而是升华为向应用代码隐藏分布式架构复杂度、让分布式架构得以成为一种可普遍推广的普适架构风格的必要前提。</p>
<h2 id="虚拟化容器"><a href="#虚拟化容器" class="headerlink" title="虚拟化容器"></a>虚拟化容器</h2><p>容器是云计算、微服务等诸多软件业界核心技术的共同基石，容器的首要目标是让软件分发部署过程从传统的发布安装包、靠人工部署转变为直接发布已经部署好的、包含整套运行环境的虚拟化镜像。</p>
<p>让软件能够在任何环境、任何物理机器上达到“一次编译，需要有以下三方面的兼容性来共同保障：</p>
<ul>
<li><strong>ISA 兼容</strong>：目标机器指令集兼容性，譬如 ARM 架构的计算机无法直接运行面向 x86 架构编译的程序</li>
<li><strong>ABI 兼容</strong>：目标系统或者依赖库的二进制兼容性，譬如 Windows 系统环境中无法直接运行 Linux 的程序，又譬如 DirectX 12 的游戏无法运行在 DirectX 9 之上</li>
<li><strong>环境兼容</strong>：目标环境的兼容性，譬如没有正确设置的配置文件、环境变量、注册中心、数据库地址、文件系统的权限等等，任何一个环境因素出现错误，都会让你的程序无法正常运行。</li>
</ul>
<p>解决以上三项兼容性问题的虚拟化技术分类：</p>
<ul>
<li><strong>指令集虚拟化</strong>：通过软件来模拟不同 ISA 架构的处理器工作过程，将虚拟机发出的指令转换为符合本机 ISA 的指令</li>
<li><strong>硬件抽象层虚拟化</strong>：以软件或者直接通过硬件来模拟处理器、芯片组、内存、磁盘控制器、显卡等设备的工作过程。</li>
<li><strong>操作系统层虚拟化</strong>：采用隔离手段，使得不同进程拥有独立的系统资源和资源配额，看起来仿佛是独享了整个操作系统一般，其实就是容器化</li>
<li><strong>运行库虚拟化</strong>：使用软件翻译的方法来模拟系统，它以一个独立进程来代替操作系统内核来提供目标软件运行所需的全部能力</li>
<li><strong>语言虚拟化</strong>：由虚拟机将高级语言生成的中间代码转换为目标机器可以直接执行的指令，代表为 Java 的 JVM 和.NET 的 CLR</li>
</ul>
<h3 id="容器的崛起"><a href="#容器的崛起" class="headerlink" title="容器的崛起"></a>容器的崛起</h3><p>以容器发展历史为线索，介绍容器技术在不同历史阶段中的主要关注点。</p>
<h4 id="隔离文件：chroot"><a href="#隔离文件：chroot" class="headerlink" title="隔离文件：chroot"></a>隔离文件：chroot</h4><p> 1979年，系统提供chroot命令，功能：当某个进程经过<code>chroot</code>操作之后，它的根目录就会被锁定在命令参数所指定的位置，以后它或者它的子进程将不能再访问和操作该目录之外的其他文件。<br> 1991年：第一个监控黑客行动的蜜罐程序就是使用<code>chroot</code>来实现的<br> 2000年：引入<code>pivot_root</code>技术来实现文件隔离<br> 时至今日，<code>chroot</code>命令依然活跃在 UNIX 系统与几乎所有主流的 Linux 发行版中，都并不能提供完美的隔离性。文件隔离性有限</p>
<h4 id="隔离访问：namespaces"><a href="#隔离访问：namespaces" class="headerlink" title="隔离访问：namespaces"></a>隔离访问：namespaces</h4><p>2002 年，Linux Kernel 2.4.19 版内核引入了一种全新的隔离机制：Linux 名称空间，一种由内核直接提供的全局资源封装，是内核针对进程设计的访问隔离机制。<br>最初的目的依然只是为了隔离文件系统，后来，要求系统隔离其他访问操作的呼声愈发强烈<br>2006年，内核陆续添加了 UTS、IPC 等名称空间隔离，直到目前最新的 Linux Kernel 5.6 版内核为止，Linux 名称空间支持八种资源的隔离</p>
<h4 id="隔离资源：cgroups"><a href="#隔离资源：cgroups" class="headerlink" title="隔离资源：cgroups"></a>隔离资源：cgroups</h4><p>cgroup：用于隔离或者说分配并限制某个进程组能够使用的资源配额，资源配额包括处理器时间、内存大小、磁盘 I&#x2F;O 速度，等等</p>
<h4 id="封装系统：LXC"><a href="#封装系统：LXC" class="headerlink" title="封装系统：LXC"></a>封装系统：LXC</h4><p>2008 年 Linux Kernel 2.6.24 内核刚刚开始提供cgroups的同一时间，就马上发布了名为Linux 容器<br>LXC 眼中的容器的定义与 OpenVZ 和 Linux-VServer 并无差别，是一种封装<code>系统</code>的轻量级虚拟机，而 Docker 眼中的容器的定义则是一种封装应用的技术手段。</p>
<h4 id="封装应用：Docker"><a href="#封装应用：Docker" class="headerlink" title="封装应用：Docker"></a>封装应用：Docker</h4><p>2013 年宣布开源的 Docker 毫无疑问是容器发展历史上里程碑式的发明，然而 Docker 的成功似乎没有太多技术驱动的成分。LXC是封装系统，Docker是封装应用。<br>2014 年，Docker 开源了自己用 Golang 开发的libcontainer，能直接与系统内核打交道，不必依赖 LXC 来提供容器化隔离能力了。<br>2015 年，在 Docker 的主导和倡议下，多家公司联合制定了“开放容器交互标准”（Open Container Initiative，OCI），这是一个关于容器格式和运行时的规范文件，其中包含运行时标准（runtime-spec ）、容器镜像标准（image-spec）和镜像分发标准（distribution-spec）<br>2016 年，Docker 把 containerd 捐献给了 CNCF 管理，runC 与 containerd 两个项目的捐赠托管，即带有 Docker 对开源信念的追求，也带有 Docker 在众多云计算大厂夹击下自救的无奈，这两个项目将成为未来 Docker 消亡和存续的伏笔</p>
<p>![[file-20250807190756431.png]]</p>
<h4 id="封装集群：Kubernetes"><a href="#封装集群：Kubernetes" class="headerlink" title="封装集群：Kubernetes"></a>封装集群：Kubernetes</h4><ul>
<li>以 Docker 为代表的容器引擎将软件的发布流程从分发二进制安装包转变为直接分发虚拟化后的整个运行环境，令应用得以实现跨机器的绿色部署；</li>
<li>以 Kubernetes 为代表的容器编排框架，就是把大型软件系统运行所依赖的集群环境也进行了虚拟化，令集群得以实现跨数据中心的绿色部署，并能够根据实际情况自动扩缩。</li>
</ul>
<p>2015 年 7 月，Kubernetes 发布了第一个正式版本 1.0 版，更重要的事件是 Google 宣布与 Linux 基金会共同筹建云原生基金会（Cloud Native Computing Foundation，CNCF），并且将 Kubernetes 托管到 CNCF，成为其第一个项目。随后，Kubernetes 以摧枯拉朽之势覆灭了容器编排领域的其他竞争对手</p>
<p>![[file-20250807191420768.png]]2016 年，Kubernetes 1.5 版本开始引入“容器运行时接口”（Container Runtime Interface，CRI），这是一个定义容器运行时应该如何接入到 kubelet 的规范标准。<br>2017 年，由 Google、RedHat、Intel、SUSE、IBM 联合发起的CRI-O（Container Runtime Interface Orchestrator）项目发布了首个正式版本。<br>2018 年，由 Docker 捐献给 CNCF 的 containerd，在 CNCF 的精心孵化下发布了 1.1 版，1.1 版与 1.0 版的最大区别是此时它已完美地支持了 CRI 标准，这意味着原本用作 CRI 适配器的 cri-containerd 从此不再需要。</p>
<h3 id="以容器构建系统"><a href="#以容器构建系统" class="headerlink" title="以容器构建系统"></a>以容器构建系统</h3><p>分布式系统里应用的概念已不再等同于进程，此时的应用需要多个进程共同协作，通过集群的形式对外提供服务，以虚拟化方法实现这个目标的过程就被称为容器编排。</p>
<h4 id="隔离与协作"><a href="#隔离与协作" class="headerlink" title="隔离与协作"></a>隔离与协作</h4><p>从k8s设计的实现意图出发了解k8s</p>
<p>Kubernetes 时代的 Pod 整合了 Borg 时代的“Prod”（Production Task 的缩写）与“Non-Prod”的职能。</p>
<ol>
<li>两个应用封装在一个容器——违背了 Docker 提倡的单个容器封装单进程应用的最佳实践。</li>
<li>两个应用封装在两个容器，通过共享空间交换数据——同一个进程组中的多个进程天然就可以共享着相同的访问权限与资源配额，要找到进程组，即Pod。Pod默认共享UTS 、网络、IPC等名称空间，Pod 还要实现原子性调度</li>
<li>容器都运行在一个节点上——要协同调度，Pod 是隔离与调度的基本单位</li>
</ol>
<p>![[file-20250807193153146.png]]</p>
<p>K8s关键资源概念</p>
<ul>
<li><strong>容器</strong>（Container）：延续了自 Docker 以来一个容器封装一个应用进程的理念，是镜像管理的最小单位。</li>
<li><strong>生产任务</strong>（Pod）：补充了容器化后缺失的与进程组对应的“容器组”的概念，Pod 中容器共享 UTS、IPC、网络等名称空间，是资源调度的最小单位。</li>
<li><strong>节点</strong>（Node）：对应于集群中的单台机器，这里的机器即可以是生产环境中的物理机，也可以是云计算环境中的虚拟节点，节点是处理器和内存等资源的资源池，是硬件单元的最小单位。</li>
<li><strong>集群</strong>（Cluster）：对应于整个集群，Kubernetes 提倡理念是面向集群来管理应用。当你要部署应用的时候，只需要通过声明式 API 将你的意图写成一份元数据（Manifests），将它提交给集群即可，而无需关心它具体分配到哪个节点（尽管通过标签选择器完全可以控制它分配到哪个节点，但一般不需要这样做）、如何实现 Pod 间通信、如何保证韧性与弹性，等等，所以集群是处理元数据的最小单位。</li>
<li><strong>集群联邦</strong>（Federation）：对应于多个集群，通过联邦可以统一管理多个 Kubernetes 集群，联邦的一种常见应用是支持跨可用区域多活、跨地域容灾的需求</li>
</ul>
<h4 id="韧性与弹性"><a href="#韧性与弹性" class="headerlink" title="韧性与弹性"></a>韧性与弹性</h4><p>作为用户，当然最希望容器编排系统能自动把所有意外因素都消灭掉，让任何每一个服务都永远健康，永不出错。但永不出错的服务是不切实际的，那就只能退而求其次，让编排系统在这些服务出现问题，运行状态不正确的时候，能自动将它们调整成正确的状态</p>
<p>将这种控制回路的思想迁移应用到容器编排上，自然会为 Kubernetes 中的资源附加上了期望状态与实际状态两项属性。</p>
<p>与资源相对应，只要是实际状态有可能发生变化的资源对象，通常都会由对应的控制器进行追踪，每个控制器至少会追踪一种类型的资源。</p>
<p>如果你希望改变某个资源的某种状态，应该将期望状态告诉 Kubernetes，而不是去教 Kubernetes 具体该如何操作。</p>
<p>故障恢复、滚动更新、自动扩缩这些特性，在云原生中时代里常被概括成服务的弹性（Elasticity）与韧性（Resilience），ReplicaSet、Deployment、Autoscaling 的用法，也属于是所有 Kubernetes 教材资料都会讲到的“基础必修课”。</p>
<h3 id="以应用为中心的封装"><a href="#以应用为中心的封装" class="headerlink" title="以应用为中心的封装"></a>以应用为中心的封装</h3><p>Kubernetes 被誉为云原生时代的操作系统，但是，从易用角度讲，坦白说差距还非常大，云原生基础设施的其中一个重要目标是接管掉业务系统复杂的非功能特性，让业务研发与运维工作变得足够简单，不受分布式的牵绊，然而 Kubernetes 被诟病得最多的就是复杂，自诞生之日起就以陡峭的学习曲线而闻名。</p>
<p>定义“以应用为中心的封装”，有以下几种思路：</p>
<ul>
<li>Kustomize：“用配置文件来配置配置文件”，根据环境来生成不同的部署配置。只要建立多个 Kustomization 文件，开发人员就能以基于基准进行派生（Base and Overlay）的方式，对不同的模式（譬如生产模式、调试模式）、不同的项目（同一个产品对不同客户的客制化）定制出不同的资源整合包。</li>
<li>Helm 与 Chart：模仿 Linux 包管理器的思路去管理 Kubernetes 应用，Helm 无法很好地管理这种有状态的依赖关系</li>
<li>Operator 与 CRD：一种封装、部署和管理 Kubernetes 应用的方法，尤其是针对最复杂的有状态应用去封装运维能力的解决方案，Operator 是如何解决那些 StatefulSet 覆盖不到的有状态服务管理需求的</li>
<li>开放应用模型：由一组相互关联但又离散独立的组件构成，这些组件实例化在合适的运行时上，由配置来控制行为并共同协作提供统一的功能，开发人员负责管理 Component；运维人员将 Component 组合并绑定 Trait 变成 Application Configuration；平台人员或基础设施提供方负责提供 OAM 的解释能力</li>
</ul>
<h2 id="容器间网络"><a href="#容器间网络" class="headerlink" title="容器间网络"></a>容器间网络</h2><p>本节特指“基于 Linux 系统的网络虚拟化技术来实现的容器间网络通信”</p>
<h3 id="Linux-网络虚拟化"><a href="#Linux-网络虚拟化" class="headerlink" title="Linux 网络虚拟化"></a>Linux 网络虚拟化</h3><h4 id="网络通信模型"><a href="#网络通信模型" class="headerlink" title="网络通信模型"></a>网络通信模型</h4><p>OSI 七层模型——&gt; TCP&#x2F;IP 四层模型![[file-20250808100735641.png]]<br>网络传输的阶段：</p>
<ul>
<li><strong>Socket</strong>：应用层的程序是通过 Socket 编程接口来和内核空间的网络协议栈通信的。</li>
<li><strong>TCP&#x2F;UDP</strong>：传输层协议族里最重要的协议无疑是传输控制协议（Transmission Control Protocol，TCP）和用户数据报协议（User Datagram Protocol，UDP）两种</li>
<li><strong>IP</strong>：网络层协议最主要就是网际协议（Internet Protocol，IP），其他还有因特网组管理协议（Internet Group Management Protocol，IGMP）</li>
<li><strong>Device</strong>：网络设备（Device）是网络访问层中面向系统一侧的接口</li>
<li><strong>Driver</strong>：网卡驱动程序（Driver）是网络访问层中面向硬件一侧的接口</li>
</ul>
<h4 id="干预网络通信"><a href="#干预网络通信" class="headerlink" title="干预网络通信"></a>干预网络通信</h4><p> Linux Kernel 2.4 版开始，内核开放了一套通用的、可供代码干预数据在协议栈中流转的过滤器框架。</p>
<p>围绕网络层（IP 协议）的周围，埋下了五个钩子（Hooks），每当有数据包流到网络层，经过这些钩子时，就会自动触发由内核模块注册在这里的回调函数，程序代码就能够通过回调来干预 Linux 的网络通信。</p>
<p>![[file-20250808102611840.png]]<br>Netfilter 允许在同一个钩子处注册多个回调函数，因此向钩子注册回调函数时必须提供明确的优先级，以便触发时能按照优先级从高到低进行激活。</p>
<p>以 Netfilter 为基础的应用有很多，其中使用最广泛的毫无疑问要数 Xtables 系列工具，譬如iptables、ebtables、arptables、ip6tables 等等</p>
<p>iptables 不仅仅是 Linux 系统自带的一个网络工具，它在容器间通信中扮演相当重要的角色，譬如 Kubernetes 用来管理 Service 的 Endpoints 的核心组件 kube-proxy，就依赖 iptables 来完成 ClusterIP 到 Pod 的通信，这种通信的本质就是一种 NAT 访问</p>
<h4 id="虚拟化网络设备"><a href="#虚拟化网络设备" class="headerlink" title="虚拟化网络设备"></a>虚拟化网络设备</h4><p>目前主流的虚拟网卡方案有tun&#x2F;tap和veth两种：</p>
<ul>
<li><strong>tun&#x2F;tap</strong>： 在时间上 tun&#x2F;tap 出现得更早，它是一组通用的虚拟驱动程序包，里面包含了两个设备，分别是用于网络数据包处理的虚拟网卡驱动，以及用于内核空间与用户空间交互的字符设备（Character Devices，这里具体指&#x2F;dev&#x2F;net&#x2F;tun）驱动。 tun&#x2F;tap 方案比起 veth 方案有更广泛的适用范围。![[file-20250808104458086.png]]</li>
<li>供了专门的虚拟以太网（Virtual Ethernet，习惯简写做 veth）让两个隔离的网络名称空间之间可以互相通信。直接把 veth 比喻成是虚拟网卡其实并不十分准确，如果要和物理设备类比，它应该相当于由交叉网线连接的一对物理网卡。它是一对设备，对多个容器间通信，如果仍然单纯只用 veth pair 的话，事情就会变得非常麻烦，让每个容器都为与它通信的其他容器建立一对专用的 veth pair 并不实际，这时就迫切需要有一台虚拟化的交换机来解决多容器之间的通信问题了![[file-20250808104452797.png]]</li>
</ul>
<p>既然有了虚拟网卡，很自然也会联想到让网卡接入到交换机里，实现多个容器间的相互连接。Linux Bridge便是 Linux 系统下的虚拟化交换机</p>
<p> Linux Bridge 与普通交换机的区别是除了显式接入的设备外，它自己也无可分割地连接着一台有着完整网络协议栈的 Linux 主机，因为 Linux Bridge 本身肯定是在某台 Linux 主机上创建的，可以看作 Linux Bridge 有一个与自己名字相同的隐藏端口，隐式地连接了创建它的那台 Linux 主机。因此，Linux Bridge 允许给自己设置 IP 地址，比普通交换机多出一种特殊的转发情况。<br> Linux Bridge 构建单 IP 容器网络<br> ![[file-20250808104956285.png]]</p>
<p>下一步就是要使用这些设备组成网络，容器分布在不同的物理主机上，每一台物理主机都有物理网络相互联通</p>
<p>SDN（Software Defined Network，SDN） 里位于下层的物理网络被称为 Underlay，它着重解决网络的连通性与可管理性，位于上层的逻辑网络被称为 Overlay，它着重为应用提供与软件需求相符的传输服务和网络拓扑。由于跨主机的容器间通信，用的大多是 Overlay 网络，以 VXLAN 为例去介绍 Overlay 网络的原理。</p>
<p>VLAN的缺陷：</p>
<ul>
<li>VLAN ID 最多只能有 212&#x3D;4096 种取值。当云计算数据中心出现后，即使不考虑虚拟化的需求，单是需要分配 IP 的物理设备都有可能数以万计甚至数以十万计，这样 4096 个 VLAN 肯定是不够用的。（出新规范）</li>
<li>VLAN 本身是为二层网络所设计的，但是在两个独立数据中心之间，信息只能够通过三层网络传递（定义了 VXLAN 规范）</li>
</ul>
<p>VXLAN：原本在二层传输的以太帧放到四层 UDP 协议的报文体内，同时加入了自己定义的 VXLAN Header，VLAN ID可以存储 1677 万个不同的取值，让二层网络得以在三层范围内进行扩展，不再受数据中心间传输的限制。</p>
<p>从 Linux Kernel 3.7 版本起，Linux 系统就开始支持 VXLAN。到了 3.12 版本，Linux 对 VXLAN 的支持已达到完全完备的程度，能够处理单播和组播，能够运行于 IPv4 和 IPv6 之上，一台 Linux 主机经过简单配置之后，便可以把 Linux Bridge 作为 VTEP 设备使用。不过，VXLAN 也带来了额外的复杂度和性能开销，传输、性能效率的下降。</p>
<p>MACVLAN 借用了 VLAN 子接口的思路，并且在这个基础上更进一步，不仅允许对同一个网卡设置多个 IP 地址，还允许对同一张网卡上设置多个 MAC 地址，这也是 MACVLAN 名字的由来。<br>![[file-20250808184541113.png]]<br>用 MACVLAN 技术虚拟出来的副本网卡，在功能上和真实的网卡是完全对等的，此时真正的物理网卡实际上确实承担着类似交换机的职责，收到数据包后，根据目标 MAC 地址判断这个包应转发给哪块副本网卡处理，由同一块物理网卡虚拟出来的副本网卡，天然处于同一个 VLAN 之中，可以直接二层通信，不需要将流量转发到外部网络。</p>
<p>Docker 的网络方案在操作层面上是指能够直接通过<code>docker run --network</code>参数指定的网络，或者先<code>docker network create</code>创建后再被容器使用的网络。安装 Docker 过程中会自动在宿主机上创建一个名为 docker0 的网桥，以及三种不同的 Docker 网络，分别是 bridge、host 和 none，对应着 Docker 提供的三种开箱即用的网络方案。</p>
<h3 id="容器网络与生态"><a href="#容器网络与生态" class="headerlink" title="容器网络与生态"></a>容器网络与生态</h3><h4 id="CNM-与-CNI"><a href="#CNM-与-CNI" class="headerlink" title="CNM 与 CNI"></a>CNM 与 CNI</h4><p>容器网络的事实标准CNI（Container Networking Interface）</p>
<p>从程序功能上看，CNM 和 CNI 的网络插件提供的能力都能划分为网络的管理与 IP 地址的管理两类，插件可以选择只实现其中的某一个，也可以全部都实现，包括<strong>管理网络创建与删除</strong>、<strong>管理 IP 地址分配与回收</strong>。</p>
<h4 id="CNM-到-CNI"><a href="#CNM-到-CNI" class="headerlink" title="CNM 到 CNI"></a>CNM 到 CNI</h4><p>Kubernetes与 CoreOS 合作以 RKT 网络提案为基础发展出 CNI 规范。CNI的成功史</p>
<h4 id="网络插件生态"><a href="#网络插件生态" class="headerlink" title="网络插件生态"></a>网络插件生态</h4><p>跨主机通信的网络实现方式有如下三种模式：</p>
<ul>
<li><strong>Overlay 模式</strong>：一种虚拟化的上层逻辑网络，好处在于它不受底层物理网络结构的约束，有更大的自由度，更好的易用性；坏处是由于额外的包头封装导致信息密度降低，额外的隧道封包解包会导致传输性能下降。</li>
<li><strong>路由模式</strong>：路由模式其实属于 Underlay 模式的一种特例，这里将它单独作为一种网络实现模式来介绍。相比起 Overlay 网络，路由模式的主要区别在于它的跨主机通信是直接通过路由转发来实现的，因而无须在不同主机之间进行隧道封包。这种模式的好处是性能相比 Overlay 网络有明显提升，坏处是路由转发要依赖于底层网络环境的支持</li>
<li><strong>Underlay 模式</strong>：这里的 Underlay 模式特指让容器和宿主机处于同一网络，两者拥有相同的地位的网络方案。Underlay 网络要求容器的网络接口能够直接与底层网络进行通信，因此该模式是直接依赖于虚拟化设备与底层网络能力的。</li>
</ul>
<h2 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h2><h3 id="Kubernetes-存储设计"><a href="#Kubernetes-存储设计" class="headerlink" title="Kubernetes 存储设计"></a>Kubernetes 存储设计</h3><p>Kubernetes 预置了很多 In-Tree插件来对接，让用户根据自己业务按需选择。</p>
<h4 id="Mount-和-Volume"><a href="#Mount-和-Volume" class="headerlink" title="Mount 和 Volume"></a>Mount 和 Volume</h4><ul>
<li>Mount 是动词，表示将某个外部存储挂载到系统中</li>
<li>Volume 是名词，表示物理存储的逻辑抽象，目的是为物理存储提供有弹性的分割方式</li>
</ul>
<p>Docker 内建支持了三种挂载类型，分别是 Bind（<code>--mount type=bind</code>）、Volume（<code>--mount type=volume</code>）和 tmpfs（<code>--mount type=tmpfs</code>），只着重关注 Bind 和 Volume 两种挂载类型<br>![[file-20250809141518216.png]]</p>
<ul>
<li>Bind Mount：把宿主机的某个目录（或文件）挂载到容器的指定目录（或文件）下，Bind Mount 只能让容器与本地宿主机之间建立了某个目录的映射，如果想要在不同宿主机上的容器共享同一份存储，就必须先把共享存储挂载到每一台宿主机操作系统的某个目录下，然后才能逐个挂载到容器内使用<br>![[file-20250809141657730.png]]、</li>
<li>Volume Mount：为了提升 Docker 对不同存储介质的支撑能力，提出了与 Storage Driver 相对应的 Volume Driver（卷驱动）的概念。用户可以通过docker plugin install命令安装外部的卷驱动，并在创建 Volume 时指定一个与其存储系统相匹配的卷驱动</li>
</ul>
<h4 id="静态存储分配"><a href="#静态存储分配" class="headerlink" title="静态存储分配"></a>静态存储分配</h4><p>Kubernetes 将 Volume 分为持久化的 PersistentVolume 和非持久化的普通 Volume 两类![[file-20250809142049107.png]]</p>
<ul>
<li>普通 Volume：同一个 Pod 中多个容器提供可共享的存储资源，因此 Volume 具有十分明确的生命周期——与挂载它的 Pod 相同的生命周期，这意味着尽管普通 Volume 不具备持久化的存储能力，但至少比 Pod 中运行的任何容器的存活期都更长，Pod 中不同的容器能共享相同的普通 Volume，当容器重新启动时，普通 Volume 中的数据也会能够得到保留。</li>
<li>持久化Volumn：可以独立于 Pod 存在，生命周期与 Pod 无关，因此也决定了 PersistentVolume 不应该依附于任何一个宿主机节点，PersistentVolume 是由管理员（运维人员）负责维护的，用户（开发人员）通过 PersistentVolumeClaim 来匹配到合乎需求的 PersistentVolume。![[file-20250809142542596.png]]</li>
</ul>
<h4 id="动态存储分配"><a href="#动态存储分配" class="headerlink" title="动态存储分配"></a>动态存储分配</h4><p>一旦应用规模增大，PersistentVolume 很难被自动化的问题就会突显出来。<br>动态存储分配：指在用户声明存储能力的需求时，不是期望通过 Kubernetes 撮合来获得一个管理员人工预置的 PersistentVolume，而是由特定的资源分配器（Provisioner）自动地在存储资源池或者云存储系统中分配符合用户存储需要的 PersistentVolume，然后挂载到 Pod 中使用，完成这项工作的资源被命名为 StorageClass<br>![[file-20250809142941504.png]]</p>
<h3 id="容器存储与生态"><a href="#容器存储与生态" class="headerlink" title="容器存储与生态"></a>容器存储与生态</h3><h4 id="Kubernetes-存储架构"><a href="#Kubernetes-存储架构" class="headerlink" title="Kubernetes 存储架构"></a>Kubernetes 存储架构</h4><p>Kubernetes 参考了传统操作系统接入或移除新存储设备做法，把接入或移除外部存储这件事情分解为以下三种操作：</p>
<ul>
<li><strong>准备</strong>（Provision）：确定了接入存储的来源、容量、性能以及其他技术参数，它的逆操作是<strong>移除</strong>（Delete）存储。</li>
<li><strong>附加</strong>（Attach）：确定了存储的设备名称、驱动方式等面向系统一侧的信息，它的逆操作是<strong>分离</strong>（Detach）存储设备。</li>
<li><strong>挂载</strong>（Mount）：存储的访问目录、文件系统格式等面向应用一侧的信息，它的逆操作是<strong>卸载</strong>（Unmount）存储设备。</li>
</ul>
<p>六种操作分别被 Kubernetes 通过两个控制器及一个管理器来进行调用，这些控制器、管理器的作用分别是：</p>
<ul>
<li><strong>PV 控制器</strong>（PersistentVolume Controller）：PV 控制器的期望状态有两个，分别是“所有未绑定的 PersistentVolume 都能处于可用状态”以及“所有处于等待状态的 PersistentVolumeClaim 都能配对到与之绑定的 PersistentVolume”</li>
<li><strong>AD 控制器</strong>（Attach&#x2F;Detach Controller）：AD 控制器的期望状态是“所有被调度到准备新创建 Pod 的节点，都附加好了要使用的存储；当 Pod 被销毁后，原本运行 Pod 的节点都分离了不再被使用的存储”，如果实际状态不符合该期望，会根据需要调用存储驱动插件的 Attach&#x2F;Detach 操作。</li>
<li><strong>Volume 管理器</strong>（Volume Manager）：用来支持本节点中 Volume 执行 Attach&#x2F;Detach&#x2F;Mount&#x2F;Unmount 操作。<br>![[file-20250809143905280.png]]</li>
</ul>
<h4 id="FlexVolume-与-CSI"><a href="#FlexVolume-与-CSI" class="headerlink" title="FlexVolume 与 CSI"></a>FlexVolume 与 CSI</h4><p>Kubernetes 目前同时支持FlexVolume与CSI（Container Storage Interface）两套独立的存储扩展机制。</p>
<ul>
<li>FlexVolume是 Kubernetes 很早期版本（1.2 版开始提供，1.8 版达到 GA 状态）就开始支持的扩展机制，它是只针对 Kubernetes 的私有的存储扩展，目前已经处于冻结状态，可以正常使用但不再发展新功能了。</li>
<li>CSI 是公开的技术规范，任何容器运行时、容器编排引擎只要愿意支持，都可以使用 CSI 规范去扩展自己的存储能力，这是目前 Kubernetes 重点发展的扩展机制。</li>
</ul>
<h4 id="容器插件生态"><a href="#容器插件生态" class="headerlink" title="容器插件生态"></a>容器插件生态</h4><p>目前出现过的存储系统和设备均可以划分到块存储、文件存储和对象存储这三种存储类型之中，划分依据是各种存储提供何种形式的接口供外部访问数据，不同的外部访问接口将反过来影响到存储的内部结构、性能与功能表现。</p>
<ul>
<li><p><strong>块存储</strong>：块存储是数据存储的最古老形式，数据都储存在固定长度的一个或多个块（Block）中，想要读写访问数据，就必须使用与存储相匹配的协议，硬盘就是最经典的块存储设备。块存储由于贴近底层硬件，没有文件、目录、访问权限等的牵绊，所以性能通常都是最优秀的，吞吐量高，延迟低。</p>
</li>
<li><p><strong>文件存储</strong>：文件存储是最贴近人类用户的数据存储形式，数据存储在长度不固定的文件之中，用户可以针对文件进行新增、写入、追加、移动、复制、删除、重命名等各种操作，POSIX接口（Portable Operating System Interface，POSIX）已经成为了事实标准，被各种商用的存储系统和操作系统共同支持。绝大多数传统的文件存储都是基于块存储之上去实现的。人们把定义文件分配表应该如何实现、储存哪些信息、提供什么功能的标准称为文件系统（File System），FAT32、NTFS、exFAT、ext2&#x2F;3&#x2F;4、XFS、BTRFS 等都是很常用的文件系统。对于性能有影响</p>
</li>
<li><p><strong>对象储存</strong>：对象存储是相对较新的数据存储形式，是一种随着云数据中心的兴起而发展起来的存储，是以非结构化数据为目标的存储方案。“对象”可以理解为一个元数据及与其配对的一个逻辑数据块的组合，元数据提供了对象所包含的上下文信息，譬如数据的类型、大小、权限、创建人、创建时间，等等，数据块则存储了对象的具体内容。对象存储基本上只会在分布式存储系统之上去实现，由于对象存储天生就有明确的“元数据”概念，不必依靠文件系统来提供数据的描述信息，由于对象的元数据仅描述对象本身的信息，与其他对象都没有关联，换而言之每个对象都是相互独立的，自然也就不存在目录的概念，可见对象存储天然就是扁平化的。由于对象存储天生的分布式特性，以及极其低廉的扩展成本，使它很适合于<a target="_blank" rel="noopener" href="https://icyfenix.cn/architect-perspective/general-architecture/diversion-system/cdn.html">CDN</a>一类的应用，拿来存放图片、音视频等媒体内容，以及网页、脚本等静态资源。</p>
</li>
</ul>
<h2 id="资源与调度"><a href="#资源与调度" class="headerlink" title="资源与调度"></a>资源与调度</h2><p><strong>调度</strong>：是指为新创建出来的 Pod 寻找到一个最恰当的宿主机节点来运行它，这个过程成功与否、结果恰当与否，关键取决于容器编排系统是如何管理与分配集群节点的资源的。</p>
<h3 id="资源模型"><a href="#资源模型" class="headerlink" title="资源模型"></a>资源模型</h3><p>“一切皆为资源”的设计是 Kubernetes 能够顺利施行声明式 API 的必要前提，Kubernetes 以资源为载体，建立了一套同时囊括了抽象元素（如策略、依赖、权限）和物理元素（如软件、硬件、网络）的领域特定语言。</p>
<p>从编排系统的角度来看，Node 是资源的提供者，Pod 是资源的使用者，调度是将两者进行恰当的撮合。</p>
<p>Node 通常能够提供的三方面的资源：计算资源（如处理器、图形处理器、内存）、存储资源（如磁盘容量、不同类型的介质）和网络资源（如带宽、网络地址）</p>
<p>处理器这样的资源被称作可压缩资源（Compressible Resources），特点是当可压缩资源不足时，Pod 只会处于“饥饿状态”，运行变慢，但不会被系统杀死；内存这样的资源，则被称作不可压缩资源（Incompressible Resources），特点是当不可压缩资源不足，或者超过了容器自己声明的最大限度时，Pod 就会因为内存溢出（Out-Of-Memory，OOM）而被系统直接杀掉。</p>
<p>Kubernetes 只负责保证 Pod 能够使用到“一个处理器”的计算能力，对不同硬件环境构成的 Kubernetes 集群，乃至同一个集群中不同硬件的宿主机节点来说，“一个处理器”所代表的真实算力完全有可能是不一样的。</p>
<h3 id="服务质量与优先级"><a href="#服务质量与优先级" class="headerlink" title="服务质量与优先级"></a>服务质量与优先级</h3><p>Pod 是由一到多个容器所组成，资源最终是交由 Pod 的各个容器去使用，所以资源的需求是设定在容器上的，具体的配置是 Pod 的<code>spec.containers[].resource.limits/requests.cpu/memory</code>字段。</p>
<p>资源需求的配额则不是针对容器的，而是针对 Pod 整体，Pod 的资源配额无需手动设置，它就是它包含的每个容器资源需求的累加值。</p>
<p>注意到 Kubernetes 给出的配置中有<code>limits</code>和<code>requests</code>两个设置项：</p>
<ul>
<li><code>requests</code>是给调度器用的，Kubernetes 选择哪个节点运行 Pod，只会根据<code>requests</code>的值来进行决策</li>
<li><code>limits</code>才是给 cgroups 用的，Kubernetes 在向 cgroups 的传递资源配额时，会按照<code>limits</code>的值来进行设置。</li>
</ul>
<p>经验法则：用户提交工作负载时设置的资源配额，并不是容器调度一定必须严格遵守的值，因为根据实际经验，大多数的工作负载运行过程中真正使用到的资源，其实都远小于它所请求的资源配额。</p>
<p><strong>驱逐机制</strong>：要进行驱逐，首先 Kubernetes 就必须拿出资源不足时该先牺牲哪些 Pod、该保留哪些 Pod 的明确准则，由此就形成了 Kubernetes 的<strong>服务质量等级</strong>（Quality of Service Level，QoS Level）和<strong>优先级</strong>（Priority）的概念</p>
<p>Kubernetes 目前提供的服务质量等级一共分为三级，由高到低分别为 Guaranteed、Burstable 和 BestEffort。</p>
<ul>
<li>Guaranteed：如果 Pod 中所有的容器都设置了<code>limits</code>和<code>requests</code>，且两者的值相等，那此 Pod 的服务质量等级便为最高的 Guaranteed；建议将数据库应用等有状态的应用，或者一些重要的要保证不能中断的业务的服务质量等级定为 Guaranteed</li>
<li>Burstable：如果 Pod 中有部分容器的 requests 值小于<code>limits</code>值，或者只设置了<code>requests</code>而未设置<code>limits</code>，那此 Pod 的服务质量等级为第二级 Burstable；</li>
<li>BestEffort：如果不去设置<code>limits</code>和<code>requests</code>，就是最低的 BestEffort 了。</li>
</ul>
<p>Kubernetes 允许系统管理员自行决定 Pod 的优先级，这是通过类型为 PriorityClass 的资源来实现的。优先级影响更大的另一方面是指 Kubernetes 的<strong>抢占机制</strong>。如果有一个被设置了明确优先级的 Pod 调度失败无法创建的话，Kubernetes 就会在系统中寻找出一批牺牲者（Victims），将它们杀掉以便给更高优先级的 Pod 让出资源。寻找的原则是根据在优先级低于待调度 Pod 的所有已调度 Pod 里，按照优先级从低到高排序，从最低的杀起，直至腾出的资源足以满足待调度 Pod 的成功调度为止，或者已经找不到更低优先级的 Pod 为止。</p>
<h4 id="驱逐机制"><a href="#驱逐机制" class="headerlink" title="驱逐机制"></a>驱逐机制</h4><p>Pod 的驱逐机制是通过 kubelet 来执行的，kubelet 是部署在每个节点的集群管理程序，由于本身就运行在节点中，所以最容易感知到节点的资源实时耗用情况。kubelet 一旦发现某种不可压缩资源将要耗尽，就会主动终止节点上较低服务质量等级的 Pod，以保证其他更重要的 Pod 的安全。被驱逐的 Pod 中所有的容器都会被终止，Pod 的状态会被更改为 Failed。</p>
<p>驱逐行为不等同于垃圾收集器。垃圾收集是安全的内存回收行为，而驱逐 Pod 是一种毁坏性的清理行为，有可能会导致服务产生中断，必须更加谨慎。</p>
<p>驱逐机制中就有了<strong>软驱逐</strong>（Soft Eviction）、<strong>硬驱逐</strong>（Hard Eviction）以及<strong>优雅退出期</strong>（Grace Period）的概念：</p>
<ul>
<li><strong>软驱逐</strong>：通常配置一个较低的警戒线（譬如可用内存仅剩 20%），触及此线时，系统将进入一段观察期。如果只是暂时的资源抖动，在观察期内能够恢复到正常水平的话，那就不会真正启动驱逐操作。</li>
<li><strong>硬驱逐</strong>：通常配置一个较高的终止线（譬如可用内存仅剩 10%），一旦触及此红线，立即强制杀掉 Pod，不理会优雅退出。</li>
</ul>
<h3 id="默认调度器"><a href="#默认调度器" class="headerlink" title="默认调度器"></a>默认调度器</h3><p>Kubernetes 是如何撮合 Pod 与 Node 的，调度是为新创建出来的 Pod 寻找到一个最恰当的宿主机节点去运行它。</p>
<ul>
<li>运行：从集群所有节点中找出一批剩余资源可以满足该 Pod 运行的节点。为此，Kubernetes 调度器设计了一组名为 Predicate 的筛选算法。</li>
<li>恰当：从符合运行要求的节点中找出一个最适合的节点完成调度。为此，Kubernetes 调度器设计了一组名为 Priority 的评价算法。</li>
</ul>
<h2 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h2><blockquote>
<p>服务网格是一种用于管控服务间通信的的基础设施，职责是为现代云原生应用支持网络请求在复杂的拓扑环境中可靠地传递。在实践中，服务网格通常会以轻量化网络代理的形式来体现，这些代理与应用程序代码会部署在一起，对应用程序来说，它完全不会感知到代理的存在。</p>
</blockquote>
<p><strong>服务网格</strong>：只是一种处理程序间通信的基础设施，典型的存在形式是部署在应用旁边，一对一为应用提供服务的边车代理，及管理这些边车代理的控制程序。</p>
<h3 id="透明通信的涅槃"><a href="#透明通信的涅槃" class="headerlink" title="透明通信的涅槃"></a>透明通信的涅槃</h3><h4 id="通信的成本-1"><a href="#通信的成本-1" class="headerlink" title="通信的成本"></a>通信的成本</h4><p>如何做到可靠的通信的，通过以下五个阶段的变化，理解分布式服务的通信是如何逐步演化成本章主角服务网格</p>
<ol>
<li>将通信的非功能性需求视作业务需求的一部分，通信的可靠性由程序员来保障。<br>![[file-20250811105702722.png]]</li>
<li>将代码中的通信功能抽离重构成公共组件库，通信的可靠性由专业的平台程序员来保障。<br>![[file-20250811105750990.png]]</li>
<li>将负责通信的公共组件库分离到进程之外，程序间通过网络代理来交互，通信的可靠性由专门的网络代理提供商来保障。<br>![[file-20250811105826841.png]]</li>
<li>将网络代理以边车的形式注入到应用容器，自动劫持应用的网络流量，通信的可靠性由专门的通信基础设施来保障。<br>![[file-20250811105955427.png]]</li>
<li>将边车代理统一管控起来实现安全、可控、可观测的通信，将数据平面与控制平面分离开来，实现通用、透明的通信，这项工作就由专门的服务网格框架来保障。<br>![[file-20250811110038854.png]]</li>
</ol>
<h4 id="数据平面"><a href="#数据平面" class="headerlink" title="数据平面"></a>数据平面</h4><p>数据平面由一系列边车代理所构成，核心职责是转发应用的入站（Inbound）和出站（Outbound）数据包，因此数据平面也有个别名叫转发平面（Forwarding Plane）。同时，为了在不可靠的物理网络中保证程序间通信最大的可靠性，数据平面必须根据控制平面下发策略的指导，在应用无感知的情况下自动完成服务路由、健康检查、负载均衡、认证鉴权、产生监控数据等一系列工作。为了达成上述的工作目标，至少需要妥善解决以下三个关键问题：</p>
<ul>
<li>代理注入：边车代理是如何注入到应用程序中的？</li>
<li>流量劫持：边车代理是如何劫持应用程序的通信流量的？</li>
<li>可靠通信：边车代理是如何保证应用程序的通信可靠性的？</li>
</ul>
<h4 id="控制平面"><a href="#控制平面" class="headerlink" title="控制平面"></a>控制平面</h4><p>控制平面的特点是不直接参与程序间通信，而只会与数据平面中的代理通信，在程序不可见的背后，默默地完成下发配置和策略，指导数据平面工作。</p>
<h3 id="服务网格与生态"><a href="#服务网格与生态" class="headerlink" title="服务网格与生态"></a>服务网格与生态</h3><p>服务网格实质上是数据平面产品与控制平面产品的集合，所以在规范制订方面，很自然地也分成了两类：SMI 规范提供了外部环境（实际上就是 Kubernetes）与控制平面交互的标准，使得 Kubernetes 及在其之上的应用能够无缝地切换各种服务网格产品。UDPA 规范则提供了控制平面与数据平面交互的标准，使得服务网格产品能够灵活地搭配不同的边车代理，针对不同场景的需求，发挥各款边车代理的功能或者性能优势。</p>
<p>![[file-20250811111217042.png]]</p>
<h4 id="服务网格接口"><a href="#服务网格接口" class="headerlink" title="服务网格接口"></a>服务网格接口</h4><p> SMI 规范包括四方面的 API 构成，分别是：<br> - <strong>流量规范</strong>（Traffic Specs）：目标是定义流量的表示方式，譬如 TCP 流量、HTTP&#x2F;1 流量、HTTP&#x2F;2 流量、gRPC 流量、WebSocket 流量等该如何在配置中抽象及使用。<br> - <strong>流量拆分</strong>（Traffic Split）：目标是定义不同版本服务之间的流量比例，提供流量治理的能力，譬如限流、降级、容错，等等，以满足灰度发布、A&#x2F;B 测试等场景。<br> - <strong>流量度量</strong>（Traffic Metrics）：目标是为资源提供通用集成点，度量工具可以通过访问这些集成点来抓取指标。<br> - <strong>流量访问控制</strong>（Traffic Access Control）：目标是根据客户端的身份配置，对特定的流量访问特定的服务提供简单的访问控制。</p>
<h4 id="通用数据平面-API"><a href="#通用数据平面-API" class="headerlink" title="通用数据平面 API"></a>通用数据平面 API</h4><p>UDAP 的主要内容会分为传输协议（UDPA-TP，TransPort）和数据模型（UDPA-DM，Data Model）两部分，这两部分是独立设计的，以后完全有可能会出现不同的数据模型共用同一套传输协议的可能性</p>
<h1 id="向微服务迈进"><a href="#向微服务迈进" class="headerlink" title="向微服务迈进"></a>向微服务迈进</h1><p>“<strong>软件研发中任何一项技术、方法、架构都不可能是银弹</strong>”</p>
<h2 id="目的：微服务的驱动力"><a href="#目的：微服务的驱动力" class="headerlink" title="目的：微服务的驱动力"></a>目的：微服务的驱动力</h2><p>软件系统选择微服务架构，通常比较常见的、合理的驱动力来自组织外部、内部两方面，笔者先列举一些外部因素：</p>
<ul>
<li>当意识到没有什么技术能够包打天下。</li>
<li>当个人能力因素成为系统发展的明显制约。</li>
<li>当遇到来自外部商业层面对内部技术层面提出的要求。</li>
</ul>
<p>在系统和研发团队内部，也会有一些因素促使其向微服务靠拢：</p>
<ul>
<li>变化发展特别快的创新业务系统往往会自主地向微服务架构靠近。</li>
<li>大规模的、业务复杂的、历史包袱沉重的系统也可能主动向微服务架构靠近。</li>
</ul>
<p>微服务最主要的目的是对系统进行有效的拆分，实现物理层面的隔离，微服务的核心价值就是拆分之后的系统能够让局部的单个服务<strong>有可能</strong>实现敏捷地卸载、部署、开发、升级，局部的持续更迭，是系统整体具备 Phoenix 特性的必要条件。</p>
<h2 id="前提：微服务需要的条件"><a href="#前提：微服务需要的条件" class="headerlink" title="前提：微服务需要的条件"></a>前提：微服务需要的条件</h2><ul>
<li>决策者与执行者都能意识到康威定律在软件设计中的关键作用。</li>
<li>组织中具备一些对微服务有充分理解、有一定实践经验的技术专家。</li>
<li>系统应具有以自治为目标的自动化与监控度量能力。</li>
<li>复杂性已经成为制约生产力的主要矛盾。</li>
</ul>
<h2 id="边界：微服务的粒度"><a href="#边界：微服务的粒度" class="headerlink" title="边界：微服务的粒度"></a>边界：微服务的粒度</h2><p>微服务边界具体实践的方法论，即领域驱动设计。</p>
<p><strong>微服务粒度的下界是它至少应满足独立——能够独立发布、独立部署、独立运行与独立测试，内聚——强相关的功能与数据在同一个服务中处理，完备——一个服务包含至少一项业务实体与对应的完整操作。</strong></p>
<p><strong>微服务粒度的上界是一个 2 Pizza Team 能够在一个研发周期内完成的全部需求范围。</strong></p>
<h2 id="治理：理解系统复杂性"><a href="#治理：理解系统复杂性" class="headerlink" title="治理：理解系统复杂性"></a>治理：理解系统复杂性</h2><p><strong>软件规模小时微服务的复杂度高于单体系统，规模大时则相反</strong>。</p>
<p>演进式设计是 ThoughtWorks 提出的架构方法，无论是代际的演进还是渐进的演进，都带有不少争议，它不仅是建造的学问，也是破坏的学问。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%87%A4%E5%87%B0%E9%A1%B9%E7%9B%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E5%87%A4%E5%87%B0%E9%A1%B9%E7%9B%AE/" class="post-title-link" itemprop="url">凤凰项目</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E6%B4%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E6%B4%BE/" class="post-title-link" itemprop="url">分布式系统实战派</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%89%91%E6%8C%87Java%E9%9D%A2%E8%AF%95-Offer%E7%9B%B4%E9%80%9A%E8%BD%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E5%89%91%E6%8C%87Java%E9%9D%A2%E8%AF%95-Offer%E7%9B%B4%E9%80%9A%E8%BD%A6/" class="post-title-link" itemprop="url">剑指Java面试-Offer直通车</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>.</p>
<h2 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h2><p>OSI开放式互联参考模型<br>物理层：物理设备标准、传输比特流（网卡）<br>数据链路层：数据帧（交换机）<br>网络层：网络间传输、数据包（路由器）<br>传输层：数据间的传输质量，流量控制，TCP&#x2F;UDP<br>会话层：建立管理应用程序的通讯<br>表示层：不同系统的会话问题<br>应用层：应用层的网络协议 HTTP协议</p>
<p>TCP&#x2F;IP 4层模型<br>链路层（数据链路层、物理层）<br>网络层<br>传输层<br>应用层（应用层、表示层、会话层）</p>
<h3 id="说说TCP的三次握手"><a href="#说说TCP的三次握手" class="headerlink" title="说说TCP的三次握手"></a>说说TCP的三次握手</h3><p>TCP<br>面向连接的、可靠的、基于字节流的传输层通信协议<br>将应用层的数据流分割成报文段并发送给目标节点的TCP层<br>数据包都有序号，对方收到则发送ACK确认，未收到则重传<br>使用校验和来检验数据在传输过程中是否有误</p>
<p>源端口、目的端口、序列号、ACK、Offset、窗口、校验和、保留域<br>常见标志位：<br>URG：紧急指针标志<br>ACK：确认序号标志<br>PSH：push编制<br>Syn：同步序号，用于建立连接<br>FIN：完成标志，用于释放连接<br>![[Pasted image 20250607123944.png]]第一次：发Syn包<br>第二次：确认Syn，自己也发一个Syn<br>第三次：收到SYN、ACK，发从ACK<br>为什么需要三次握手才能建立联系<br>为了初始化Seq的初始值</p>
<p>首次握手的隐患——SYN超时<br>linux会重试5次，大概63s才会断开连接<br>针对SYN Flood的防护参数<br>SYN满了之后，通过tcp_syncookies会发SYN cookie<br>若为正常连接则Client会回发Syn Cookie，直接建立连接</p>
<p>保活机制</p>
<h3 id="TCP的四次挥手"><a href="#TCP的四次挥手" class="headerlink" title="TCP的四次挥手"></a>TCP的四次挥手</h3><p>![[Pasted image 20250607125925.png]]<br>第一次挥手：发一个FIN<br>第二次挥手：收到后，发一个ACK，确认序号为seq+1，进入CLosewait状态<br>第三次挥手：Server发一个Fin，Server进入Last ACK状态<br>第四次挥手：CLient收到Fin后，进入TIME Wait状态，发送一个ACK给Server，Server进入Closed状态</p>
<p>为什么会有TIME_WAIT状态<br>确保有足够的时候让对方收到ACK包<br>避免新旧连接混淆<br>为什么需要四次挥手才能断开连接<br>因为全双工，发送方和接受方都需要FIN、ACK</p>
<p>服务器出现大量的Close Wait状态的原因<br>对方关闭socket连接，我方忙于读或写，没有及时关闭连接<br>检查代码、检查配置</p>
<h3 id="UDP简介"><a href="#UDP简介" class="headerlink" title="UDP简介"></a>UDP简介</h3><p>面向非连接<br>不维护连接状态，支持同时向多个客户端传输相同的消息<br>数据包只有8歌个字节<br>吞吐量受限于生成速率等</p>
<p>对比：<br>面向连接 vs 无连接<br>可靠性<br>有序性<br>速度<br>量级</p>
<h3 id="TCP的滑动窗口"><a href="#TCP的滑动窗口" class="headerlink" title="TCP的滑动窗口"></a>TCP的滑动窗口</h3><p>RTT：发送一个数据包到收回对应的ACK，所花费的时间<br>RTO：重传时间间隔</p>
<p>TCP使用滑动窗口做流量控制和乱序重排，保证它的可靠性和流控特性</p>
<h3 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h3><p>超文本传输协议：<br>支持客户服务器模式<br>简单快速<br>灵活<br>无连接<br>无状态</p>
<p>请求报文、响应报文</p>
<p>键入URL后，经历的流程<br>DNS解析&#x2F;TCP连接&#x2F;发送HTTP请求&#x2F;处理请求返回报文&#x2F;解析页面&#x2F;连接结束</p>
<p>HTTP状态码<br>1xx 已接受，继续处理<br>200正常&#x2F;<br>2xx 重定向<br>404 客户端错误 资源不在，400请求有语法错误，403拒绝服务<br>500 服务端错误<br>503 当前不能处理请求<br> Get请求和POST的区别<br>HTTP报文层面：get请求信息放在URL，post在报文体里<br>数据库层面：GET符合幂等和安全（查询操作），POST不安全（会提交数据）<br>其他层面：GET可以被缓存、被存储，而POST不行</p>
<p>Cookie和Session的区别<br>Cookie：服务器发给客户端的特殊信息，以文本的形式存放在客户端<br>客户端再次请求是，会把Cookie回发<br>Session：服务器端的机制，再服务器上保存的信息，解析客户端请求并处理session id，按需保存状态信息，可以使用Cookie实现&#x2F;使用url回写<br>Session更加安全，但可能影响性能</p>
<p>HTTP和HTTPS的区别</p>
<p>加入了SSL or TLS层<br>SSL（安全套接层）3.0被称为TLS<br>采用身份验证和数据加密保证网络通信的安全和数据的完整性</p>
<p>加密的方式：<br>对称：加密解密使用同一个密钥<br>非对称：密钥不同<br>哈希算法<br>数字签名</p>
<p> HTTPS数据传输流程：<br> 浏览器加支持的算法发给服务器；<br> 服务选一套算法，以证书回发给浏览器<br> 浏览器验证证书合法性，结合公钥加密发给服务器<br> 服务器使用私钥解析，验证哈希<br> 浏览器解析响应消息<br>HTTPS需要到申请CA证书<br>HTTPS密文传输<br>联系方式不同，HTTPS 443端口</p>
<p>HTTPS&#x3D; HTTP+加密+认证+完整性</p>
<p>浏览器默认http，可以使用HST优化</p>
<h3 id="Socket简介"><a href="#Socket简介" class="headerlink" title="Socket简介"></a>Socket简介</h3><p>Socket是TCP&#x2F;IP的抽象，是操作系统对外开放的接口<br>Socket通信流程<br>![[Pasted image 20250607134147.png]]</p>
<h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><p>关系型数据库（架构、索引、锁、语法、理论范式）<br>如何设计一个关系型数据库<br>存储模块、程序实例（存储管理、缓存机制、SQL解析、日志管理、权限划分、容灾机制、索引、锁）</p>
<h3 id="索引模块"><a href="#索引模块" class="headerlink" title="索引模块"></a>索引模块</h3><p>为什么用索引<br>快速查询数据<br>什么样可以是索引<br>主键、唯一键、普通键<br>索引的数据结构<br>生成索引，二叉树、B+、B-、Hash<br> 二叉查找树上阵<br> O(logn)<br> 1、时间复杂度可能会提高 O(n)<br> 2、两个节点，树可能很高<br>B-Tree平衡多路查找树<br>定义：根节点至少有两个孩子<br>树中每个节点最多有m个孩子（m&gt;&#x3D;2）<br>除根节点和叶节点外，其他每个节点至少有ceil（m&#x2F;2）个孩子<br>所有叶子节点都位于同一层<br>还有一个关键信息<br>![[Pasted image 20250607200533.png]]</p>
<p>树会变矮，不会成为线性</p>
<p>B+-Tree平衡多路查找树<br>定义与B树类似，除了：</p>
<p>![[Pasted image 20250607200958.png]]<br>![[Pasted image 20250607200942.png]]</p>
<p>B+ 更适合用来做存储索引<br>1、读写代价更低<br>2、查询效率更加稳定<br>3、更有利于对数据库的扫描</p>
<p>Hash索引也可以考虑以下<br>![[Pasted image 20250607201218.png]]<br>效率很高，但有缺点：<br>不能进行范围查询<br>无法被用来避免数据的排序操作<br>不能利用部分索引查询<br>不能避免表扫描<br>遇到大量Hash相等的情况性能不一定比B树高</p>
<p>BitMap索引<br>很少支持，结构类似于B+树，不适合高并发</p>
<p>密集索引和稀疏索引？<br>![[Pasted image 20250607201707.png]]<br>![[Pasted image 20250607201734.png]]</p>
<p> MyISAM：稀疏索引<br> InnoDB：密集索引<br> ![[Pasted image 20250607201851.png]]</p>
<p>如何定位并优化慢查询SQL<br>![[Pasted image 20250607202537.png]]<br>联合索引的最左匹配原则的成因</p>
<p>一直向右匹配，知道遇到 &gt; &lt; between like这样的就停止匹配，等于的顺序可以乱序，因为mysql会进行优化。按照字段逐个排序</p>
<p>索引是建立得越来越好吗</p>
<ul>
<li>数据量小的表不需要建立索引，会有额外开销</li>
<li>数据变更需要维护索引，有更多的维护成本</li>
<li>更多的索引也意味着更多的空间</li>
</ul>
<h3 id="锁模块"><a href="#锁模块" class="headerlink" title="锁模块"></a>锁模块</h3><p>MyISAM和InnoDB在锁方面的区别是什么？</p>
<p>MyISAM是表级锁，不支持行级锁<br>InnoDB是行级锁，也支持表级锁</p>
<p>读锁——共享锁<br>写锁——排他锁</p>
<p>innodb不走索引的时候整张表就会被锁住，走索引才是行级锁</p>
<p>![[file-20250622134139306.png]]<br>![[file-20250622134206654.png]]</p>
<p>![[file-20250622134303188.png]]</p>
<p>数据库事务的四大特性，ACID</p>
<p>脏读：读到未提交的数据<br>不可重复读：多次读到的数据不一样<br>幻读：读到了没见过的数据，插入操作<br>![[file-20250622151211284.png]]</p>
<p>InnoDB可重复读隔离级别下如何实现避免幻读</p>
<p>![[file-20250622152303503.png]]</p>
<p>![[file-20250622152427760.png]]![[file-20250622152435383.png]]</p>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><p>![[file-20250624215706781.png]]</p>
<p>![[file-20250624215736074.png]]</p>
<p>![[file-20250624215750833.png]]</p>
<p>10w QPS</p>
<ul>
<li>完全基于内存，纯粹的内存操作，执行效率高</li>
<li>数据结构简单</li>
<li>单线程，能处理高并发</li>
<li>多路IO复用模型，非阻塞IO</li>
</ul>
<p>![[file-20250624220210313.png]]</p>
<p>Redis的数据类型<br>![[file-20250624224823463.png]]</p>
<p>如何从海量key中查询固定前缀的key</p>
<p>![[file-20250624225259856.png]]<br>![[file-20250624225509767.png]]</p>
<p>如何通过Redis实现分布式锁<br>解决互斥性、安全性、死锁、容错性的问题<br>![[file-20250624225835785.png]]</p>
<p>![[file-20250624230017809.png]]</p>
<p>![[file-20250625205509814.png]]</p>
<p>![[file-20250625205616252.png]]</p>
<p>![[file-20250625205645775.png]]</p>
<p>消息发布无状态，无法保证可达</p>
<p>Redis如何做持久和<br>![[file-20250625210059433.png]]![[file-20250625210304655.png]]</p>
<p>![[file-20250625210421684.png]]![[file-20250625210548743.png]]</p>
<p>AOF持久化，保存写状态</p>
<ul>
<li>记录查询以外的指令</li>
<li>append追加到AOF<br>日志重写解决文件会不断变大，原理：<br>![[file-20250625210937122.png]]</li>
</ul>
<p>![[file-20250625211039662.png]]<br>![[file-20250625211156825.png]]<br>![[file-20250625211320630.png]]</p>
<p>Redis 的主从同步过程</p>
<p>![[file-20250625211520796.png]]</p>
<p>![[file-20250625213233103.png]]</p>
<p>![[file-20250625213344249.png]]</p>
<p>![[file-20250625213434462.png]]</p>
<p>![[file-20250625213549619.png]]一致性哈希</p>
<p>![[file-20250625213735373.png]]</p>
<p>![[file-20250625213844592.png]]</p>
<p>引入虚拟节点</p>
<p>![[file-20250625213918097.png]]</p>
<h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><p>Compile Once，Run Anywhere如何实现：</p>
<p>![[1751465589386.png]]</p>
<p>JVM如何加载.class文件</p>
<p>![[1751465887848.png]]</p>
<p>谈谈反射<br>![[1751465980543.png]]</p>
<p>常用的反馈函数：<br>Class.forName</p>
<p>类从编译到执行的过程<br>![[1751466975191.png]]![[1751467621253.png]]</p>
<p>类加载器的双亲委派机制</p>
<p>![[file-20250703205429747.png]]</p>
<p>![[file-20250703210009484.png]]</p>
<p>类的加载方式</p>
<ul>
<li>隐式加载：new</li>
<li>显示加载：loadClass、forName<br>显示加载两种方式的区别：<br>![[file-20250703210227720.png]]</li>
</ul>
<p>![[file-20250703210326967.png]]</p>
<p>Java的内存模型<br>![[file-20250703210822160.png]]<br>![[file-20250703210934595.png]]<br>![[file-20250703211002249.png]]<br>![[file-20250703211030197.png]]</p>
<p>![[file-20250703211456135.png]]</p>
<p>![[file-20250703211538414.png]]</p>
<p>![[file-20250703211737647.png]]</p>
<p>![[file-20250703211819474.png]]</p>
<p>![[file-20250703211945387.png]]</p>
<p>![[file-20250703212047411.png]]</p>
<p>![[file-20250703212146099.png]]</p>
<p>![[file-20250703212232530.png]]<br>![[file-20250703212345342.png]]</p>
<p>![[file-20250703212603306.png]]</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E7%9F%A5%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E7%9F%A5%E5%BD%95/" class="post-title-link" itemprop="url">大数据日知录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%83%BD%E5%8A%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%83%BD%E5%8A%9B/" class="post-title-link" itemprop="url">大数据组件数据同步能力</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>.</p>
<h3 id="同步能力视图总览"><a href="#同步能力视图总览" class="headerlink" title="同步能力视图总览"></a>同步能力视图总览</h3><table>
<thead>
<tr>
<th>组件</th>
<th>用途</th>
<th>是否涉及数据</th>
<th>是否容灾关键因素</th>
</tr>
</thead>
<tbody><tr>
<td>yarn</td>
<td>资源管理</td>
<td>不涉及</td>
<td>非</td>
</tr>
<tr>
<td>zookeeper</td>
<td>协同管理</td>
<td>不涉及</td>
<td>非</td>
</tr>
<tr>
<td>kerberos</td>
<td>安全认证</td>
<td>不涉及</td>
<td>非</td>
</tr>
<tr>
<td>Ranger</td>
<td>权限认证</td>
<td>权限policy数据</td>
<td>是</td>
</tr>
<tr>
<td>Kafka</td>
<td>实时数据传输</td>
<td>主题分区数据</td>
<td>是</td>
</tr>
<tr>
<td>Loader</td>
<td>数据加载</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Flume</td>
<td>日志采集</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDFS</td>
<td>文件管理</td>
<td>所有hadoop数据</td>
<td>是</td>
</tr>
<tr>
<td>hudi</td>
<td>湖格式</td>
<td>否（在HDFS层完成）</td>
<td>否</td>
</tr>
<tr>
<td>Alluxio</td>
<td>缓存数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>MemartsCC</td>
<td>缓存数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mapreduce</td>
<td>批量计算框架</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>Spark</td>
<td>批量数据加工</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>Flink</td>
<td>实时数据加工</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>Hive</td>
<td>HQL服务</td>
<td>元数据</td>
<td>是</td>
</tr>
<tr>
<td>Phoenix</td>
<td>HBase二级索引</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>HetuEngine</td>
<td>交互式分析</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>ElasticSearch</td>
<td>检索引擎</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>Clickhouse</td>
<td>实时数据接入实时查询</td>
<td>是</td>
<td>是</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>组件</th>
<th>同步工具</th>
<th>同步原理</th>
<th>时效性</th>
<th>是否支持异步</th>
<th>触发方式</th>
<th>一致性评估</th>
<th>适用场景</th>
<th>特性</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>DistCp</td>
<td>生成MapReduce任务传输数据</td>
<td>批量</td>
<td>是</td>
<td>一过性任务</td>
<td>最终一致性</td>
<td>HDFS—&gt;HDFS</td>
<td>文件拷贝，支持增全量拷贝</td>
</tr>
<tr>
<td>HBase</td>
<td>Replication</td>
<td>主备集群分别启动ReplicationSource、ReplicationSink线程进行数据传输</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>HBase—&gt;HBase</td>
<td>WAL拷贝，支持增全量拷贝</td>
</tr>
<tr>
<td>Kafka</td>
<td>MirrorMaker</td>
<td>从源集群中消费消息，然后将消息发送到目标集群中</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>Kafka—&gt;Kafka</td>
<td>消息传输</td>
</tr>
<tr>
<td>ElasticSearch</td>
<td>CCR</td>
<td>批量拉取主集群变更记录并行写入备集群,备集群拉取</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>ElasticSearch—&gt;ElasticSearch</td>
<td>变更索引拷贝</td>
</tr>
<tr>
<td>Hive</td>
<td>DistCp</td>
<td>hive数据表通过distcp同步，元数据通过dump或者数据库的同步能力完成</td>
<td>批量</td>
<td>是</td>
<td>一过性任务</td>
<td>最终一致性</td>
<td>Hive—&gt;Hive</td>
<td>数据库同步能力</td>
</tr>
<tr>
<td>Clickhouse</td>
<td>ReplicatedMergeTree</td>
<td>通过ReplicatedMergeTree引擎（Replicated 系列引擎）实现了副本机制</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>Clickhouse—&gt;Clickhouse</td>
<td>表副本机制</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="一、HDFS组件"><a href="#一、HDFS组件" class="headerlink" title="一、HDFS组件"></a>一、HDFS组件</h3><h4 id="DistCp-分布式拷贝"><a href="#DistCp-分布式拷贝" class="headerlink" title="DistCp 分布式拷贝"></a>DistCp 分布式拷贝</h4><h5 id="1、定义："><a href="#1、定义：" class="headerlink" title="1、定义："></a><strong>1、定义</strong>：</h5><p><strong>DistCp</strong>（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。 它使用Map&#x2F;Reduce实现文件分发，错误处理和恢复，以及报告生成。 它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝。 由于使用了Map&#x2F;Reduce方法，这个工具在语义和执行上都会有特殊的地方。<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html">^1</a></p>
<h5 id="2、同步原理："><a href="#2、同步原理：" class="headerlink" title="2、同步原理："></a><strong>2、同步原理</strong>：</h5><p>distcp 命令通过提交 mapreduce 程序在 map 阶段进⾏数据传输，基于 block 流读⼀次写⼀次⼤幅度提升拷贝速度。<a target="_blank" rel="noopener" href="https://yampery.github.io/2019/01/29/distcp/">^3</a><br>![[Pasted image 20250317185307.png]]</p>
<h5 id="3、适用场景："><a href="#3、适用场景：" class="headerlink" title="3、适用场景："></a><strong>3、适用场景</strong>：</h5><p>Hadoop集群之间，同步HDFS层的数据</p>
<h5 id="4、常用指令："><a href="#4、常用指令：" class="headerlink" title="4、常用指令："></a><strong>4、常用指令</strong>：</h5><p>（1） 集群间拷贝</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash$ hadoop distcp hdfs://nn1:8020/foo/bar hdfs://nn2:8020/bar/foo</span><br></pre></td></tr></table></figure>
<p>执行过程：这条命令会把nn1集群的&#x2F;foo&#x2F;bar目录下的所有文件或目录名展开并存储到一个临时文件中，这些文件内容的拷贝工作被分配给多个map任务， 然后每个TaskTracker分别执行从nn1到nn2的拷贝操作。注意DistCp使用绝对路径进行操作。<br>（2）指定多个原集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bash$ hadoop distcp hdfs://nn1:8020/foo/a \  </span><br><span class="line">                    hdfs://nn1:8020/foo/b \  </span><br><span class="line">                    hdfs://nn2:8020/bar/foo</span><br></pre></td></tr></table></figure>
<p>执行过程：指定需拷贝的多个源集群地址。注：当从多个源拷贝时，如果两个源冲突，DistCp会停止拷贝并提示出错信息， 如果在目的位置发生冲突，会根据<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html#options">选项设置</a>解决。</p>
<h5 id="5、可选参数"><a href="#5、可选参数" class="headerlink" title="5、可选参数"></a><strong>5、可选参数</strong></h5><table>
<thead>
<tr>
<th>标识</th>
<th>描述</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-p[rbugp]</td>
<td>Preserve  <br>  r: replication<br>number  <br>  b: block size  <br>  u: user  <br>  g: group  <br>  p: permission</td>
<td>修改次数不会被保留。并且当指定 -update 时，更新的状态<strong>不</strong>会 被同步，除非文件大小不同（比如文件被重新创建）。</td>
</tr>
<tr>
<td>-i</td>
<td>忽略失败</td>
<td>这个选项会比默认情况提供关于拷贝的更精确的统计， 同时它还将保留失败拷贝操作的日志，这些日志信息可以用于调试。最后，如果一个map失败了，但并没完成所有分块任务的尝试，这不会导致整个作业的失败。</td>
</tr>
<tr>
<td>-log <logdir></td>
<td>记录日志到 <logdir></td>
<td>DistCp为每个文件的每次尝试拷贝操作都记录日志，并把日志作为map的输出。 如果一个map失败了，当重新执行时这个日志不会被保留。</td>
</tr>
<tr>
<td>-m <num_maps></td>
<td>同时拷贝的最大数目</td>
<td>指定了拷贝数据时map的数目。请注意并不是map数越多吞吐量越大。</td>
</tr>
<tr>
<td>-overwrite</td>
<td>覆盖目标</td>
<td>如果一个map失败并且没有使用-i选项，不仅仅那些拷贝失败的文件，这个分块任务中的所有文件都会被重新拷贝。 就像下面提到的，它会改变生成目标路径的语义，所以 用户要小心使用这个选项</td>
</tr>
<tr>
<td>-update</td>
<td>如果源和目标的大小不一样则进行覆盖</td>
<td>像之前提到的，这不是”同步”操作。 执行覆盖的唯一标准是源文件和目标文件大小是否相同；如果不同，则源文件替换目标文件。</td>
</tr>
<tr>
<td>-f <urilist_uri></td>
<td>使用<urilist_uri> 作为源文件列表</td>
<td>这等价于把所有文件名列在命令行中。 urilist_uri 列表应该是完整合法的URI。</td>
</tr>
</tbody></table>
<h5 id="6、附录"><a href="#6、附录" class="headerlink" title="6、附录"></a><strong>6、附录</strong></h5><p>（1）Map数目<br>DistCp会尝试着均分需要拷贝的内容，这样每个map拷贝差不多相等大小的内容。 但因为文件是最小的拷贝粒度，所以配置增加同时拷贝（如map）的数目不一定会增加实际同时拷贝的数目以及总吞吐量。<br>如果没使用-m选项，DistCp会尝试在调度工作时指定map的数目 为 min (total_bytes &#x2F; bytes.per.map, 20 * num_task_trackers)， 其中bytes.per.map默认是256MB。<br>建议对于长时间运行或定期运行的作业，根据源和目标集群大小、拷贝数量大小以及带宽调整map的数目。<br>（2）不同HDFS版本间的拷贝<br>对于不同Hadoop版本间的拷贝，用户应该使用HftpFileSystem。 这是一个只读文件系统，所以DistCp必须运行在目标端集群上（更确切的说是在能够写入目标集群的TaskTracker上）。<br>（3）Map&#x2F;Reduce和副效应<br>像前面提到的，map拷贝输入文件失败时，会带来一些副效应。</p>
<ul>
<li>除非使用了-i，任务产生的日志会被新的尝试替换掉。</li>
<li>除非使用了-overwrite，文件被之前的map成功拷贝后当又一次执行拷贝时会被标记为 “被忽略”。</li>
<li>如果map失败了mapred.map.max.attempts次，剩下的map任务会被终止（除非使用了-i)。</li>
<li>如果mapred.speculative.execution被设置为 final和true，则拷贝的结果是未定义的。</li>
</ul>
<hr>
<h3 id="二、HBase组件"><a href="#二、HBase组件" class="headerlink" title="二、HBase组件"></a>二、HBase组件</h3><h4 id="Replication-分布式拷贝"><a href="#Replication-分布式拷贝" class="headerlink" title="Replication 分布式拷贝"></a>Replication 分布式拷贝</h4><h5 id="1、定义：-1"><a href="#1、定义：-1" class="headerlink" title="1、定义："></a><strong>1、定义</strong>：</h5><p><strong>Replication</strong> (TM) 提供了一种在 HBase 部署之间复制数据的方法。它可以用作灾难恢复解决方案，并有助于在 HBase 层提供更高的可用性。它还可以提供更实际的功能；例如，作为一种将编辑内容从面向 Web 的集群轻松复制到“MapReduce”集群的方法，该集群将处理新旧数据并自动发回结果。<a target="_blank" rel="noopener" href="https://svn-master.apache.org/repos/asf/hbase/hbase.apache.org/trunk/0.94/replication.html">^2</a></p>
<h5 id="2、同步原理"><a href="#2、同步原理" class="headerlink" title="2、同步原理"></a><strong>2、同步原理</strong></h5><p>HBase 的复制方式是 master-push 方式，即主集群推的方式，主要是因为每个RegionServer都有自己的WAL。 一个master集群可以复制给多个从集群，复制是异步的，运行集群分布在不同的地方，这也意味着从集群和主集群的数据不是完全一致的，它的目标就是最终一致性。</p>
<p>每个RegionServer的 HLog 是 HBase 复制的基础，并且该日志复制时必须将其保存在 HDFS 中。每个 RegionServer 都会从需要复制的最旧的日志中读取，并在 ZooKeeper 中保存当前位置以简化故障恢复。该位置对于每个从属集群可能不同，对于要处理的 HLog 队列也一样。</p>
<p>参与复制的集群可以是不对称大小，主集群将尽“最大努力”通过随机化来平衡从属集群上的复制流。</p>
<p>从 0.92 版本开始，Apache HBase 支持主&#x2F;主和循环复制以及到多个从属的复制。</p>
<p>![[Pasted image 20250317110926.png]]</p>
<p>按照同步方式可以分类如下<a target="_blank" rel="noopener" href="https://www.cnblogs.com/caoweixiong/p/13606732.html">^4</a>：</p>
<p><strong>（1）异步Replication</strong><br>后台线程异步的读取WAL并复制到备集群，即做异步Replication，正常情况下备集群收到最新写入数据的延迟在<strong>秒</strong>级别。</p>
<ul>
<li><strong>主集群启动线程</strong>：主集群的每个RegionServer进程内部起了一个叫做ReplicationSource的线程来负责Replication</li>
<li><strong>备集群启动线程</strong>：的每个RegionServer内部起了一个ReplicationSink的线程来负责接收Replication数据</li>
<li><strong>确定同步内容</strong>ReplicationSource记录需要同步的WAL队列，然后不断读取WAL中的内容，同时可以根据Replication的配置做一些过滤，比如是否要复制这个表的数据等</li>
<li><strong>RPC调用</strong>：通过replicateWALEntry这个Rpc调用来发送给备集群的RegionServer，备集群的ReplicationSink线程则负责将收到的数据转换为put&#x2F;delete操作，以batch的形式写入到备集群中</li>
</ul>
<p><strong>（2）串行Replication（HBase 2.1引入）</strong><br>对于某个Region来说，严格按照主集群的写入顺序复制到备集群，其是一种特殊的Replication。</p>
<p>【注】当源集群发生Region move 或 RegionServer failure 时，在Region move或RegionServer failure之前未推送的HLog条目将由原始RegionServer（用于Region move）或另一个RegionServer（用于RegionServer failure）推送 ，并由现在服务于该区域的RS推送相同区域的新HLog条目，但它们在没有协调的情况下同时推送同一区域的 HLog 条目。<br>解决方案：确保移动后的Region Server写入操作必须在原Region Server的写入操作复制完成后再进行。</p>
<p><strong>（3）同步Replication</strong><br>异步Replication的最大问题在于复制是存在延迟的，所以在主集群整集群挂掉的情况下，备集群是没有已经写入的完整数据的，会丢失数据。</p>
<p>同步Replication的核心思路就是在写入主集群WAL的同时，在备集群上写入一份RemoteWAL，只有同时在主集群的WAL和备集群的RemoteWAL写入成功了，才会返回给Client说写入成功。</p>
<p>【注】同步Replication是在异步Replication的基础之上的，也就是说异步Replication的复制链路还会继续保留，同时增加了新的写Remote WAL的步骤。<br>![[Pasted image 20250317150012.png]]</p>
<p>对比异步复制来看，同步复制主要是影响的写路径，从我们的测试结果上来看，大概会有14%的性能下降，后续计划在HBase-20422中进行优化。</p>
<h5 id="3、适用场景：-1"><a href="#3、适用场景：-1" class="headerlink" title="3、适用场景："></a><strong>3、适用场景</strong>：</h5><p>HBase到HBase集群之间</p>
<h5 id="4、常用指令：-1"><a href="#4、常用指令：-1" class="headerlink" title="4、常用指令："></a><strong>4、常用指令</strong>：</h5><p>（1） 主集群添加复制关系</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_peer &#x27;100&#x27;, CLUSTER_KEY =&gt; &quot;172.16.10.60:2181:/hbase&quot;</span><br></pre></td></tr></table></figure>

<p>（2）建表，并对指定列簇开启Replication</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;tt&#x27;, &#123;NAME=&gt;&#x27;cf&#x27;, REPLICATION_SCOPE=&gt;&#x27;1&#x27;&#125;</span><br></pre></td></tr></table></figure>

<p>（3）备集群建表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;tt&#x27;, &#123;NAME=&gt;&#x27;cf&#x27;&#125;     </span><br></pre></td></tr></table></figure>

<p>（4）通过HBase自带的VerifyReplication工具验证数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication -mappers 10 -bandwidth 1024 1 tt</span><br></pre></td></tr></table></figure>

<h5 id="5、可选参数-1"><a href="#5、可选参数-1" class="headerlink" title="5、可选参数"></a><strong>5、可选参数</strong></h5><table>
<thead>
<tr>
<th>参数</th>
<th>配置</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>zookeeper.znode.replication.rs</td>
<td>&#x2F;hyperbase1&#x2F;replication&#x2F;rs</td>
<td>包含主集群 RegionServers 列表 ( &#x2F;hbase&#x2F;replication&#x2F;rs&#x2F;<region server> )；对每个 RegionServer 节点，都有它要 Replication 数据过去的一个 Per Peer 子节点。<br>在 Peer 子节点内， Hlogs 等待被 Repication ，以这个路径表示: ( &#x2F;hbase&#x2F;replication&#x2F;rs&#x2F;<region server>&#x2F;<ClusterId>&#x2F;<hlogName> )</td>
</tr>
<tr>
<td>zookeeper.znode.replication.peers</td>
<td>&#x2F;hyperbase1&#x2F;replication&#x2F;peers</td>
<td>每个 Peer 有一个子节点(例如： &#x2F;hbase&#x2F;replication&#x2F;peers&#x2F;<ClusterID> )，包含能够连接到 peer 的 zookeeper 地址。 一个hbase 表可以同时replication到多个peer。</td>
</tr>
<tr>
<td>zookeeper.znode.replication</td>
<td>&#x2F;hyperbase1&#x2F;replication</td>
<td>包含 HBase replication state information 的根节点</td>
</tr>
<tr>
<td>zookeeper.znode.parent</td>
<td>&#x2F;hyperbase{num.}</td>
<td>Hyperbase在zookeeper上znode的名字</td>
</tr>
<tr>
<td>replication.sleep.before.failover</td>
<td>1</td>
<td>重新尝试同步已经死掉的 region server的WAL队列的时间，单位：ms</td>
</tr>
<tr>
<td>replication.executor.workers</td>
<td>1</td>
<td>每个 region server 应尝试同时进行故障切换的 region server 的数量</td>
</tr>
</tbody></table>
<h5 id="6、附录-1"><a href="#6、附录-1" class="headerlink" title="6、附录"></a><strong>6、附录</strong></h5><p>（1）replication不会根据实际插入的顺序来进行，只保证和master集群最终一致性。<br>（2）主集群对于同步的数据大小和个数采用默认值较大，容易导致备集群内存被压垮。建议配置减少每次同步数据的大小。replication.source.size.capacity4194304&#x2F;replication.source.nb.capacity2000<br>（3）HBase集群间复制时一般通过 CopyTable + Replication共同实现。</p>
<hr>
<h3 id="三、Kafka组件"><a href="#三、Kafka组件" class="headerlink" title="三、Kafka组件"></a>三、Kafka组件</h3><h4 id="MirrorMaker"><a href="#MirrorMaker" class="headerlink" title="MirrorMaker"></a>MirrorMaker</h4><h5 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h5><p><strong>MirrorMaker</strong> ：Apache Kafka中的一个工具，用于在不同的Kafka集群之间进行数据复制和数据同步。它可以将一个Kafka集群中的主题（topic）的数据复制到另一个Kafka集群中的相应主题，从而实现数据的跨集群复制。</p>
<p>MirrorMaker最初是由LinkedIn开发的，作为其内部使用的数据复制工具。LinkedIn是一个职业社交网络平台，使用Kafka作为其核心的消息传递系统。为了实现数据的跨集群复制和数据同步，LinkedIn团队开发了MirrorMaker。<br>MirrorMaker于2012年首次发布，作为LinkedIn的开源项目，成为Apache Kafka的一部分。随着Kafka的快速发展和广泛应用，MirrorMaker也逐渐得到了更多社区的关注和贡献。<br>随着时间的推移，MirrorMaker经历了多个版本的更新和改进。在不同的Kafka版本中，MirrorMaker的功能和性能都得到了不断优化和增强。社区也提供了丰富的文档和示例，以帮助用户更好地理解和使用MirrorMaker。<br>MirrorMaker的历史可以追溯到Kafka的早期发展阶段，它在Kafka生态系统中扮演着重要的角色，为用户提供了可靠的数据复制解决方案。随着时间的推移，MirrorMaker在Kafka社区中得到了广泛的认可和应用，并成为了许多企业在构建分布式数据处理系统中的重要组成部分。<a target="_blank" rel="noopener" href="https://www.ctyun.cn/developer/article/442989040070725">^5</a></p>
<h5 id="2、原理"><a href="#2、原理" class="headerlink" title="2、原理"></a>2、原理</h5><p>（1）配置源集群和目标集群：首先，你需要配置源集群和目标集群的连接信息，包括Kafka集群的地址、主题名称等。MirrorMaker需要同时连接到源集群和目标集群。<br>（2）配置源集群和目标集群：首先，你需要配置源集群和目标集群的连接信息，包括Kafka集群的地址、主题名称等。MirrorMaker需要同时连接到源集群和目标集群。<br>创建消费者和生产者：MirrorMaker会创建一个或多个消费者，从源集群中读取消息。每个消费者会订阅一个或多个源集群的主题。同时，MirrorMaker也会创建一个或多个生产者，将消息写入目标集群的相应主题。<br>（3）复制消息：MirrorMaker的消费者会从源集群中读取消息，并将其转发给生产者，生产者将消息写入目标集群。复制过程是异步进行的，即源集群中的数据变化会延迟一段时间后才会在目标集群中出现。<br>（4）容错和故障处理：MirrorMaker具有一定的容错机制，当源集群或目标集群出现故障或不可用时，它会尽力保证数据的复制和同步。如果源集群的某个分区不可用，MirrorMaker会尝试从其他可用的分区读取消息。如果目标集群的某个分区不可用，MirrorMaker会重试写入操作，直到成功为止。<br>（5）配置选项：MirrorMaker提供了丰富的配置选项，可以根据需要进行配置。你可以选择复制全部主题或只复制特定的主题，还可以配置复制的速率和数据过滤等。</p>
<p>总之，MirrorMaker通过消费者和生产者的组合，实现了从源集群到目标集群的数据复制和同步。它可以在不同版本的Kafka集群之间进行数据复制，并提供了灵活的配置选项和容错机制，以保证数据的可用性和一致性。</p>
<p>![[Pasted image 20250317185721.jpg]]</p>
<h5 id="3、适用场景"><a href="#3、适用场景" class="headerlink" title="3、适用场景"></a><strong>3、适用场景</strong></h5><p>Kafka集群到Kafka集群</p>
<ul>
<li><p>灾难恢复与冗余：如果你有一个重要的Kafka集群运行在一个数据中心，并且你希望为其创建一个备份，可以使用MirrorMaker将数据复制到另一个位于不同数据中心的Kafka集群。这样，如果主数据中心发生故障，你可以立即切换到备份数据中心，确保业务的连续性。</p>
</li>
<li><p>数据聚合：如果你有多个位于不同地区或部门的Kafka集群，每个集群都在生产重要的数据，你可能希望在一个中心位置进行数据聚合和分析。在这种情况下，可以使用MirrorMaker将所有的Kafka集群的数据复制到一个中心集群。</p>
</li>
<li><p>跨地域应用：如果你的应用需要在多个地域部署，并需要访问到相同的数据流，那么可以使用MirrorMaker在各个地域之间复制数据。</p>
</li>
<li><p>数据管道和ETL：可以在源Kafka集群中创建生产者应用，将数据送入管道，然后在目的地Kafka集群中创建消费者应用，对数据进行处理和存储。MirrorMaker可以在这两个集群之间提供数据流。</p>
</li>
</ul>
<h5 id="4、常用指令：-2"><a href="#4、常用指令：-2" class="headerlink" title="4、常用指令："></a><strong>4、常用指令</strong>：</h5><p>（1）官方提供的MirrorMaker脚本，用于启动MirrorMaker进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-mirror-maker.sh --consumer.config consumer.properties --producer.config producer.properties --whitelist=&quot;^topic.*&quot;</span><br></pre></td></tr></table></figure>

<h5 id="5、参数说明"><a href="#5、参数说明" class="headerlink" title="5、参数说明"></a>5、参数说明</h5><table>
<thead>
<tr>
<th>参数名</th>
<th>参数含义</th>
</tr>
</thead>
<tbody><tr>
<td>whitelist</td>
<td>指定一个正则表达式，指定拷贝源集群中的哪些topic。比如 a|b 表示拷贝源集群上连个topic的数据a和b。注意，当使用新版本consumer时必须指定该参数。为了方便使用，可以将|替换为,</td>
</tr>
<tr>
<td>blacklist</td>
<td>指定一个正则表达式，屏蔽指定topic的拷贝。注意，该参数只使用于老版本consumer</td>
</tr>
<tr>
<td>abort.on.send.failure</td>
<td>若设置为true，当发送失败时则关闭MirrorMaker</td>
</tr>
<tr>
<td>consumer.config</td>
<td>指定MirrorMaker下consumer的属性文件。至少指定bootstrap.server和group.id</td>
</tr>
<tr>
<td>producer.config</td>
<td>指定MirrorMaker下producer的属性文件</td>
</tr>
<tr>
<td>consumer.rebalance.listener</td>
<td>指定MirrorMaker使用的consumer rebalance监听器</td>
</tr>
<tr>
<td>rebalance.listener.args</td>
<td>指定MirrorMaker使用的consumer rebalance监听器的参数，与consumer.rebalance.listener一同使用</td>
</tr>
<tr>
<td>message.handler</td>
<td>指定消息处理器类。消息处理器在consumer获取消息与producer发送消息之间调用</td>
</tr>
<tr>
<td>message.handler.args</td>
<td>指定消息处理器类的参数，与message.handler一同使用</td>
</tr>
<tr>
<td>num.streams</td>
<td>指定MirrorMaker线程数。默认是1</td>
</tr>
<tr>
<td>offset.conmmit.interval.ms</td>
<td>指定MirrorMaker位移提交间隔，默认值为1分钟<br>help	打印帮助信息</td>
</tr>
</tbody></table>
<hr>
<h3 id="四、ElasticSearch组件"><a href="#四、ElasticSearch组件" class="headerlink" title="四、ElasticSearch组件"></a>四、ElasticSearch组件</h3><h4 id="CCR"><a href="#CCR" class="headerlink" title="CCR"></a>CCR</h4><h5 id="1、定义-1"><a href="#1、定义-1" class="headerlink" title="1、定义"></a>1、定义</h5><p> CCR（Cross-Cluster Replication），是Elasticsearch 6.7 版本中引入跨集群复制功能，支持将指定的索引从一个 Elasticsearch 集群复制到一个或多个 Elasticsearch 集群。跨集群复制属于 Elastic Stack 的白金版（PLATINUM）付费功能，需要额外付费才可以使用。<a target="_blank" rel="noopener" href="https://www.infvie.com/ops-notes/elasticsearch-multiple-cross-machine-rooms.html">^6</a></p>
<h5 id="2、原理-1"><a href="#2、原理-1" class="headerlink" title="2、原理"></a>2、原理</h5><p>跨集群复制使用主动-被动模型（active-passive model），复制更改的索引称为“追随者索引”（follower Index），被复制的索引称为“领导者索引”（leader index）。当 leader index 收到写入时，follower index 会从远程集群上的 leader index 上基于文档操作实现订阅复制。当配置复制规则时，可以指定特定的索引进行复制；也可以通过 auto-follow pattern 以通配符的形式自动匹配多个索引，创建复制规则后新创建的索引也会自动匹配。</p>
<p>![[Pasted image 20250318142248.png]]</p>
<p>follower index 是被动的，它可以服务于读取请求，但不能接受写入请求，只有 leader index 可以接受写入请求。</p>
<p>复制过程主要分为两个阶段(对应ES写入的两个阶段，复制落地到磁盘的segment和复制写入缓存区还未落地到磁盘的数据)</p>
<ul>
<li>Step1–复制远程leader集群的<strong>segment</strong>到 本地 follower集群</li>
</ul>
<p>![[Pasted image 20250318152607.png]]</p>
<ul>
<li>Step2–复制远程leader集群的 <strong>operator records</strong> (存在内存缓冲区和translog )到 本地follower集群。<br>![[Pasted image 20250318152627.png]]<br>💢当主集群发生宕机时，如果我们想让在备集群中的 follower index 接管服务，允许进行写入请求，需要依次暂停索引的复制，关闭索引，取消跟随 leader index，最后将其重新打开为普通的索引，整套操作下来非常复杂，而且无法进行回切，这也是 CCR 跨集群复制最大的一个问题。<br>![[Pasted image 20250318144030.png]]</li>
</ul>
<p>针对上述问题，这里也提供了一种解决方案，那就是双向复制（CCR bi-directional replication）。如下图所示，我们可以在集群 cluster01 上创建索引 <code>logs-cluster01</code>，并在集群 cluster02 上复制该索引；在集群 cluster02 上创建索引 <code>logs-cluster02</code> ，并在集群 cluster01 上复制该索引。然后在两个集群上创建别名 <code>logs</code>  指向索引 <code>logs-cluster01</code> 和 <code>logs-cluster02</code>，对外可以提供统一的索引名。别名指向的多个索引中，只能有一个索引是允许接收写入请求的，在 cluster01 将索引 <code>logs-cluster01</code> 设置为可写，<code>logs-cluster02</code> 索引中的数据将会通过 CCR 跨集群复制从集群 cluster02 中获取；集群 cluster02 的别名设置相反。通过以上设置，应用程序在读写的时候都往 <code>logs</code>  别名发送请求，假设当集群 cluster01 不可用时，我们可以继续使用集群 cluster02，并且依然是往 <code>logs</code> 别名发送请求，无需手动进行切换操作；当集群 cluster01 恢复后，会从上次记录的 checkpoint 继续从集群 cluster02 复制数据，也无需额外的切换操作。</p>
<h5 id="3、适用场景-1"><a href="#3、适用场景-1" class="headerlink" title="3、适用场景"></a>3、适用场景</h5><p>ElasticSearch实时同步至ElasticSearch</p>
<ul>
<li><strong>灾难恢复（DR）&#x2F;高可用性（HA）</strong>：如果主群集发生故障，则进行灾难恢复。 辅助群集可以用作热备份</li>
<li><strong>地理位置优先</strong>：在 Elasticsearch 中复制数据以更接近用户或应用程序服务器，从而减少延迟。优先就近读取数据，提升性能</li>
<li><strong>集中报告</strong>：将数据从大量较小的集群复制回一个中央集群进行报告<a target="_blank" rel="noopener" href="https://www.cnblogs.com/tgzhu/p/17090475.html">^7</a></li>
</ul>
<h5 id="4、常用指令：-3"><a href="#4、常用指令：-3" class="headerlink" title="4、常用指令："></a>4、常用指令：</h5><p>（1）开启CCR，Elasticsearch 7.0+ 之后版本已默认开启，无需单独配置。</p>
<p>（2）连接到远程集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PUT /_cluster/settings  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;persistent&quot; : &#123;  </span><br><span class="line">    &quot;cluster&quot; : &#123;  </span><br><span class="line">      &quot;remote&quot; : &#123;  </span><br><span class="line">        &quot;es01&quot; : &#123;  </span><br><span class="line">          &quot;seeds&quot; : [  </span><br><span class="line">            &quot;es01:9300&quot;   </span><br><span class="line">          ]  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）创建Follower index</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT /index-1-follower/_ccr/follow?wait_for_active_shards=1  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;remote_cluster&quot; : &quot;es01&quot;,  </span><br><span class="line">  &quot;leader_index&quot; : &quot;index-1&quot;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">_# 返回结果_  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;follow_index_created&quot; : true,  </span><br><span class="line">  &quot;follow_index_shards_acked&quot; : true,  </span><br><span class="line">  &quot;index_following_started&quot; : true  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="5、参数说明-1"><a href="#5、参数说明-1" class="headerlink" title="5、参数说明"></a>5、参数说明</h5><table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>ccr.indices.recovery.max_bytes_per_sec</td>
<td>限制每个节点上的总入站和总出站的远程流量(速度)。(默认值是40mb)，当主集群和从集群都设置这个值后，先达到限制值的先其作用。即如果主集群设置20mb，从集群设置60mb，那么主集群也只会想从集群发送20mb。</td>
</tr>
<tr>
<td>ccr.indices.recovery.max_concurrent_file_chunks</td>
<td>复制文件的并行度，即可以同时复制接个文件，默认值是5，最大值为10.</td>
</tr>
<tr>
<td>ccr.indices.recovery.chunk_size</td>
<td>复制文件一次请求的最大限制，默认值是1mb</td>
</tr>
<tr>
<td>ccr.indices.recovery.recovery_activity_timeout</td>
<td>leader等待follower恢复请求的时间，默认值是60s</td>
</tr>
<tr>
<td>ccr.indices.recovery.internal_action_timeout</td>
<td>在远程恢复过程中单个网络请求的超时值，默认值是60s</td>
</tr>
</tbody></table>
<h5 id="6、附录-2"><a href="#6、附录-2" class="headerlink" title="6、附录"></a>6、附录</h5><ul>
<li>​<strong>分片数量与线程数关系</strong>：分片数量直接影响并行复制的线程数，需合理规划分片数以避免资源争用。</li>
<li>​<strong>版本兼容性</strong>：需确保 leader 和 follower 集群的 Elasticsearch 版本兼容，否则可能引发线程池调度异常</li>
<li>​<strong>网络带宽</strong>：多线程可能加剧跨集群网络负载，需监控带宽使用情况。</li>
</ul>
<h3 id="五、Hive组件"><a href="#五、Hive组件" class="headerlink" title="五、Hive组件"></a>五、Hive组件</h3><p>hive的数据包含两部分，一部分是hive数据表，可以通过distcp同步，另一部分是元数据，可通过dump方式生成文件，再通过distcp同步，或者基于元数据的数据库能力进行同步均可，不再介绍</p>
<h3 id="六、Clickhouse组件"><a href="#六、Clickhouse组件" class="headerlink" title="六、Clickhouse组件"></a>六、Clickhouse组件</h3><h4 id="ReplicatedMergeTree引擎"><a href="#ReplicatedMergeTree引擎" class="headerlink" title="ReplicatedMergeTree引擎"></a>ReplicatedMergeTree引擎</h4><h5 id="1、定义-2"><a href="#1、定义-2" class="headerlink" title="1、定义"></a>1、定义</h5><p> ClickHouse 采用 Multi - Master 的多主架构，集群中的每个节点角色对等，客户端访问任意一个节点都能达到相同的结果。这种多主架构有许多优势，例如对等的角色使系统架构变的更加简单，不再区分主控节点、数据节点和计算节点，集群中所有节点的功能相同。正因如此，ClickHouse 天然规避了单点故障的问题，非常适用于多数据中心、异地多活等场景。<a target="_blank" rel="noopener" href="https://www.dbkuaizi.com/archives/207.html">^8</a></p>
<p>ClickHouse利用ZooKeeper，通过ReplicatedMergeTree引擎（Replicated 系列引擎）实现了副本机制。副本机制是多主架构，可以将INSERT语句发送给任意一个副本，其余副本会进行数据的异步复制。</p>
<h5 id="2、原理-2"><a href="#2、原理-2" class="headerlink" title="2、原理"></a>2、原理</h5><p>副本机制功能：</p>
<ul>
<li>ClickHouse副本机制的设计可以最大限度的减少网络数据传输，用以在不同的数据中心进行同步，可以用来建设多数据中心、异地多活的集群架构。</li>
<li>副本机制是实现：高可用（HA）、负载均衡（Load Balance）、迁移&#x2F;升级（Migration&#x2F;Upgrade）功能的基础。</li>
<li>高可用：系统会监视副本数据的同步情况，识别故障节点，并在节点恢复正常时进行故障恢复，保证服务整体高可用。<br>![[Pasted image 20250318183444.png]]<br>ReplicateMergeTree可以通过和zk结合，把数据同步到对应的副本节点中，而且同步是相互的，也就是说从A节点写入的数据会同步到B节点，从B节点写入的数据也会写入到A节点中，典型的Mul-Master架构。通过一个分片多个副本的形式可以分摊读和写的负载，我们看一下同步的原理：</li>
</ul>
<p>（1）insert数据：假设A节点进行数据插入，首先A节点本地会创建一个新的目录分区，然后他会把这个分区目录的信息推送到zk的log目录节点下，目的是为了通知B节点来获取该分区的数据，B节点会监听zk的log节点的变更通知，让得知是要去A节点同步数据分区数据时，他首先先把这个消息发送到他对应的zk上面的任务执行队列，B本身会按照zk上面的执行队列的顺序顺序执行各个操作，自然当获取到是要去A同步数据分区数据时，他会和A节点建立数据连接，希望从A那里下载到该分区数据，等到A返回对应的分区数据时，B会在本地创建一个名称一模一样的目录分区数据,自此insert的数据完成了同步。<br>![[Pasted image 20250318184230.png]]<br>Insert数据插入操作时多个副本之间是有存在副本一致性问题的，也就是同步期间副本0和副本1的数据是不一致的，所以对于使用multi-master进行写多个副本的操作时，需要意识到在一定的时间内多个副本之间的数据是不一致的，所以选择这种方案需要考虑到数据不一致的问题</p>
<p>b. merge合并数据: 这个操作需要从A和B中通过zk选举出主节点，假设A是主节点，B是副节点，当B执行optimize table操作合并数据分区时，B首先和主节点A直接建立连接，告诉A主副本负责制定merge合并计划，当A收到B的制定merge计划的请求后，A制定了merge计划，比如把2020_0_0_0和2020_2_2_1合并成2020_0_2_2，他会把这个执行计划推送到zk的log节点中，这样A和B监听到zk的log节点执行计划后会分别把这个执行计划推送到各自在zk上的queue任务队列中，然后A和B各自执行各自的任务队列操作时，就会各自按照执行计划merge各自的分区<br>![[Pasted image 20250318184300.png]]<br>c. update&#x2F;delete数据：假设A节点进行数据删除操作Alter table XX delete id&#x3D;100，首先A节点会把这个操作组合成一个消息（包含mutationid）发送到zk中，此后节点A和B会监听zk中的mutation节点的变更，假设此时B节点是主节点，所以B节点会响应这个数据变更的消息并指定具体的数据更新计划，比如目录文件从202209_0_0_1在进行了delete具体操作后变成202209_0_0_1_mutationid,然后B节点会发送这个具体的数据更新消息到zk中，此时A和B节点会同时监听到具体的数据变更消息，然后在各自的本地磁盘中进行数据的修改&#x2F;删除操作,自此update&#x2F;delete的数据完成了同步。<br>![[Pasted image 20250318184309.png]]<br>update&#x2F;delete数据修改操作时多个副本之间是有存在副本一致性问题的，也就是同步期间副本0和副本1的数据是不一致的，所以对于使用multi-master进行修改删除多个副本的操作时，需要意识到在一定的时间内多个副本之间的数据是不一致的，所以选择这种方案需要考虑到数据不一致的问题</p>
<p>整个执行过程中zk只是作为消息通知的手段，clickhouse表数据的传输并没有通过zk进行，zk的压力其实不大，此外，对于ReplicateMergeTree表的查询操作并不需要zk的参与。</p>
<h5 id="3、适用场景-2"><a href="#3、适用场景-2" class="headerlink" title="3、适用场景"></a>3、适用场景</h5><p>Clickhouse多主架构</p>
<h5 id="4、常用指令-9"><a href="#4、常用指令-9" class="headerlink" title="4、常用指令^9"></a>4、常用指令<a target="_blank" rel="noopener" href="https://blog.csdn.net/nazeniwaresakini/article/details/105858390">^9</a></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS test.events_local ON CLUSTER &#x27;&#123;cluster&#125;&#x27; (</span><br><span class="line">  ts_date Date,</span><br><span class="line">  ts_date_time DateTime,</span><br><span class="line">  uzser_id Int64,</span><br><span class="line">  event_type String,</span><br><span class="line">  site_id Int64,</span><br><span class="line">  groupon_id Int64,</span><br><span class="line">  category_id Int64,</span><br><span class="line">  merchandise_id Int64,</span><br><span class="line">  search_text String</span><br><span class="line">  -- A lot more columns...</span><br><span class="line">)</span><br><span class="line">ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/&#123;shard&#125;/test/events_local&#x27;,&#x27;&#123;replica&#125;&#x27;)</span><br><span class="line">PARTITION BY ts_date</span><br><span class="line">ORDER BY (ts_date,toStartOfHour(ts_date_time),site_id,event_type)</span><br><span class="line">SETTINGS index_granularity = 8192;</span><br></pre></td></tr></table></figure>

<h5 id="5、参数说明-2"><a href="#5、参数说明-2" class="headerlink" title="5、参数说明"></a>5、参数说明</h5><table>
<thead>
<tr>
<th>参数</th>
<th>介绍</th>
</tr>
</thead>
<tbody><tr>
<td><code>zoo_path</code></td>
<td>ZooKeeper 路径。相同的 ZooKeeper 路径对应于相同的数据库。</td>
</tr>
<tr>
<td><code>shard_name</code></td>
<td>分片名称。数据库副本按 <code>shard_name</code> 分组到分片中。</td>
</tr>
<tr>
<td><code>replica_name</code></td>
<td>副本名称。相同分片的所有副本名称必须不同。</td>
</tr>
<tr>
<td>对于<a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/replication">ReplicatedMergeTree</a>表，如果没有提供参数，则使用默认参数：<code>/clickhouse/tables/&#123;uuid&#125;/&#123;shard&#125;</code>和<code>&#123;replica&#125;</code>。这些可以在服务器设置中更改 <a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/operations/server-configuration-parameters/settings#default_replica_path">default_replica_path</a> 和 <a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/operations/server-configuration-parameters/settings#default_replica_name">default_replica_name</a>。宏 <code>&#123;uuid&#125;</code> 被展开为表的 uuid，<code>&#123;shard&#125;</code> 和<code>&#123;replica&#125;</code> 被展开为来自服务器配置的值，而不是数据库引擎参数中的值。但在将来，可以使用副本数据库的 <code>shard_name</code> 和 <code>replica_name</code>。<a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/engines/database-engines/replicated">^10</a></td>
<td></td>
</tr>
</tbody></table>
<h5 id="6、附录-3"><a href="#6、附录-3" class="headerlink" title="6、附录"></a>6、附录</h5><ul>
<li>ClickHouse容灾保护的范围是基于复制表创建的分布式表和物化视图，即对分布式表、物化视图及相关的复制表可以完成容灾保护同步数据到容灾集群。</li>
<li>![[计算机基础&#x2F;assets&#x2F;大数据组件数据同步能力&#x2F;1751852687392.png|assets&#x2F;大数据组件数据同步能力&#x2F;1751852687392.png]]</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90Kubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90Kubernetes/" class="post-title-link" itemprop="url">深入剖析Kubernetes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E8%AE%BE%E8%AE%A1%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/08/16/%E8%AE%BE%E8%AE%A1%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8/" class="post-title-link" itemprop="url">设计数据密集型应用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>作者： Martin Kleppmann<br>阅读日期：20250811——20250830<br>学习网站：<a target="_blank" rel="noopener" href="http://ddia.vonng.com/">http://ddia.vonng.com/</a></p>
<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>第一部分：数据系统基础——设计数据密集型应用所赖的基本思想</p>
<ol>
<li>数据系统架构中的权衡 </li>
<li>定义非功能性需求 </li>
<li>数据模型与查询语言 </li>
<li>存储与检索 </li>
<li>编码与演化<br>第二部分：分布式数据——存储在一台机器上的数据转向讨论分布在多台机器上的数据</li>
<li>复制 </li>
<li>分片 </li>
<li>事务 </li>
<li>分布式系统的麻烦 </li>
<li>一致性与共识<br>第三部分：派生数据——从其他数据集派生出一些数据集的系统。</li>
<li>批处理 </li>
<li>流处理 </li>
<li>数据系统的未来</li>
</ol>
<h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p><strong>数据密集型应用（data-intensive applications）</strong> 正在通过使用这些技术进步来推动可能性的边界。一个应用被称为 <strong>数据密集型</strong> 的，如果 <strong>数据是其主要挑战</strong>（数据量，数据复杂度或数据变化速度）—— 与之相对的是 <strong>计算密集型</strong>，即处理器速度是其瓶颈。</p>
<h1 id="第一部分：数据系统基础"><a href="#第一部分：数据系统基础" class="headerlink" title="第一部分：数据系统基础"></a>第一部分：数据系统基础</h1><h2 id="1、数据系统架构中的权衡"><a href="#1、数据系统架构中的权衡" class="headerlink" title="1、数据系统架构中的权衡"></a>1、数据系统架构中的权衡</h2><p>如果数据管理是开发应用程序的主要挑战之一，我们就称应用程序为 <strong>数据密集型（data-intensive）</strong> 的，关心诸如<strong>存储和处理大量数据、管理数据变更、在面对故障和并发时确保一致性，以及确保服务高可用</strong>等问题。一般需要通过<strong>数据库、缓存、索引、流批处理</strong>来构建。</p>
<h3 id="分析型与事务型系统"><a href="#分析型与事务型系统" class="headerlink" title="分析型与事务型系统"></a>分析型与事务型系统</h3><p>三类人：</p>
<ul>
<li><strong>后端工程师</strong>：构建处理读取和更新数据请求的服务；这些服务通常直接或间接地通过其他服务为外部用户提供服务</li>
<li><strong>业务分析师</strong>：生成关于组织活动的报告，以帮助管理层做出更好的决策</li>
<li><strong>数据科学家</strong>：在数据中寻找新的见解，或创建由数据分析和机器学习&#x2F;AI 支持的面向用户的产品功能</li>
</ul>
<p>业务分析师和数据科学家两者都执行 <strong>分析</strong>，这意味着他们查看用户和后端服务生成的数据，但他们通常不修改这些数据，这导致了两种类型系统之间的分离：</p>
<ul>
<li><strong>事务型系统</strong> 由后端服务和数据基础设施组成，在这里创建数据，例如通过服务外部用户。在这里，应用程序代码基于用户执行的操作读取和修改其数据库中的数据。</li>
<li><strong>分析型系统</strong> 服务于业务分析师和数据科学家的需求。它们包含来自事务型系统的只读数据副本，并针对分析所需的数据处理类型进行了优化。</li>
</ul>
<p>随着这些系统的成熟，出现了两个新的专业角色：<strong>数据工程师</strong> 和 <strong>分析工程师</strong>。</p>
<ul>
<li><strong>数据工程师</strong>是知道如何集成事务型系统和分析型系统的人，并更广泛地负责组织的数据基础设施</li>
<li><strong>分析工程师</strong>对数据进行建模和转换，使其对组织中的业务分析师和数据科学家更有用</li>
</ul>
<h4 id="事务处理与分析的特征"><a href="#事务处理与分析的特征" class="headerlink" title="事务处理与分析的特征"></a>事务处理与分析的特征</h4><ul>
<li><strong>OLTP</strong>：事务型系统通常通过某个键查找少量记录（这称为 <strong>点查询</strong>）。基于用户的输入插入、更新或删除记录。因为这些应用程序是交互式的，这种访问模式被称为 <strong>联机事务处理</strong>（OLTP）</li>
<li><strong>OLAP</strong>：分析具有非常不同的访问模式。通常，分析查询会扫描大量记录，并计算聚合统计信息（如计数、求和或平均值），而不是将单个记录返回给用户，被称为 <strong>联机分析处理</strong>（OLAP）</li>
</ul>
<table>
<thead>
<tr>
<th>属性</th>
<th>事务型系统（OLTP）</th>
<th>分析型系统（OLAP）</th>
</tr>
</thead>
<tbody><tr>
<td>主要读取模式</td>
<td>点查询（通过键获取单个记录）</td>
<td>对大量记录进行聚合</td>
</tr>
<tr>
<td>主要写入模式</td>
<td>创建、更新和删除单个记录</td>
<td>批量导入（ETL）或事件流</td>
</tr>
<tr>
<td>人类用户示例</td>
<td>Web&#x2F;移动应用程序的最终用户</td>
<td>内部分析师，用于决策支持</td>
</tr>
<tr>
<td>机器使用示例</td>
<td>检查操作是否被授权</td>
<td>检测欺诈&#x2F;滥用模式</td>
</tr>
<tr>
<td>查询类型</td>
<td>固定的查询集，由应用程序预定义</td>
<td>分析师可以进行任意查询</td>
</tr>
<tr>
<td>数据代表</td>
<td>数据的最新状态（当前时间点）</td>
<td>随时间发生的事件历史</td>
</tr>
<tr>
<td>数据集大小</td>
<td>GB 到 TB</td>
<td>TB 到 PB</td>
</tr>
</tbody></table>
<h4 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h4><p>90 年代初，公司倾向于停止使用其 OLTP 系统进行分析目的，而是在单独的数据库系统上运行分析。这个单独的数据库被称为 <strong>数据仓库</strong>。有以下几个原因：</p>
<ul>
<li>数据孤岛问题</li>
<li>查询模式和数据布局不太合适</li>
<li>分析查询相当昂贵</li>
</ul>
<p>数据仓库包含公司中所有各种 OLTP 系统中数据的只读副本。数据从 OLTP 数据库中提取（使用定期数据转储或连续更新流），转换为分析友好的模式，清理，然后加载到数据仓库中。这种将数据导入数据仓库的过程称为 <strong>提取-转换-加载</strong>（ETL）<br>![[file-20250811204322471.png]]<br>一些数据库系统提供 <strong>混合事务&#x2F;分析处理</strong>（HTAP），旨在在单个系统中启用 OLTP 和分析，而无需从一个系统 ETL 到另一个系统。<strong>HTAP 不会取代数据仓库</strong>。相反，它在同一应用程序需要既执行扫描大量行的分析查询，又以低延迟读取和更新单个记录的场景中很有用。</p>
<h5 id="从数据仓库到数据湖"><a href="#从数据仓库到数据湖" class="headerlink" title="从数据仓库到数据湖"></a>从数据仓库到数据湖</h5><p><strong>数据分析师</strong>：使用通过 SQL 查询的 <strong>关系</strong> 数据模型<br><strong>数据科学家</strong>：将数据转换为适合训练机器学习模型的形式（特征工程）；使用自然语言处理技术尝试从中提取结构化信息。</p>
<p>数据科学家不喜欢在数据仓库等关系数据库中工作，更喜欢使用 Python 数据分析库（如 pandas 和 scikit-learn）、统计分析语言（如 R）和分布式分析框架。</p>
<p>组织面临着以适合数据科学家使用的形式提供数据的需求。通过数据湖解决：</p>
<p><strong>数据湖</strong>：一个集中的数据存储库，保存任何可能对分析有用的数据副本，通过 ETL 过程从事务型系统获得。与数据仓库的区别在于，数据湖只是包含文件，而不强制任何特定的文件格式或数据模型。数据湖中的文件可能是数据库记录的集合，使用 Avro 或 Parquet 等文件格式编码，但它们同样可以包含文本、图像、视频、传感器读数、稀疏矩阵、特征向量、基因组序列或任何其他类型的数据 <a target="_blank" rel="noopener" href="http://ddia.vonng.com/ch1/#fn:15">15</a>。除了更灵活之外，这通常也比关系数据存储更便宜，因为数据湖可以使用商品化的文件存储，如对象存储</p>
<p>ETL 过程已经泛化为 <strong>数据管道</strong></p>
<p>从数据湖加载数据到单独的数据仓库之外，还可以直接在数据湖中的文件上运行典型的数据仓库工作负载（SQL 查询和业务分析），以及数据科学&#x2F;机器学习工作负载。这种架构被称为 <strong>数据湖仓</strong>，它需要一个查询执行引擎和一个元数据（例如，模式管理）层来扩展数据湖的文件存储。<br><strong>数据湖仓</strong>：数据湖上的仓，是湖也是仓</p>
<h5 id="超越数据湖"><a href="#超越数据湖" class="headerlink" title="超越数据湖"></a>超越数据湖</h5><p>在某些情况下，分析系统的输出被提供给事务型系统（这个过程有时被称为 <strong>反向 ETL</strong>）</p>
<p>例如，在分析系统中训练的机器学习模型可能会部署到生产环境中，以便为最终用户生成推荐，例如”购买了 X 的人也购买了 Y”。这种分析系统的部署输出也被称为 <strong>数据产品</strong></p>
<h4 id="权威数据源与派生数据"><a href="#权威数据源与派生数据" class="headerlink" title="权威数据源与派生数据"></a>权威数据源与派生数据</h4><p><strong>权威记录系统</strong>：权威记录系统，也称为 权威数据源，保存某些数据的权威或 规范 版本。当新数据进入时，例如作为用户输入，它首先写入这里。每个事实只表示一次。如果另一个系统与权威记录系统之间存在任何差异，那么权威记录系统中的值（根据定义）是正确的。</p>
<p><strong>派生数据系统</strong>：派生系统中的数据是从另一个系统获取一些现有数据并以某种方式转换或处理它的结果。如果你丢失了派生数据，你可以从原始源重新创建它。一个经典的例子是缓存：如果存在，可以从缓存提供数据，但如果缓存不包含你需要的内容，你可以回退到底层数据库。反规范化值、索引、物化视图、转换的数据表示和在数据集上训练的模型也属于这一类别。</p>
<ul>
<li>分析系统通常是派生数据系统，因为它们是在其他地方创建的数据的消费者。</li>
<li>事务型服务可能包含权威记录系统和派生数据系统的混合。</li>
</ul>
<h3 id="云服务与自托管"><a href="#云服务与自托管" class="headerlink" title="云服务与自托管"></a>云服务与自托管</h3><p>公认的管理智慧是，作为组织核心竞争力或竞争优势的事物应该在内部完成，而非核心、例行或常见的事物应该留给供应商。<br> <strong>自托管</strong> 的现成软件（开源或商业），即自己部署</p>
<h4 id="云服务的利弊"><a href="#云服务的利弊" class="headerlink" title="云服务的利弊"></a>云服务的利弊</h4><p>云服务的最大缺点是你无法控制它：</p>
<ul>
<li>功能定制开发</li>
<li>服务宕机等恢复</li>
<li>出错难以诊断</li>
<li>存在数据安全问题</li>
</ul>
<h4 id="云原生系统架构"><a href="#云原生系统架构" class="headerlink" title="云原生系统架构"></a>云原生系统架构</h4><p>从头开始设计为云原生的系统已被证明具有几个优势：在相同硬件上具有更好的性能、从故障中更快恢复、 能够快速扩展计算资源以匹配负载，以及支持更大的数据集</p>
<table>
<thead>
<tr>
<th>类别</th>
<th>自托管系统</th>
<th>云原生系统</th>
</tr>
</thead>
<tbody><tr>
<td>事务型&#x2F;OLTP</td>
<td>MySQL、PostgreSQL、MongoDB</td>
<td>AWS Aurora 、Azure SQL DB Hyperscale 、Google Cloud Spanner</td>
</tr>
<tr>
<td>分析型&#x2F;OLAP</td>
<td>Teradata、ClickHouse、Spark</td>
<td>Snowflake、Google BigQuery、Azure Synapse Analytics</td>
</tr>
</tbody></table>
<h6 id="云服务的分层"><a href="#云服务的分层" class="headerlink" title="云服务的分层"></a>云服务的分层</h6><ul>
<li>自托管软件倾向于使用非常通用的计算资源：CPU、RAM、文件系统和 IP 网络。</li>
<li>云实例可以更快地配置，并且有更多种类的大小，但除此之外，它们与传统计算机类似</li>
</ul>
<p>云原生服务的关键思想是不仅使用由操作系统管理的计算资源，还基于较低级别的云服务构建更高级别的服务。例如：</p>
<ul>
<li><strong>对象存储</strong> 服务存储大文件，隐藏了底层物理机器，不必担心任何一台机器上的磁盘空间用完，也不会丢失数据。</li>
<li>许多其他服务反过来建立在对象存储和其他云服务之上：例如，Snowflake 是一个基于云的分析数据库（数据仓库），依赖于 S3 进行数据存储</li>
</ul>
<h6 id="存储和计算的分离"><a href="#存储和计算的分离" class="headerlink" title="存储和计算的分离"></a>存储和计算的分离</h6><p><strong>传统计算</strong>：磁盘存储被认为是持久的，为了容忍单个硬盘的故障，通常使用 RAID（独立磁盘冗余阵列）在连接到同一台机器的几个磁盘上维护数据副本。它对访问文件系统的应用程序是透明的。<br><strong>云计算</strong>：云原生系统通常将这些磁盘更多地视为临时缓存，而不是长期存储。如果实例被替换，本地磁盘会不可访问</p>
<p>云服务还提供可以从一个实例分离并附加到另一个实例的虚拟磁盘存储，种虚拟磁盘实际上不是物理磁盘，而是由一组单独的机器提供的云服务，它模拟磁盘的行为。但是对网络很敏感。</p>
<p>云原生服务通常避免使用虚拟磁盘，而是建立在针对特定工作负载优化的专用存储服务之上。对象存储服务（如 S3）设计用于长期存储相当大的文件，大小从数百千字节到几千兆字节不等。数据库中存储的单个行或值通常比这小得多；<br><strong>云数据库通常在单独的服务中管理较小的值，并将较大的数据块（包含许多单个值）存储在对象存储中</strong></p>
<p>云原生系统中，存储（磁盘）和计算（CPU 和 RAM）在某种程度上分离或 <strong>解耦</strong>。</p>
<h4 id="云时代的运维"><a href="#云时代的运维" class="headerlink" title="云时代的运维"></a>云时代的运维</h4><p><strong>运维</strong>：确保服务可靠地交付给用户（包括配置基础设施和部署应用程序），并确保稳定的生产环境（包括监控和诊断可能影响可靠性的任何问题）</p>
<p>从单个机器到服务的重点转移伴随着运维角色的变化。提供可靠服务的高级目标保持不变，但流程和工具已经发展。DevOps&#x2F;SRE 理念更加强调：自动化、频繁更新等等。</p>
<p>云正在改变运维的角色，但对运维的需求比以往任何时候都大。</p>
<h3 id="分布式与单节点系统"><a href="#分布式与单节点系统" class="headerlink" title="分布式与单节点系统"></a>分布式与单节点系统</h3><p>涉及多台机器通过网络通信的系统称为 <strong>分布式系统</strong>。参与分布式系统的每个进程称为 <strong>节点</strong>。做分布式有很多原因，如：高可用、可伸缩、低延迟、弹性、可持续性等等</p>
<h4 id="分布式系统的问题"><a href="#分布式系统的问题" class="headerlink" title="分布式系统的问题"></a>分布式系统的问题</h4><ul>
<li>网络传输中断、响应时间慢、分布式事务等等</li>
</ul>
<h4 id="微服务与-Serverless"><a href="#微服务与-Serverless" class="headerlink" title="微服务与 Serverless"></a>微服务与 Serverless</h4><p>分布系统的最常见方式是：分为客户端和服务器，并让客户端向服务器发出请求。最常见的是使用 HTTP 进行此通信。</p>
<p>这种构建应用程序的方式传统上被称为 <strong>面向服务架构</strong>（SOA），目前被细化为<strong>微服务</strong> 架构。</p>
<p>微服务架构的特点：服务有一个明确定义的目的；每个服务公开一个可以由客户端通过网络调用的 API，每个服务有一个负责其维护的团队。</p>
<p>带来的复杂性：每个服务都需要用于部署新版本、调整分配的硬件资源以匹配负载、收集日志、监控服务健康状况以及在出现问题时向值班工程师发出警报的基础设施。</p>
<h4 id="云计算与超级计算"><a href="#云计算与超级计算" class="headerlink" title="云计算与超级计算"></a>云计算与超级计算</h4><p>云计算不是构建大规模计算系统的唯一方式；另一种选择是 <strong>高性能计算</strong>（HPC），也称为 <strong>超级计算</strong>。HPC 通常有不同的优先级并使用不同的技术：</p>
<ul>
<li>HPC 通常有不同的优先级并使用不同的技术。</li>
<li>通常运行大型批处理作业，定期将其计算状态检查点到磁盘。</li>
<li>通常通过共享内存和远程直接内存访问（RDMA）进行通信，这支持高带宽和低延迟</li>
</ul>
<h3 id="数据系统、法律与社会"><a href="#数据系统、法律与社会" class="headerlink" title="数据系统、法律与社会"></a>数据系统、法律与社会</h3><p><strong>通用数据保护条例</strong>（GDPR）：多欧洲国家居民对其个人数据更大的控制权和法律权利，类似的隐私法规已在世界各地的各个国家和州采用，包括例如加州消费者隐私法（CCPA）。关于 AI 的法规，例如 <strong>欧盟 AI 法案</strong>，对个人数据的使用方式施加了进一步的限制。</p>
<h2 id="2-定义非功能性需求"><a href="#2-定义非功能性需求" class="headerlink" title="2. 定义非功能性需求"></a>2. 定义非功能性需求</h2><p>应用程序的非功能需求，比如应用程序应该快速、可靠、安全、合规，并且易于维护</p>
<p>从一个案例研究开始本章，研究社交网络服务可能如何工作，这将提供性能和可伸缩性的实际案例。</p>
<h3 id="案例研究：社交网络首页时间线"><a href="#案例研究：社交网络首页时间线" class="headerlink" title="案例研究：社交网络首页时间线"></a>案例研究：社交网络首页时间线</h3><p>社交网络服务：假设用户每天发布 5 亿条帖子，或平均每秒 5,700 条帖子。偶尔，速率可能飙升至每秒 150,000 条帖子。</p>
<p>![[file-20250812104503252.png]]<br>帖子应该是及时的，所以假设在某人发布帖子后，我们希望他们的粉丝能够在 5 秒内看到它。一种方法是让用户的客户端每 5 秒重复上述查询（这称为 _轮询_）。如果我们假设有 1000 万用户同时在线登录，这意味着每秒运行 200 万次查询。即使增加轮询间隔，这也是很大的负载。</p>
<h4 id="时间线的物化与更新"><a href="#时间线的物化与更新" class="headerlink" title="时间线的物化与更新"></a>时间线的物化与更新</h4><p>每次用户发布帖子时，我们查找他们的所有粉丝，并将该帖子插入到每个粉丝的首页时间线中——就像向邮箱投递消息一样。现在当用户登录时，我们可以简单地给他们这个预先计算的首页时间线。此外，要接收时间线上任何新帖子的通知，用户的客户端只需订阅添加到其首页时间线的帖子流。<br>![[file-20250812104720007.png]]这种预先计算和更新查询结果的过程称为 <strong>物化</strong>，时间线缓存是 <em>物化视图</em> 的一个例子</p>
<h3 id="描述性能"><a href="#描述性能" class="headerlink" title="描述性能"></a>描述性能</h3><p>考虑两种主要的度量类型：</p>
<ul>
<li><strong>响应时间</strong>：从用户发出请求到收到所请求答案的经过时间。</li>
<li><strong>吞吐量</strong>：系统正在处理的每秒请求数，或每秒数据量。</li>
</ul>
<p>随着服务的吞吐量接近其容量，由于排队，响应时间急剧增加。<br>![[file-20250812105314815.png]]</p>
<p>就性能指标而言，响应时间通常是用户最关心的，而吞吐量决定了所需的计算资源，因此决定了服务特定工作负载的成本。<br>如果系统的最大吞吐量可以通过添加计算资源显著增加，则称系统为 _可伸缩的_。</p>
<h4 id="延迟与响应时间"><a href="#延迟与响应时间" class="headerlink" title="延迟与响应时间"></a>延迟与响应时间</h4><ul>
<li><em>响应时间</em> 是客户端看到的；它包括系统中任何地方产生的所有延迟。</li>
<li><em>服务时间</em> 是服务主动处理用户请求的持续时间。</li>
<li><em>排队延迟</em> 可能发生在流程中的几个点：例如，在收到请求后，它可能需要等待直到 CPU 可用才能被处理；如果同一台机器上的其他任务通过出站网络接口发送大量数据，响应数据包可能需要在发送之前进行缓冲。</li>
<li><em>延迟</em> 是一个涵盖请求未被主动处理时间的总称，即在此期间它是 <em>潜在的_。特别是，_网络延迟</em> 或 <em>网络延迟</em> 指的是请求和响应在网络中传输所花费的时间。<br>![[file-20250812110210600.png]]</li>
</ul>
<h4 id="平均值、中位数与百分位数"><a href="#平均值、中位数与百分位数" class="headerlink" title="平均值、中位数与百分位数"></a>平均值、中位数与百分位数</h4><p>因为响应时间因请求而异，我们需要将其视为值的 _分布_，而不是单个数字。<br><strong>平均响应时间</strong>：对于估计吞吐量限制很有用<br><strong>中位数</strong>：如果你将响应时间列表从最快到最慢排序，那么 <em>中位数</em> 就在中间中位数成为了解用户通常需要等待多长时间的良好指标。中位数也称为 _第 50 百分位_，有时缩写为 <em>p50_。<br><strong>百分位数</strong>：为了弄清异常值有多糟糕，_第 95_、_99</em> 和 <em>99.9</em> 百分位数很常见，它们是 95%、99% 或 99.9% 的请求比该特定阈值快的响应时间阈值。</p>
<p>响应时间的高百分位数，也称为 _尾部延迟_，很重要，因为它们直接影响用户的服务体验。</p>
<h4 id="响应时间指标的应用"><a href="#响应时间指标的应用" class="headerlink" title="响应时间指标的应用"></a>响应时间指标的应用</h4><p>高百分位数在被多次调用作为服务单个最终用户请求的一部分的后端服务中尤其重要。</p>
<p>百分位数通常用于 _服务级别目标_（SLO）和 _服务级别协议_（SLA），作为定义服务预期性能和可用性的方式</p>
<h3 id="可靠性与容错"><a href="#可靠性与容错" class="headerlink" title="可靠性与容错"></a>可靠性与容错</h3><p>可靠性：即使出现问题也能继续正确工作。<br>为了更准确地说明出现问题，我们将区分 故障 和 失效：</p>
<ul>
<li><strong>故障</strong>：故障是指系统的某个特定 <em>部分</em> 停止正确工作：例如，如果单个硬盘驱动器发生故障，或单台机器崩溃，或外部服务（系统所依赖的）发生中断。</li>
<li><strong>失效</strong>：失效是指 <em>整个</em> 系统停止向用户提供所需的服务；换句话说，当它不满足服务级别目标（SLO）时。</li>
</ul>
<p>故障和失效之间的区别可能会令人困惑，因为它们在不同层面上是同一件事。</p>
<h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p><strong>容错</strong>：如果系统在发生某些故障时仍继续向用户提供所需的服务，我们称系统为 _容错的_。<br><strong>单点故障</strong>：如果系统不能容忍某个部分变得有故障，我们称该部分为 _单点故障_（SPOF），因为该部分的故障会升级导致整个系统的失效。<br><strong>故障注入</strong>：在这种容错系统中，通过故意触发故障来 <em>增加</em> 故障率是有意义。通过故意引发故障，你确保容错机制不断得到锻炼和测试，这可以增加你对故障自然发生时将被正确处理的信心。<br><strong>混沌工程</strong>：一门旨在通过故意注入故障等实验来提高对容错机制的信心的学科。</p>
<h4 id="硬件与软件故障"><a href="#硬件与软件故障" class="headerlink" title="硬件与软件故障"></a>硬件与软件故障</h4><p>常见的硬件故障：</p>
<ul>
<li>大约 2-5% 的磁性硬盘驱动器每年发生故障</li>
<li>大约 0.5-1% 的固态硬盘（SSD）每年发生故障</li>
<li>大约千分之一的机器有一个 CPU 核心偶尔计算错误的结果，可能是由于制造缺陷</li>
<li>RAM 中的数据也可能被损坏，要么是由于宇宙射线等随机事件，要么是由于永久性物理缺陷。即使使用纠错码（ECC）的内存，超过 1% 的机器在给定年份遇到不可纠正的错误<br>在大规模系统中，硬件故障发生得足够频繁，以至于它们成为正常系统运行的一部分。</li>
</ul>
<h5 id="通过冗余容忍硬件故障"><a href="#通过冗余容忍硬件故障" class="headerlink" title="通过冗余容忍硬件故障"></a>通过冗余容忍硬件故障</h5><p>我们对不可靠硬件的第一反应通常是向各个硬件组件添加冗余，以降低系统的故障率。</p>
<ul>
<li>磁盘可以设置为 RAID 配置（将数据分布在同一台机器的多个磁盘上，以便故障磁盘不会导致数据丢失）</li>
<li>服务器可能有双电源和可热插拔的 CPU</li>
</ul>
<p>硬件冗余增加了单台机器的正常运行时间,使用分布式系统有一些优势，例如能够容忍一个数据中心的完全中断。</p>
<p><strong>滚动升级</strong>：如果你需要重新启动机器（例如，应用操作系统安全补丁），单服务器系统需要计划停机时间，而多节点容错系统可以一次修补一个节点，而不影响用户的服务。这称为 <em>滚动升级</em></p>
<h5 id="软件故障"><a href="#软件故障" class="headerlink" title="软件故障"></a>软件故障</h5><p>硬件故障大多数都是独立的，软件故障通常是高度相关的。这种故障比不相关的硬件故障更难预料，并且它们往往导致比硬件故障更多的系统失效。</p>
<ul>
<li>在特定情况下导致每个节点同时失效的软件错误。</li>
<li>使用某些共享、有限资源（如 CPU 时间、内存、磁盘空间、网络带宽或线程）的失控进程</li>
<li>系统所依赖的服务变慢、无响应或开始返回损坏的响应。</li>
</ul>
<p>软件故障的设计方案：仔细考虑系统中的假设和交互；彻底测试；进程隔离；允许进程崩溃和重新启动；避免反馈循环，如重试风暴</p>
<h4 id="人类与可靠性"><a href="#人类与可靠性" class="headerlink" title="人类与可靠性"></a>人类与可靠性</h4><p>在日常业务的务实现实中，组织通常优先考虑创收活动而不是增加其抵御错误的韧性的措施。如果在更多功能和更多测试之间有选择，许多组织可以理解地选择功能。鉴于这种选择，当可预防的错误不可避免地发生时，责怪犯错误的人是没有意义的——问题是组织的优先事项。</p>
<p>管理层应该借此机会从每天与之合作的人的角度了解社会技术系统如何工作的细节，并根据这些反馈采取措施改进它</p>
<h3 id="可伸缩性"><a href="#可伸缩性" class="headerlink" title="可伸缩性"></a>可伸缩性</h3><p><strong>可伸缩性</strong>：用来描述系统应对负载增加能力的术语</p>
<h4 id="描述负载"><a href="#描述负载" class="headerlink" title="描述负载"></a>描述负载</h4><p>包括：吞吐量的度量、某个变量数量的峰值、还有其他影响访问模式并因此影响可伸缩性要求的负载统计特征</p>
<p>目标是在最小化运行系统成本的同时保持系统性能在 SLA 的要求范围内</p>
<h4 id="共享内存、共享磁盘与无共享架构"><a href="#共享内存、共享磁盘与无共享架构" class="headerlink" title="共享内存、共享磁盘与无共享架构"></a>共享内存、共享磁盘与无共享架构</h4><p>增加服务硬件资源的最简单方法是将其移动到更强大的机器。<br><strong>纵向伸缩</strong>：购买一台机器（或租用云实例）具有更多 CPU 核心、更多 RAM 和更多磁盘空间。<br><strong>共享内存架构</strong>：通过使用多个进程或线程在单台机器上获得并行性；成本增长速度快于线性：具有两倍硬件资源的高端机器通常成本远远超过两倍<br><strong>共享磁盘架构</strong>：使用几台具有独立 CPU 和 RAM 的机器，但将数据存储在机器之间共享的磁盘阵列上，这些机器通过快速网络连接：_网络附加存储_（NAS）或 _存储区域网络_（SAN）<br><strong>无共享架构</strong>（ <em>横向伸缩</em> 或 _向外扩展_）：具有多个节点的分布式系统，每个节点都有自己的 CPU、RAM 和磁盘。节点之间的任何协调都在软件级别通过传统网络完成。</p>
<ul>
<li>优点：有线性伸缩的潜力，它可以使用提供最佳性价比的任何硬件</li>
<li>缺点：显式分片，它会产生分布式系统的所有复杂性</li>
</ul>
<h4 id="可伸缩性原则"><a href="#可伸缩性原则" class="headerlink" title="可伸缩性原则"></a>可伸缩性原则</h4><p>可伸缩性的一个良好通用原则是将系统分解为可以在很大程度上相互独立运行的较小组件<br>另一个好原则是不要让事情变得比必要的更复杂。如果单机数据库可以完成工作，它可能比复杂的分布式设置更可取。</p>
<h3 id="可运维性"><a href="#可运维性" class="headerlink" title="可运维性"></a>可运维性</h3><p>软件的大部分成本不在其初始开发中，而在其持续维护中——修复错误、保持其系统运行、调查故障、将其适应新平台、为新用例修改它、偿还技术债务和添加新功能</p>
<p>几个广泛适用的原则：</p>
<ul>
<li><strong>可运维性（Operability）</strong>：使组织容易保持系统平稳运行</li>
<li><strong>简单性（Simplicity）</strong>：通过使用易于理解、一致的模式和结构来实施它，并避免不必要的复杂性，使新工程师容易理解系统。</li>
<li><strong>可演化性（Evolvability）</strong>：使工程师将来容易对系统进行更改，随着需求变化而适应和扩展它以用于未预料的用例。</li>
</ul>
<h4 id="可运维性：让运维更轻松"><a href="#可运维性：让运维更轻松" class="headerlink" title="可运维性：让运维更轻松"></a>可运维性：让运维更轻松</h4><p>运维很重要：良好的运维通常可以解决糟糕（或不完整）软件的局限性，但再好的软件碰上糟糕的运维也难以可靠地运行</p>
<p>良好的可操作性意味着使常规任务变得容易，使运维团队能够将精力集中在高价值活动上。 数据系统可以做各种事情来使常规任务变得容易，包括：</p>
<ul>
<li>允许监控工具检查系统的关键指标，并支持可观测性工具</li>
<li>避免对单个机器的依赖（允许在系统整体继续不间断运行的同时关闭机器进行维护）</li>
<li>提供良好的文档和易于理解的操作模型</li>
</ul>
<h4 id="简单性：管理复杂度"><a href="#简单性：管理复杂度" class="headerlink" title="简单性：管理复杂度"></a>简单性：管理复杂度</h4><p>推理复杂性的一种尝试是将其分为两类，<strong>本质复杂性</strong> 和 <strong>偶然复杂性</strong>：</p>
<ul>
<li>本质复杂性是应用程序问题域中固有的</li>
<li>偶然复杂性仅由于我们工具的限制而产生<br>管理复杂性的最佳工具之一是 <strong>抽象</strong>。良好的抽象可以在干净、易于理解的外观后面隐藏大量实现细节。良好的抽象也可以用于各种不同的应用程序。</li>
</ul>
<h4 id="可演化性：让变化更容易"><a href="#可演化性：让变化更容易" class="headerlink" title="可演化性：让变化更容易"></a>可演化性：让变化更容易</h4><p>在组织流程方面，<em>敏捷</em> 工作模式为适应变化提供了框架。敏捷社区还开发了在频繁变化的环境中开发软件时有用的技术工具和流程， 例如测试驱动开发（TDD）和重构。</p>
<h2 id="3-数据模型与查询语言"><a href="#3-数据模型与查询语言" class="headerlink" title="3. 数据模型与查询语言"></a>3. 数据模型与查询语言</h2><p><strong>数据模型</strong>不仅影响软件的编写方式，还影响我们 <strong>思考问题</strong> 的方式。</p>
<p>如何用更低层次的数据模型来 <strong>表示</strong>应用程序：</p>
<ul>
<li>观察现实世界并用对象或数据结构，以及操作这些数据结构的 API 来建模。这些结构通常是特定于应用程序的。</li>
<li>用通用的数据模型来表达它们，例如 JSON 或 XML 文档、关系数据库中的表，或者图中的顶点和边</li>
<li>用内存、磁盘或网络上的字节来表示文档&#x2F;关系&#x2F;图数据</li>
</ul>
<p><strong>基本思想</strong>：每一层通过提供一个简洁的数据模型来隐藏下层的复杂性。</p>
<p>在本章中，通过比较关系模型、文档模型、基于图的数据模型、事件溯源和数据框来探讨这些权衡。</p>
<h3 id="关系模型与文档模型"><a href="#关系模型与文档模型" class="headerlink" title="关系模型与文档模型"></a>关系模型与文档模型</h3><p> 1970 年Edgar Codd提出最早的的关系模型：SQL，数据被组织成 <strong>关系</strong>（在 SQL 中称为 <strong>表</strong>），其中每个关系是 <strong>元组</strong>（在 SQL 中称为 <strong>行</strong>）的无序集合。<br> 20 世纪 80 年代中期，关系数据库管理系统（RDBMS）和 SQL 已成为大多数需要存储和查询具有某种规则结构的数据的人的首选工具。<br> 20 世纪 70 年代和 80 年代初，<strong>网状模型</strong> 和 <strong>层次模型</strong> 是主要的替代方案，但关系模型最终战胜了它们。<br>  2010 年代，<strong>NoSQL</strong> 是试图推翻关系数据库主导地位的最新流行词。一些数据库将自己标榜为 _NewSQL_，因为它们旨在提供 NoSQL 系统的可伸缩性以及传统关系数据库的数据模型和事务保证。 NoSQL 和 NewSQL 的想法在数据系统设计中产生了很大的影响，但随着这些原则被广泛采用，这些术语的使用已经减少。<br>  NoSQL 运动的一个持久影响是 <strong>文档模型</strong> 的流行，它通常将数据表示为 JSON。 这个模型最初由专门的文档数据库（如 MongoDB 和 Couchbase）推广，尽管大多数关系数据库现在也增加了 JSON 支持。</p>
<h4 id="对象关系不匹配"><a href="#对象关系不匹配" class="headerlink" title="对象关系不匹配"></a>对象关系不匹配</h4><p>大部分应用程序开发都是使用面向对象的编程语言完成的。如果数据存储在关系表中，则需要在应用程序代码中的对象和数据库的表、行、列模型之间建立一个笨拙的转换层。这种模型之间的脱节有时被称为 <strong>阻抗不匹配</strong>。</p>
<h5 id="对象关系映射（ORM）"><a href="#对象关系映射（ORM）" class="headerlink" title="对象关系映射（ORM）"></a>对象关系映射（ORM）</h5><p>对象关系映射（ORM）框架（如 ActiveRecord 和 Hibernate）减少了这个转换层所需的样板代码量，但它们经常受到批评，有如下问题：</p>
<ul>
<li>ORM 很复杂，无法完全隐藏两种模型之间的差异</li>
<li>ORM 通常仅用于 OLTP 应用程序开发，为分析目的提供数据的数据工程师仍然需要使用底层的关系表示</li>
<li>许多 ORM 仅适用于关系型 OLTP 数据库</li>
<li>一些 ORM 会自动生成关系模式，但这些模式对于直接访问关系数据的用户来说可能很尴尬</li>
<li>ORM 使得意外编写低效查询变得容易，例如 <em>N+1 查询问题</em><br>ORM的优势：</li>
<li>对于非常适合关系模型的数据，ORM 减少了这种转换所需的样板代码量</li>
<li>ORM 有助于缓存数据库查询的结果，这可以帮助减少数据库的负载</li>
<li>ORM 还可以帮助管理模式迁移和其他管理活动</li>
</ul>
<h5 id="用于一对多关系的文档数据模型"><a href="#用于一对多关系的文档数据模型" class="headerlink" title="用于一对多关系的文档数据模型"></a>用于一对多关系的文档数据模型</h5><p><strong>一对多关系</strong>的关系化表达<br>![[file-20250812214919026.png]]<br>JSON 模型能减少应用程序代码和存储层之间的阻抗不匹配，但是JSON 作为数据编码格式也存在问题。JSON 表示具有更好的 _局部性_，所有相关信息都在一个地方，使查询既更快又更简单。<br>![[file-20250812215109300.png]]</p>
<h4 id="规范化、反规范化与连接"><a href="#规范化、反规范化与连接" class="headerlink" title="规范化、反规范化与连接"></a>规范化、反规范化与连接</h4><p>使用 ID，数据更加规范化：对人类有意义的信息只存储在一个地方，所有引用它的地方都使用 ID。当你直接存储文本时，你在使用它的每条记录中都复制了对人类有意义的信息；这种表示是 <em>反规范化</em> 的。</p>
<p>规范化表示的缺点是，每次要显示包含 ID 的记录时，都必须进行额外的查找以将 ID 解析为人类可读的内容。</p>
<p>文档数据库可以存储规范化和反规范化的数据，但它们通常与反规范化相关联 —— 部分是因为 JSON 数据模型使得存储额外的反规范化字段变得容易，部分是因为许多文档数据库中对连接的弱支持使得规范化不方便。</p>
<h5 id="规范化的权衡"><a href="#规范化的权衡" class="headerlink" title="规范化的权衡"></a>规范化的权衡</h5><p>作为一般原则，规范化数据通常写入更快（因为只有一个副本），但查询更慢（因为它需要连接）；反规范化数据通常读取更快（连接更少），但写入更昂贵（更多副本要更新，使用更多磁盘空间）</p>
<p>规范化往往更适合 OLTP 系统，其中读取和更新都需要快速；分析系统通常使用反规范化数据表现更好，因为它们批量执行更新，只读查询的性能是主要关注点</p>
<p>在中小规模的系统中，规范化数据模型通常是最好的，因为你不必担心保持数据的多个副本相互一致，执行连接的成本是可以接受的。然而，在非常大规模的系统中，连接的成本可能会成为问题。</p>
<h5 id="社交网络案例研究中的反规范化"><a href="#社交网络案例研究中的反规范化" class="headerlink" title="社交网络案例研究中的反规范化"></a>社交网络案例研究中的反规范化</h5><p>通过 ID 查找人类可读信息的过程称为 <em>hydrating</em> ID，它本质上是在应用程序代码中执行的连接</p>
<p>在读取数据时必须执行连接并不像有时声称的那样，是创建高性能、可扩展服务的障碍。<br><strong>规范化和反规范化本质上并不好或坏</strong> —— <strong>它们只是在读写性能以及实施工作量方面的权衡</strong>。</p>
<h4 id="多对一与多对多关系"><a href="#多对一与多对多关系" class="headerlink" title="多对一与多对多关系"></a>多对一与多对多关系</h4><p>![[Pasted image 20250813140710.png]]<br>多对一和多对多关系不容易适应一个自包含的 JSON 文档；它们更适合规范化表示。<br>![[Pasted image 20250813140803.png]]<br>规范化表示仅在一个地方存储关系，并依赖 _二级索引_来允许有效地双向查询关系。</p>
<h4 id="星型与雪花型：分析模式"><a href="#星型与雪花型：分析模式" class="headerlink" title="星型与雪花型：分析模式"></a>星型与雪花型：分析模式</h4><p>数据仓库通常是关系型的，并且数据仓库中表结构有一些广泛使用的约定：<em>星型模式_、_雪花模式_、_维度建模</em> ，以及 _一张大表_（OBT）。</p>
<p>一个可能在杂货零售商的数据仓库中找到的星型模式示例。<br>![[Pasted image 20250813141442.png]]<br>一个大型企业可能在其数据仓库中有许多 PB 的交易历史，主要表示为事实表。</p>
<p>事实表中的一些列是属性，例如产品售出的价格和从供应商那里购买它的成本（允许计算利润率）。事实表中的其他列是对其他表的外键引用，称为 <strong><em>维度表</em><strong>。由于事实表中的每一行代表一个事件，</strong>维度</strong>代表事件的 <em>谁_、_什么_、_哪里_、_何时_、_如何</em> 和 _为什么_。</p>
<ul>
<li><strong>星形模式</strong>：当表关系被可视化时，事实表位于中间，被其维度表包围；到这些表的连接就像星星的光芒。</li>
<li><strong>雪花模式</strong>：星型模式的变体，维度被进一步分解为子维度。雪花模式比星型模式更规范化，但星型模式通常更受欢迎，因为它们对分析师来说更简单</li>
</ul>
<p>星型或雪花模式主要由多对一关系组成，表示为事实表对维度表的外键，或维度对子维度的外键。<br>原则上，其他类型的关系可能存在，但它们通常被反规范化以简化查询。</p>
<p>一些数据仓库模式进一步进行反规范化，完全省略维度表，将维度中的信息折叠到事实表上的反规范化列中，这种方法被称为 **<em>一张大表</em>**（OBT），虽然它需要更多的存储空间，但有时可以实现更快的查询。</p>
<h4 id="何时使用哪种模型"><a href="#何时使用哪种模型" class="headerlink" title="何时使用哪种模型"></a>何时使用哪种模型</h4><ul>
<li>文档数据模型的主要论点是模式灵活性、由于局部性而获得更好的性能，以及对于某些应用程序来说，它更接近应用程序使用的对象模型。</li>
<li>关系模型通过为连接、多对一和多对多关系提供更好的支持来反击。</li>
</ul>
<p>应用程序中的数据具有类似文档的结构，可以使用文档模型，将类似文档的结构 _切碎_（shredding）为多个表的关系技术可能导致繁琐的模式和不必要复杂的应用程序代码。<br>一些应用程序允许用户选择项目的顺序,文档模型很好地支持此类应用程序，因为项目（或它们的 ID）可以简单地存储在 JSON 数组中以确定它们的顺序。</p>
<p>文档模型有局限性：不能直接引用文档中的嵌套项</p>
<h5 id="文档模型中的模式灵活性"><a href="#文档模型中的模式灵活性" class="headerlink" title="文档模型中的模式灵活性"></a>文档模型中的模式灵活性</h5><p><strong>大多数文档数据库以及关系数据库中的 JSON 支持不会对文档中的数据强制执行任何模式。</strong></p>
<ul>
<li>**<em>读时模式</em>**：数据的结构是隐式的，只有在读取数据时才解释，文档数据库</li>
<li>**<em>写时模式</em>**：关系数据库的传统方法，其中模式是显式的，数据库确保所有数据在写入时都符合它</li>
</ul>
<p>读时模式类似于编程语言中的动态（运行时）类型检查，而写时模式类似于静态（编译时）类型检查。</p>
<p>如果集合中的项目由于某种原因并非都具有相同的结构则读时模式方法是有利的 —— 例如，因为：</p>
<ul>
<li>有许多不同类型的对象，将每种类型的对象放在自己的表中是不切实际的。</li>
<li>数据的结构由你无法控制且可能随时更改的外部系统决定。</li>
</ul>
<h5 id="读写的数据局部性"><a href="#读写的数据局部性" class="headerlink" title="读写的数据局部性"></a>读写的数据局部性</h5><p>文档通常存储为单个连续字符串，编码为 JSON、XML 或二进制变体（如 MongoDB 的 BSON）。如果你的应用程序经常需要访问整个文档（例如，在网页上渲染它），则这种 <strong><em>存储局部性</em> 具有性能优势。</strong></p>
<p>将相关数据存储在一起以获得局部性的想法并不限于文档模型。Google 的 Spanner 数据库在关系数据模型中提供相同的局部性属性，允许模式声明表的行应该交错（嵌套）在父表中；由 Google 的 Bigtable 推广并在 HBase 和 Accumulo 等中使用的 <em>宽列</em> 数据模型具有 <em>列族</em> 的概念，其目的类似于管理局部性。</p>
<h5 id="文档的查询语言"><a href="#文档的查询语言" class="headerlink" title="文档的查询语言"></a>文档的查询语言</h5><p>关系数据库和文档数据库之间的另一个区别是你用来查询它的语言或 API。大多数关系数据库使用 SQL 查询，但文档数据库更加多样化。</p>
<ul>
<li>XML 数据库通常使用 XQuery 和 XPath 查询，它们旨在允许复杂的查询，包括跨多个文档的连接，并将其结果格式化为 XML</li>
<li>JSON Pointer 和 JSONPath 为 JSON 提供了等效于 XPath 的功能。</li>
<li>MongoDB 的聚合管道，其用于连接的 <code>$lookup</code> 运算符，是 JSON 文档集合查询语言的一个例子。</li>
</ul>
<h5 id="文档和关系数据库的融合"><a href="#文档和关系数据库的融合" class="headerlink" title="文档和关系数据库的融合"></a>文档和关系数据库的融合</h5><p>关系数据库增加了对 JSON 类型和查询运算符的支持，以及索引文档内属性的能力。一些文档数据库（如 MongoDB、Couchbase 和 RethinkDB）增加了对连接、二级索引和声明式查询语言的支持。</p>
<p>关系-文档混合是一个强大的组合。</p>
<h3 id="图数据模型"><a href="#图数据模型" class="headerlink" title="图数据模型"></a>图数据模型</h3><p>图由两种对象组成：_顶点_（也称为 <em>节点</em> 或 _实体_）和 _边_（也称为 <em>关系</em> 或 _弧_）。许多类型的数据可以建模为图。典型的例子包括：</p>
<ul>
<li><strong>社交图</strong>：顶点是人，边表示哪些人相互认识。</li>
<li><strong>网页图</strong>：顶点是网页，边表示指向其他页面的 HTML 链接。</li>
<li><strong>道路或铁路网络</strong>：顶点是交叉点，边表示它们之间的道路或铁路线。</li>
</ul>
<p>图的表示方式：</p>
<ul>
<li>**<em>邻接表</em>**：每个顶点存储其相距一条边的邻居顶点的 ID。以使用 _邻接矩阵_，这是一个二维数组，其中每一行和每一列对应一个顶点，当行顶点和列顶点之间没有边时值为零，如果有边则值为一。邻接表适合图遍历，矩阵适合机器学习</li>
</ul>
<p>同质数据图&#x2F;非同质数据图</p>
<p>图的构建和查询数据的方式：</p>
<ul>
<li><em>属性图</em> 模型（由 Neo4j、Memgraph、KùzuDB  和其他 实现）</li>
<li><em>三元组存储</em> 模型（由 Datomic、AllegroGraph、Blazegraph 和其他实现）</li>
<li>图的四种查询语言（Cypher、SPARQL、Datalog 和 GraphQL）</li>
</ul>
<h4 id="属性图"><a href="#属性图" class="headerlink" title="属性图"></a>属性图</h4><p>在 _属性图_（也称为 _标记属性图_）模型中，将图存储视为由两个关系表组成，一个用于顶点，一个用于边。每个顶点包含：</p>
<ul>
<li>唯一标识符</li>
<li>标签（字符串），描述此顶点表示的对象类型</li>
<li>一组出边</li>
<li>一组入边</li>
<li>属性集合（键值对）<br>每条边包含：</li>
<li>唯一标识符</li>
<li>边开始的顶点（_尾顶点_）</li>
<li>边结束的顶点（_头顶点_）</li>
<li>描述两个顶点之间关系类型的标签</li>
<li>属性集合（键值对）</li>
</ul>
<p>此模型的一些重要方面是：</p>
<ol>
<li>任何顶点都可以有一条边将其与任何其他顶点连接。</li>
<li>给定任何顶点，你可以有效地找到其入边和出边，从而 <em>遍历</em> 图</li>
<li>通过对不同类型的顶点和关系使用不同的标签，你可以在单个图中存储几种不同类型的信息，同时仍保持简洁的数据模型。</li>
</ol>
<h4 id="Cypher-查询语言"><a href="#Cypher-查询语言" class="headerlink" title="Cypher 查询语言"></a>Cypher 查询语言</h4><p><em>Cypher</em> 是用于属性图的查询语言，最初为 Neo4j 图数据库创建，后来作为 <em>openCypher</em> 发展为开放标准<br>除了 Neo4j，Cypher 还得到 Memgraph、KùzuDB、Amazon Neptune、Apache AGE（在 PostgreSQL 中存储）等的支持。它以电影《黑客帝国》中的角色命名，与密码学中的密码无关</p>
<h4 id="SQL-中的图查询"><a href="#SQL-中的图查询" class="headerlink" title="SQL 中的图查询"></a>SQL 中的图查询</h4><p>在关系数据库中，你通常事先知道查询中需要哪些连接。另一方面，在图查询中，你可能需要遍历可变数量的边才能找到你要查找的顶点 —— 也就是说，连接的数量不是预先固定的。</p>
<ul>
<li>在 Cypher 中，<code>:WITHIN*0..</code> 非常简洁地表达了这个事实：它意味着”跟随 <code>WITHIN</code> 边，零次或多次”。它就像正则表达式中的 <code>*</code> 运算符。</li>
<li>SQL:1999 以来，查询中可变长度遍历路径的想法可以使用称为 _递归公用表表达式_（<code>WITH RECURSIVE</code> 语法）的东西来表达。</li>
</ul>
<p>4 行 Cypher 查询需要 31 行 SQL 的事实表明，正确选择数据模型和查询语言可以产生多大的差异。</p>
<p>有计划向 SQL 标准添加一种名为 GQL 的图查询语言，它将提供受 Cypher、GSQL  和 PGQL 启发的语法。</p>
<h4 id="三元组存储与-SPARQL"><a href="#三元组存储与-SPARQL" class="headerlink" title="三元组存储与 SPARQL"></a>三元组存储与 SPARQL</h4><p>元组存储模型大多等同于属性图模型</p>
<p>在三元组存储中，所有信息都以非常简单的三部分语句的形式存储：（<em>主语_、_谓语_、_宾语_）。例如，在三元组（_Jim_、_likes_、_bananas_）中，_Jim</em> 是主语，<em>likes</em> 是谓语（动词），<em>bananas</em> 是宾语。</p>
<p>三元组的主语等同于图中的顶点。宾语是两种东西之一：</p>
<ol>
<li>原始数据类型的值，如字符串或数字。在这种情况下，三元组的谓语和宾语等同于主语顶点上属性的键和值。</li>
<li>图中的另一个顶点。在这种情况下，谓语是图中的边，主语是尾顶点，宾语是头顶点。</li>
</ol>
<p>三元组存储是另一种在其原始用例之外找到用途的语义网技术：即使你对语义网没有兴趣，三元组也可以成为应用程序的良好内部数据模型。</p>
<h5 id="RDF-数据模型"><a href="#RDF-数据模型" class="headerlink" title="RDF 数据模型"></a>RDF 数据模型</h5><p>Turtle 语言实际上是在 _资源描述框架_（RDF）<a target="_blank" rel="noopener" href="http://ddia.vonng.com/ch3/#fn:55">55</a> 中编码数据的一种方式，这是为语义网设计的数据模型。RDF 数据也可以用其他方式编码，例如（更冗长地）用 XML</p>
<h5 id="SPARQL-查询语言"><a href="#SPARQL-查询语言" class="headerlink" title="SPARQL 查询语言"></a>SPARQL 查询语言</h5><p><em>SPARQL</em> 是使用 RDF 数据模型的三元组存储的查询语言（它是 <em>SPARQL Protocol and RDF Query Language</em> 的首字母缩略词，发音为 “sparkle”。）<br>它早于 Cypher，由于 Cypher 的模式匹配是从 SPARQL 借用的，它们看起来非常相似。</p>
<p>SPARQL 得到 Amazon Neptune、AllegroGraph、Blazegraph、OpenLink Virtuoso、Apache Jena 和各种其他三元组存储的支持</p>
<h4 id="Datalog：递归关系查询"><a href="#Datalog：递归关系查询" class="headerlink" title="Datalog：递归关系查询"></a>Datalog：递归关系查询</h4><p>Datalog 是一种比 SPARQL 或 Cypher 更古老的语言：它源于 20 世纪 80 年代的学术研究</p>
<p>它是一种非常有表现力的语言，对于复杂查询特别强大。几个小众数据库，包括 Datomic、LogicBlox、CozoDB 和 LinkedIn 的 LIquid使用 Datalog 作为它们的查询语言。</p>
<p>Datalog 实际上基于关系数据模型，递归查询是 Datalog 的特殊优势。</p>
<p>Datalog 数据库的内容由 <em>事实</em> 组成，每个事实对应于关系表中的一行。<br>Datalog 是 Prolog 的子集，这是一种编程语言，如果你学过计算机科学，你可能见过它。</p>
<h4 id="GraphQL"><a href="#GraphQL" class="headerlink" title="GraphQL"></a>GraphQL</h4><p>GraphQL 是一种查询语言，从设计上讲，它比我们在本章中看到的其他查询语言限制性更强。<br>目的是允许在用户设备上运行的客户端软件（如移动应用程序或 JavaScript Web 应用程序前端）请求具有特定结构的 JSON 文档，其中包含渲染其用户界面所需的字段。GraphQL 接口允许开发人员快速更改客户端代码中的查询，而无需更改服务器端 API。</p>
<p>采用 GraphQL 的组织通常需要工具将 GraphQL 查询转换为对内部服务的请求，这些服务通常使用 REST 或 gRPC</p>
<p>GraphQL 不允许递归查询（与 Cypher、SPARQL、SQL 或 Datalog 不同），并且不允许任意搜索条件</p>
<h3 id="事件溯源与-CQRS"><a href="#事件溯源与-CQRS" class="headerlink" title="事件溯源与 CQRS"></a>事件溯源与 CQRS</h3><p>迄今为止讨论的所有数据模型中，数据以与写入相同的形式被查询 —— 无论是 JSON 文档、表中的行，还是图中的顶点和边。</p>
<p>使用事件作为真相源，并将每个状态变化表达为事件的想法被称为 **<em>事件溯源</em>**。<br>维护单独的读优化表示并从写优化表示派生它们的原则称为 <strong>_命令查询责任分离</strong>（CQRS）_</p>
<p>事件溯源与星型模式事实表之间的相似之处：事件溯源与星型模式事实表之间的相似之处</p>
<ul>
<li>事实表中的行都具有相同的列集</li>
<li>事件溯源中可能有许多不同的事件类型，每种都有不同的属性。事实表是无序集合<br>事件溯源和 CQRS 有几个优点：</li>
<li>事件更好地传达了 <em>为什么</em> 发生某事的意图</li>
<li>事件溯源的关键原则是物化视图以可重现的方式从事件日志派生</li>
<li>可以有多个物化视图，针对应用程序所需的特定查询进行优化。</li>
<li>以新方式呈现现有信息，很容易从现有事件日志构建新的物化视图。<br>事件溯源和 CQRS 也有缺点：</li>
<li>如果涉及外部信息，可能会得到不同的结果</li>
<li>事件不可变的要求会在事件包含用户的个人数据时产生问题，因为用户可能行使他们的权利（例如，根据 GDPR）请求删除他们的数据</li>
<li>如果存在外部可见的副作用，重新处理事件需要小心</li>
</ul>
<p>有一些专业系统：EventStoreDB、MartenDB（基于 PostgreSQL）和 Axon Framework，还可以使用消息代理（如 Apache Kafka）来存储事件日志</p>
<p>唯一重要的要求是事件存储系统必须保证所有物化视图以与它们在日志中出现的完全相同的顺序处理事件</p>
<h3 id="数据框、矩阵与数组"><a href="#数据框、矩阵与数组" class="headerlink" title="数据框、矩阵与数组"></a>数据框、矩阵与数组</h3><p>数据框：R 语言、Python 的 Pandas 库、Apache Spark、ArcticDB、Dask 和其他系统支持的数据模型。它们是数据科学家为训练机器学习模型准备数据的流行工具，但它们也广泛用于数据探索、统计数据分析、数据可视化和类似目的。</p>
<p>数据框通常不是通过声明式查询（如 SQL）而是通过一系列修改其结构和内容的命令来操作的。<br>![[Pasted image 20250813161537.png]]</p>
<p>矩阵只能包含数字，各种技术用于将非数字数据转换为矩阵中的数字。例如：日期缩放、独热编码<br>数据以数字矩阵的形式存在，它就适合线性代数运算。<br>数据框足够灵活，允许数据从关系形式逐渐演变为矩阵表示，同时让数据科学家控制最适合实现数据分析或模型训练过程目标的表示。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><em>关系模型</em> 尽管已有半个多世纪的历史，但对许多应用来说仍然是一个重要的数据模型——特别是在数据仓库和商业分析中，关系星型或雪花模式和 SQL 查询无处不在。然而，关系数据的几种替代方案也在其他领域变得流行：</p>
<ul>
<li><em>文档模型</em> 针对数据以独立的 JSON 文档形式出现的用例，以及一个文档与另一个文档之间的关系很少的情况。</li>
<li><em>图数据模型</em> 走向相反的方向，针对任何东西都可能与一切相关的用例，以及查询可能需要遍历多个跳跃才能找到感兴趣的数据（可以使用 Cypher、SPARQL 或 Datalog 中的递归查询来表达）。</li>
<li><em>数据框</em> 将关系数据推广到大量列，从而在数据库和构成大量机器学习、统计数据分析和科学计算基础的多维数组之间提供桥梁。</li>
</ul>
<h2 id="4-存储与检索"><a href="#4-存储与检索" class="headerlink" title="4. 存储与检索"></a>4. 存储与检索</h2><p>数据库如何存储你提供的数据，以及当你请求时如何再次找到这些数据。<br>事务型工作负载（OLTP）优化的存储引擎和针对分析型工作负载优化的存储引擎之间存在巨大差异</p>
<h2 id="OLTP-系统的存储与索引"><a href="#OLTP-系统的存储与索引" class="headerlink" title="OLTP 系统的存储与索引"></a>OLTP 系统的存储与索引</h2><p>世界上最简单的数据库</p>
<pre><code class="bash">#!/bin/bash
db_set () &#123;
  echo &quot;$1,$2&quot; &gt;&gt; database
&#125;

db_get () &#123;
  grep &quot;^$1,&quot; database | sed -e &quot;s/^$1,//&quot; | tail -n 1
&#125;```

这两个函数实现了一个键值存储。你可以调用 `db_set key value`，它将在数据库中存储 `key` 和 `value`。

为了高效地找到数据库中特定键的值，我们需要一个不同的数据结构：_索引_。

索引是从主数据派生出的 _额外_ 结构。许多数据库允许你添加和删除索引，这不会影响数据库的内容；它只影响查询的性能。
维护额外的结构会产生开销，特别是在写入时。对于写入，很难超越简单地追加到文件的性能，因为这是最简单的写入操作。**任何类型的索引通常都会减慢写入速度**，因为每次写入数据时也需要更新索引。

数据库通常不会默认为所有内容建立索引，而是要求你 —— 编写应用程序或管理数据库的人 —— 使用你对应用程序典型查询模式的了解来手动选择索引。

#### 日志结构存储

继续将数据存储在 `db_set` 写入的仅追加文件中，你只是想加快读取速度。一种方法是在内存中保留一个哈希映射，其中每个键都映射到文件中可以找到该键最新值的字节偏移量
![[Pasted image 20250815105925.png]]
向文件追加新的键值对时，你也会更新哈希映射以反映刚刚写入数据的偏移量。
存在几个问题：
- 永远不会释放被覆盖的旧日志条目占用的磁盘空间；如果你不断写入数据库，可能会耗尽磁盘空间。
- 哈希映射不是持久化的，所以当你重启数据库时必须重建它
- 哈希表必须适合内存。原则上，你可以在磁盘上维护哈希表，但不幸的是，很难让磁盘上的哈希映射表现良好。
- 范围查询效率不高。

##### SSTable 文件格式

实际上，哈希表很少用于数据库索引，相反，保持数据 _按键排序_ 的结构更为常见
这种结构的一个例子是 _排序字符串表_（_Sorted String Table_），简称 _SSTable_，这种文件格式也存储键值对，但它确保它们按键排序，每个键在文件中只出现一次。
![[Pasted image 20250815143608.png]]

将 SSTable 中的键值对分组为几千字节的 _块_，然后在索引中存储每个块的第一个键。这种只存储部分键的索引称为 _稀疏_ 索引。这个索引存储在 SSTable 的单独部分，例如使用不可变 B 树、字典树或其他允许查询快速查找特定键的数据结构。

一个块的第一个键是 `handbag`，下一个块的第一个键是 `handsome`。现在假设你要查找键 `handiwork`，它没有出现在稀疏索引中。由于排序，你知道 `handiwork` 必须出现在 `handbag` 和 `handsome` 之间。这意味着你可以寻找到 `handbag` 的偏移量，然后从那里扫描文件，直到找到 `handiwork`

每个记录块都可以压缩，除了节省磁盘空间外，压缩还减少了 I/O 带宽使用，代价是使用更多一点的 CPU 时间。

##### 构建和合并 SSTable

SSTable 文件格式在读取方面比仅追加日志更好，但它使写入更加困难。
每次在中间某处插入键时都必须重写整个 SSTable，写入将变得太昂贵。

可以用 _日志结构_ 方法解决这个问题，这是仅追加日志和排序文件之间的混合：
1. 当写入操作到来时，将其添加到内存中的有序映射数据结构中，例如红黑树、跳表 或字典树。使用这些数据结构，你可以按任意顺序插入键，高效地查找它们，并按排序顺序读回它们。这个内存数据结构称为 _内存表_（_memtable_）。
2. 当内存表变得大于某个阈值（通常是几兆字节）时，将其按排序顺序作为 SSTable 文件写入磁盘。我们将这个新的 SSTable 文件称为数据库的最新 _段_，它与旧段一起作为单独的文件存储。每个段都有自己内容的单独索引。当新段被写入磁盘时，数据库可以继续写入新的内存表实例，当 SSTable 写入完成时，旧内存表的内存被释放。
3. 为了读取某个键的值，首先尝试在内存表和最新的磁盘段中找到该键。如果没有找到，就在下一个较旧的段中查找，依此类推，直到找到键或到达最旧的段。如果键没有出现在任何段中，则它不存在于数据库中。
4. 不地在后台运行合并和压实过程，以合并段文件并丢弃被覆盖或删除的值。

合并段的工作方式类似于 _归并排序_ 算法：
并排开始读取输入文件，查看每个文件中的第一个键，将最低的键（根据排序顺序）复制到输出文件，然后重复。如果同一个键出现在多个输入文件中，只保留较新的值。这会产生一个新的合并段文件，也按键排序，每个键只有一个值，并且它使用最少的内存，因为我们可以一次遍历一个键的 SSTable。
![[Pasted image 20250815150221.png]]

为了确保数据库崩溃时内存表中的数据不会丢失，存储引擎在磁盘上保留一个单独的日志，每次写入都会立即追加到该日志中。此日志不按键排序，但这无关紧要，因为它的唯一目的是在崩溃后恢复内存表。每次内存表被写出到 SSTable 后，日志的相应部分就可以丢弃。

如果你想删除一个键及其关联的值，你必须向数据文件追加一个称为 _墓碑_（_tombstone_）的特殊删除记录。当日志段合并时，墓碑告诉合并过程丢弃已删除键的任何先前值。一旦墓碑合并到最旧的段中，它就可以被丢弃。

这里描述的算法本质上就是 **RocksDB、Cassandra、Scylla 和 HBase** 中使用的算法，它们都受到 Google 的 Bigtable 论文 9 的启发

1996 年以 _日志结构合并树_（_Log-Structured Merge-Tree_）或 _LSM 树_（_LSM-Tree_）的名称发布，建立在早期日志结构文件系统工作的基础上 。因此，基于合并和压实排序文件原理的存储引擎通常被称为 _LSM 存储引擎_。

在 LSM 存储引擎中，**段文件是一次性写入**的（通过写出内存表或合并一些现有段），此后它是不可变的。段的合并和压实可以在后台线程中完成，当它进行时，我们**仍然可以使用旧的段文件继续提供读取服务**。当合并过程完成时，我们将读取请求切换到使用新的合并段而不是旧段，然后可以删除旧的段文件。

段文件也非常适合写入对象存储。

如果在写出内存表或合并段时发生崩溃，数据库可以删除未完成的 SSTable 并重新开始。

##### 布隆过滤器

使用 LSM 存储，**读取很久以前更新的键或不存在的键可能会很慢**，因为存储引擎需要检查多个段文件。为了加快此类读取，LSM 存储引擎通常在每个段中包含一个 _布隆过滤器_（_Bloom filter_），它提供了一种快速但近似的方法来检查特定键是否出现在特定 SSTable 中。

一个包含两个键和 16 位的布隆过滤器示例：
![[Pasted image 20250815152322.png]]对于 SSTable 中的每个键，我们计算一个哈希函数，产生一组数字，然后将其解释为位数组的索引
将对应于这些索引的位设置为 1，其余保持为 0。例如，键 `handbag` 哈希为数字 (2, 9, 4)，所以我们将第 2、9 和 4 位设置为 1。然后将**位图与键的稀疏索引**一起存储为 SSTable 的一部分。这需要一点额外的空间，但与 SSTable 的其余部分相比，布隆过滤器通常很小。

- **查询不在**：如果至少有一个位是 0，我们知道该键肯定不在 SSTable 中。
- **查询可能在**：如果查询中的位都是 1，那么该键很可能在 SSTable 中，但也有可能是巧合，所有这些位都被其他键设置为 1。这种看起来键存在但实际上不存在的情况称为 **_假阳性_**（_false positive_）。
假阳性的概率取决于键的数量、每个键设置的位数和布隆过滤器中的总位数。

经验法则：为 SSTable 中的每个键分配 10 位布隆过滤器空间以获得 1% 的假阳性概率，每为每个键分配额外的 5 位，概率就会降低十倍。

##### 压实策略

SM 存储如何选择何时执行压实，以及在压实中包括哪些 SSTable。许多基于 LSM 的存储系统允许你配置使用哪种压实策略，常见选择如下：
- **分层压实**：较新和较小的 SSTable 依次合并到较旧和较大的 SSTable 中，可以处理非常高的写入吞吐量
- **分级压实**：键范围被分成较小的 SSTable，较旧的数据被移动到单独的&quot;级别&quot;中，这允许压实更增量地进行，并且比分层策略使用更少的磁盘空间。这种策略对于读取比分层压实更有效，因为存储引擎需要读取更少的 SSTable 来检查它们是否包含该键。

**经验法则**：如果你主要有写入而读取很少，分层压实表现更好，而如果你的工作负载以读取为主，分级压实表现更好。

**嵌入式存储引擎**的例子包括 RocksDB、SQLite、LMDB、DuckDB 和 KùzuDB。在与应用程序代码相同的进程中运行的库，通常读取和写入本地磁盘上的文件，你通过正常的函数调用与它们交互。

#### B 树

按键读取和写入数据库记录最广泛使用的结构是 _B 树_。
1970 年引入B树，几乎所有关系数据库中的标准索引实现，许多非关系数据库也使用它们。
像 SSTable 一样，B 树按键保持键值对排序，这允许高效的键值查找和范围查询

**B 树有着非常不同的设计理念。**

- LSM：将数据库分解为可变大小的 _段_，通常为几兆字节或更大，写入一次后就不可变。
- B树：将数据库分解为固定大小的 _块_ 或 _页_，并可能就地覆盖页。页传统上大小为 4 KiB，但 PostgreSQL 现在默认使用 8 KiB，MySQL 默认使用 16 KiB。

每个页都可以使用页号来标识，这允许一个页引用另一个页 —— 类似于指针，但在磁盘上而不是在内存中。如果所有页都存储在同一个文件中，将页号乘以页大小就给我们文件中页所在位置的字节偏移量。我们可以使用这些页引用来构建页树
![[Pasted image 20250815154238.png]]一个页被指定为 B 树的 _根_；每当你想在索引中查找一个键时，你就从这里开始。该页包含几个键和对子页的引用。每个子负责一个连续的键范围，引用之间的键指示这些范围之间的边界在哪里。

B 树的一个页中对子页的引用数称为 _分支因子_。分支因子取决于存储页引用和范围边界所需的空间量，但通常为几百。

更新 B 树中现有键的值，你搜索包含该键的叶页，并用包含新值的版本覆盖磁盘上的该页。如果你想添加一个新键，你需要找到其范围包含新键的页并将其添加到该页。如果页中没有足够的空闲空间来容纳新键，则页被分成两个半满的页，并更新父页以说明键范围的新细分。
![[Pasted image 20250815154759.png]]想插入键 334，但范围 333–345 的页已经满了。因此，我们将其分成范围 333–337（包括新键）的页和 337–344 的页。我们还必须更新父页以引用两个子页，它们之间的边界值为 337。如果父页没有足够的空间容纳新引用，它也可能需要被分割，分割可以一直持续到树的根。当根被分割时，我们在它上面创建一个新根。

这个算法确保树保持 _平衡_：具有 _n_ 个键的 B 树始终具有 _O_(log _n_) 的深度。大多数数据库可以适合三或四层深的 B 树，所以你不需要跟随许多页引用来找到你要查找的页。

##### 使 B 树可靠

B 树的基本底层写操作是用新数据覆盖磁盘上的页。
一次覆盖多个页，如在页分割中，是一个危险的操作：如果数据库在只写入了部分页后崩溃，你最终会得到一个损坏的树（例如，可能有一个 _孤立_ 页，它不是任何父页的子页）。如果硬件不能原子地写入整个页，你也可能最终得到部分写入的页（这称为 _撕裂页_（_torn page_））。

为了使数据库对崩溃具有弹性，B 树实现通常包括磁盘上的额外数据结构：**_预写日志_**（_write-ahead log_，WAL）。这是一个仅追加文件，每个 B 树修改必须在应用于树本身的页之前写入其中。当数据库在崩溃后恢复时，此日志用于将 B 树恢复到一致状态

为了提高性能，B 树实现通常不会立即将每个修改的页写入磁盘，而是**首先将 B 树页缓冲在内存**中一段时间。预写日志还确保在崩溃的情况下数据不会丢失：**只要数据已写入 WAL，并使用 `fsync()` 系统调用刷新到磁盘，数据就是持久的**，因为数据库将能够在崩溃后恢复它

##### B 树变体

- 一些数据库（如 LMDB）使用写时复制方案，而不是覆盖页并维护 WAL 以进行崩溃恢复。
- 通过不存储整个键而是缩写它来节省页中的空间。特别是在树内部的页中，键只需要提供足够的信息来充当键范围之间的边界。
- 为了加快按排序顺序扫描键范围，一些 B 树实现尝试布局树，使叶页按顺序出现在磁盘上，减少磁盘寻道次数。

#### 比较 B 树与 LSM 树

**经验法则**：LSM 树更适合写入密集型应用，而 B 树对读取更快。
存储引擎有时会混合两种方法的特征，例如具有多个 B 树并以 LSM 风格合并它们。
##### 读取性能

- B树：在 B 树中，查找键涉及在 B 树的每个级别读取一个页。由于级别数通常很小，这意味着从 B 树读取通常很快并且具有可预测的性能。
- LSM：在 LSM 存储引擎中，读取通常必须检查处于不同压实阶段的几个不同 SSTable，但布隆过滤器有助于减少所需的实际磁盘 I/O 操作数。

在 LSM 存储引擎中，读取通常必须检查处于不同压实阶段的几个不同 SSTable，但布隆过滤器有助于减少所需的实际磁盘 I/O 操作数。使得**范围查询在 LSM 方法中比点查询更昂贵**

现代 SSD（特别是 NVMe）可以并行执行许多独立的读请求。LSM 树和 B 树都能够提供高读取吞吐量，但存储引擎需要仔细设计以利用这种并行性

##### 顺序与随机写入

- B树：如果应用程序写入的键分散在整个键空间中，生成的磁盘操作也会随机分散，因为存储引擎需要覆盖的页可能位于磁盘的任何位置。
- LSM：日志结构存储引擎一次写入整个段文件（无论是写出内存表还是压实现有段），这比 B 树中的页大得多。

许多小的、分散的写入模式（如 B 树中的）称为 **_随机写入_**，而较少的大写入模式（如 LSM 树中的）称为 **_顺序写入_**。磁盘通常具有比随机写入更高的顺序写入吞吐量，这意味着**日志结构存储引擎通常可以在相同硬件上处理比 B 树更高的写入吞吐量**。这种差异在旋转磁盘硬盘（HDD）上特别大；在今天大多数数据库使用的固态硬盘（SSD）上，差异较小，但仍然明显

- 旋转磁盘硬盘（HDD）上，**顺序写入比随机写入快得多**：随机写入必须机械地将磁头移动到新位置，并等待盘片的正确部分经过磁头下方，这需要几毫秒 —— 在计算时间尺度上是永恒的。
- SSD（固态硬盘）包括 NVMe（非易失性内存快速，即连接到 PCI Express 总线的闪存）现在已经在许多用例中超越了 HDD，它们不受这种机械限制。SSD 对**顺序写入的吞吐量也高于随机写入**。原因是闪存可以一次读取或写入一页（通常为 4 KiB），但**只能一次擦除一个块**。块中的某些页可能包含有效数据，而其他页可能包含不再需要的数据。在擦除块之前，控制器必须首先将包含有效数据的页移动到其他块中；这个过程称为 **_垃圾回收_**（GC）

##### 写放大

对于任何类型的存储引擎，来自应用程序的一次写请求都会转换为底层磁盘上的多个 I/O 操作。

- 对于 LSM 树，一个值首先被写入日志以保证持久性，然后在内存表写入磁盘时再次写入，并且每次键值对参与压实时再次写入。
- B 树索引必须至少写入每条数据两次：一次写入预写日志，一次写入树页本身。此外，它们有时需要写出整个页，即使该页中只有几个字节发生了变化，以确保 B 树在崩溃或断电后可以正确恢复

如果你获取在某个工作负载中写入磁盘的总字节数，然后除以如果你只是写入没有索引的仅追加日志需要写入的字节数，你就得到了 **_写放大_**。

写放大是 LSM 树和 B 树中的问题。哪个更好取决于各种因素，例如键和值的长度，以及你覆盖现有键与插入新键的频率

LSM 树往往具有较低的写放大，因为它们不必写入整个页，并且可以压缩 SSTable 的块

##### 磁盘空间使用

**_主键_ 索引**：主键唯一标识关系表中的一行，或文档数据库中的一个文档，或图数据库中的一个顶点。数据库中的其他记录可以通过其主键（或 ID）引用该行/文档/顶点，索引用于解析此类引用。

**_二级索引_**：可以使用 `CREATE INDEX` 命令在同一个表上创建多个二级索引，允许你按主键以外的列进行搜索。在二级索引中，索引值不一定是唯一的；也就是说，同一索引条目下可能有许多行（文档、顶点）。这可以通过两种方式解决：要么使索引中的每个值成为匹配行标识符的列表（如全文索引中的倒排列表），要么通过向其追加行标识符使每个条目唯一。具有就地更新的存储引擎（如 B 树）和日志结构存储都可用于实现索引。


##### 在索引中存储值

索引中的键是查询搜索的内容，但值可以是几种东西之一：
- 如果实际数据（行、文档、顶点）直接存储在索引结构中，则称为 _聚簇索引_。例如，在 MySQL 的 InnoDB 存储引擎中，表的主键始终是聚簇索引
- 值可以是对实际数据的引用：要么是相关行的主键（InnoDB 对二级索引这样做），要么是对磁盘上位置的直接引用。在后一种情况下，存储行的地方称为 _堆文件_，它以无特定顺序存储数据（它可能是仅追加的，或者它可能跟踪已删除的行以便稍后用新数据覆盖它们）。例如，Postgres 使用堆文件方法
- 两者之间的折中是 _覆盖索引_ 或 _包含列的索引_，它在索引中存储表的 _某些_ 列，除了在堆上或主键聚簇索引中存储完整行

#### 全内存存储

随着 RAM 变得更便宜，每千兆字节成本的论点被侵蚀。许多数据集根本不是那么大，因此将它们完全保留在内存中是完全可行的，可能分布在几台机器上。这导致了 _内存数据库_ 的发展。

一些内存键值存储，例如 Memcached，仅用于缓存，如果机器重新启动，数据丢失是可以接受的。但其他内存数据库旨在实现持久性，这可以通过特殊硬件（例如电池供电的 RAM）、将更改日志写入磁盘、将定期快照写入磁盘或将内存状态复制到其他机器来实现。

VoltDB、SingleStore 和 Oracle TimesTen 等产品是具有关系模型的内存数据库

Redis 和 Couchbase 通过异步写入磁盘提供弱持久性。

内存数据库的另一个有趣领域是提供难以使用基于磁盘的索引实现的数据模型。例如，Redis 为各种数据结构（例如优先队列和集合）提供类似数据库的接口。因为它将所有数据保留在内存中，其实现相对简单。

### 分析型数据存储

表面上，数据仓库和关系型 OLTP 数据库看起来很相似，因为它们都有 SQL 查询接口。然而，系统的内部可能看起来完全不同，因为它们针对非常不同的查询模式进行了优化。许多数据库供应商现在专注于支持事务处理或分析工作负载，但不是两者兼而有之。

一些数据库，如 Microsoft SQL Server、SAP HANA 和 SingleStore，在同一产品中支持事务处理和数据仓库。

#### 云数据仓库

与传统数据仓库不同，云数据仓库利用可扩展的云基础设施，如对象存储和无服务器计算平台。

Apache Hive、Trino 和 Apache Spark 等开源数据仓库也随着云的发展而发展。随着分析数据存储转移到对象存储上的数据湖，开源仓库已经开始分解：
- **查询引擎**：Trino、Apache DataFusion 和 Presto 等查询引擎解析 SQL 查询，将其优化为执行计划，并针对数据执行它们。执行通常需要并行、分布式数据处理任务。一些查询引擎提供内置任务执行，而其他选择使用第三方执行框架，如 Apache Spark 或 Apache Flink。
- **存储格式**：存储格式确定表的行如何编码为文件中的字节，然后通常存储在对象存储或分布式文件系统中。此类存储格式的示例包括 Parquet、ORC、Lance 或 Nimble
- **表格式**：以 Apache Parquet 和类似存储格式编写的文件一旦编写通常是不可变的。为了支持行插入和删除，使用 Apache Iceberg 或 Databricks 的 Delta 格式等表格式。表格式指定定义哪些文件构成表以及表模式的文件格式。此类格式还提供高级功能，例如时间旅行（查询表在以前时间点的能力）、垃圾回收，甚至事务。
- **数据目录**：就像表格式定义哪些文件构成表一样，数据目录定义哪些表组成数据库。目录用于创建、重命名和删除表。与存储和表格式不同，Snowflake 的 Polaris 和 Databricks 的 Unity Catalog 等数据目录通常作为可以使用 REST 接口查询的独立服务运行。Apache Iceberg 也提供目录，可以在客户端内运行或作为单独的进程运行。

#### 列式存储

数据仓库按照惯例通常使用带有大型事实表的关系模式，该表包含对维度表的外键引用。
在本节中我们将重点关注事实的存储。

典型的数据仓库查询一次只访问其中的 4 或 5 列。
大多数 OLTP 数据库中，存储是以 _面向行_ 的方式布局的：表中一行的所有值彼此相邻存储。文档数据库类似：整个文档通常作为一个连续的字节序列存储。

_面向列_（或 _列式_）存储背后的想法很简单：不要将一行中的所有值存储在一起，而是将每 _列_ 中的所有值存储在一起。如果每列单独存储，查询只需要读取和解析该查询中使用的那些列，这可以节省大量工作。
![[Pasted image 20250815191357.png]]

列式存储引擎并不真的一次存储整个列（可能包含数万亿行）。相反，它们将表分解为数千或数百万行的块，并且在每个块内，它们分别存储每列的值

由于许多查询都限制在特定的日期范围内，因此通常使每个块包含特定时间戳范围的行。然后查询只需要在与所需日期范围重叠的那些块中加载它需要的列。

列式存储如今几乎用于所有分析数据库，从大规模云数据仓库（如 Snowflake ）到单节点嵌入式数据库（如 DuckDB ），以及产品分析系统（如 Pinot 和 Druid ）。它用于存储格式，如 Parquet、ORC 、Lance 和 Nimble，以及内存分析格式，如 Apache Arrow   和 Pandas/NumPy。一些时间序列数据库，如 InfluxDB IOx 和 TimescaleDB，也基于面向列的存储。

##### 列压缩

在数据仓库中特别有效的一种技术是 _位图编码_，可以将具有 _n_ 个不同值的列转换为 _n_ 个单独的位图：每个不同值一个位图，每行一位。如果该行具有该值，则该位为 1，否则为 0。
![[file-20250816215228398.png]]


位图索引非常适合数据仓库中常见的查询类型，位图也可用于回答图查询

不要将**面向列的数据库**与 **_宽列_（也称为 _列族_）**数据模型**混淆，在该模型中，一行可以有数千列，并且不需要所有行都有相同的列。
尽管名称相似，宽列数据库是面向行的，因为它们将一行中的所有值存储在一起。Google 的 Bigtable、Apache Accumulo 和 HBase 是宽列模型的例子。

##### 列存储中的排序顺序

在列存储中，行的存储顺序并不一定重要。最简单的是按插入顺序存储它们，因为这样插入新行只需追加到每列。独立排序每列是没有意义的

数据库管理员可以使用他们对常见查询的了解来选择表应按哪些列排序。

##### 写入列式存储

使用列式存储，在排序表的中间某处写入单个行将非常低效，因为你必须从插入位置开始重写所有压缩列。但是，一次批量写入许多行会分摊重写这些列的成本，使其高效。

通常使用日志结构方法以批次执行写入。所有写入首先进入面向行的、排序的内存存储。当积累了足够的写入时，它们将与磁盘上的列编码文件合并，并批量写入新文件。由于旧文件保持不可变，新文件一次写入，对象存储非常适合存储这些文件。

#### 查询执行：编译与向量化

用于分析的复杂 SQL 查询被分解为由多个阶段组成的 _查询计划_，称为 _算子_，这些算子可能分布在多台机器上以并行执行。
查询规划器可以通过选择使用哪些算子、以何种顺序执行它们以及在哪里运行每个算子来执行大量优化。

高效查询执行的两种替代方法已经出现：
- **查询编译**：查询引擎获取 SQL 查询并生成用于执行它的代码。代码逐行迭代，查看感兴趣列中的值，执行所需的任何比较或计算，如果满足所需条件，则将必要的值复制到输出缓冲区。查询引擎将生成的代码编译为机器代码（通常使用现有编译器，如 LLVM），然后在已加载到内存中的列编码数据上运行它。
- **向量化处理**：查询被解释，而不是编译，但通过批量处理列中的许多值而不是逐行迭代来提高速度。一组固定的预定义算子内置在数据库中；我们可以向它们传递参数并获得一批结果

两个位图之间的按位 AND 适合向量化。可以将 `product_sk` 列和&quot;香蕉&quot;的 ID 传递给相等算子，并获得一个位图（输入列中每个值一位，如果是香蕉则为 1）；然后我们可以将 `store_sk` 列和感兴趣商店的 ID 传递给相同的相等算子，并获得另一个位图；然后我们可以将两个位图传递给&quot;按位 AND&quot;算子，结果将是一个位图，包含特定商店中所有香蕉销售的 1。
![[file-20250816220235402.png]]

两者都可以通过利用现代 CPU 的特性来实现非常好的性能：
- 优先选择顺序内存访问而不是随机访问以减少缓存未命中
- 在紧密的内部循环中完成大部分工作（即，具有少量指令且没有函数调用）以保持 CPU 指令处理管道繁忙并避免分支预测错误
- 利用并行性，例如多线程和单指令多数据（SIMD）指令
- 直接对压缩数据进行操作，而无需将其解码为单独的内存表示

#### 物化视图与多维数据集

 **_物化视图_**：在关系数据模型中，它们是表状对象，其内容是某些查询的结果。**物化视图是查询结果的实际副本**，写入磁盘，而虚拟视图只是编写查询的快捷方式。当你从虚拟视图读取时，SQL 引擎会即时将其扩展为视图的基础查询，然后处理扩展的查询。

物化视图可以改善在重复需要执行相同查询的工作负载中的读取性能。

**_物化聚合_** 是一种可以在数据仓库中有用的物化视图类型。

_多维数据集_ 或 _OLAP 立方体_ 通过创建按不同维度分组的聚合网格来缓存查询最常使用的一些计数或总和。
![[file-20250816220810602.png]]
现在假设每个事实只有两个维度表的外键 —— 在图 中，这些是 `date_key` 和 `product_sk`。你现在可以绘制一个二维表，日期沿着一个轴，产品沿着另一个轴。每个单元格包含具有该日期-产品组合的所有事实的属性（例如 `net_price`）的聚合（例如 `SUM`）。然后，你可以沿着每行或列应用相同的聚合，并获得已减少一个维度的摘要（不管日期的产品销售，或不管产品的日期销售）。

物化多维数据集的优点是某些查询变得非常快，因为它们已经有效地预先计算了。例如，如果你想知道昨天每个商店的总销售额，你只需要查看适当维度的总计 —— 不需要扫描数百万行。

缺点是多维数据集没有与查询原始数据相同的灵活性。

大多数数据仓库尽可能多地保留原始数据，并仅将聚合（如多维数据集）用作某些查询的性能提升。

### 多维索引与全文索引

最常见的多列索引类型称为 **_联合索引_**，它通过将一列追加到另一列来将几个字段组合成一个键（索引定义指定字段以何种顺序连接）。**_多维索引_** 允许你一次查询多个列。在地理空间数据中这尤其重要。

#### 全文检索

**全文检索**：允许你通过可能出现在文本中任何位置的关键字搜索文本文档集合（网页、产品描述等）

可以将全文检索视为另一种多维查询：在这种情况下，可能出现在文本中的每个单词（_词项_）是一个维度。包含词项 _x_ 的文档在维度 _x_ 中的值为 1，不包含 _x_ 的文档的值为 0。

许多搜索引擎用来回答此类查询的数据结构称为 _倒排索引_。这是一个键值结构，其中键是词项，值是包含该词项的所有文档的 ID 列表（_倒排列表_）。如果文档 ID 是顺序数字，倒排列表也可以表示为稀疏位图。

Elasticsearch 和 Solr 使用的全文索引引擎 Lucene 就是这样工作的。它将词项到倒排列表的映射存储在类似 SSTable 的排序文件中，这些文件使用我们在本章前面看到的相同日志结构方法在后台合并

除了将文本分解为单词，另一种选择是查找长度为 _n_ 的所有子字符串，称为 _n_ 元语法。例如，字符串 `&quot;hello&quot;` 的三元语法（_n_ = 3）是 `&quot;hel&quot;`、`&quot;ell&quot;` 和 `&quot;llo&quot;`

为了处理文档或查询中的拼写错误，Lucene 能够在一定编辑距离内搜索文本中的单词（编辑距离为 1 意味着已添加、删除或替换了一个字母）.它通过将词项集存储为字符上的有限状态自动机（类似于 _字典树_ )并将其转换为 _莱文斯坦自动机_ 来实现，该自动机支持在给定编辑距离内高效搜索单词。

#### 向量嵌入

为了理解文档的语义 —— 它的含义 —— 语义搜索索引使用嵌入模型将文档转换为浮点值向量，称为 **_向量嵌入_**。向量表示多维空间中的一个点，每个浮点值表示文档沿着一个维度轴的位置。嵌入模型生成的向量嵌入在（这个多维空间中）彼此接近，当嵌入的输入文档在语义上相似时。

索引擎使用距离函数（如余弦相似度或欧几里得距离）来测量向量之间的距离。余弦相似度测量两个向量角度的余弦以确定它们的接近程度，而欧几里得距离测量空间中两点之间的直线距离。

许多早期的嵌入模型，如 Word2Vec、BERT 和 GPT 都处理文本数据。这些模型通常实现为神经网络。研究人员继续为视频、音频和图像创建嵌入模型。最近，模型架构已经变成 _多模态_ 的：单个模型可以为多种模态（如文本和图像）生成向量嵌入。

语义搜索引擎在用户输入查询时使用嵌入模型生成向量嵌入。用户的查询和相关上下文（例如用户的位置）被输入到嵌入模型中。嵌入模型生成查询的向量嵌入后，搜索引擎必须使用向量索引找到具有相似向量嵌入的文档。

向量索引存储文档集合的向量嵌入。要查询索引，你传入查询的向量嵌入，索引返回其向量最接近查询向量的文档。使用专门的向量索引，例如：
- **平面索引**：向量按原样存储在索引中。查询必须读取每个向量并测量其与查询向量的距离。平面索引是准确的，但测量查询与每个向量之间的距离很慢。
- **倒排文件（IVF）索引**：向量空间被聚类为向量的分区（称为 _质心_），以减少必须比较的向量数量。IVF 索引比平面索引更快，但只能给出近似结果：即使查询和文档彼此接近，它们也可能落入不同的分区。
- **分层可导航小世界**：HNSW 索引维护向量空间的多个层，每一层都表示为一个图，其中节点表示向量，边表示与附近向量的接近度。与 IVF 索引一样，HNSW 索引是近似的。
![[file-20250816223315450.png]]
## 5. 编码与演化
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
