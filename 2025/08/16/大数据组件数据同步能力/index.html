<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content=". 同步能力视图总览   组件 用途 是否涉及数据 是否容灾关键因素    yarn 资源管理 不涉及 非   zookeeper 协同管理 不涉及 非   kerberos 安全认证 不涉及 非   Ranger 权限认证 权限policy数据 是   Kafka 实时数据传输 主题分区数据 是   Loader 数据加载     Flume 日志采集     HDFS 文件管理 所有hadoo">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据组件数据同步能力">
<meta property="og:url" content="http://example.com/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%83%BD%E5%8A%9B/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content=". 同步能力视图总览   组件 用途 是否涉及数据 是否容灾关键因素    yarn 资源管理 不涉及 非   zookeeper 协同管理 不涉及 非   kerberos 安全认证 不涉及 非   Ranger 权限认证 权限policy数据 是   Kafka 实时数据传输 主题分区数据 是   Loader 数据加载     Flume 日志采集     HDFS 文件管理 所有hadoo">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-08-16T15:19:28.000Z">
<meta property="article:modified_time" content="2025-08-16T15:19:28.645Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%83%BD%E5%8A%9B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>大数据组件数据同步能力 | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BB%84%E4%BB%B6%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%83%BD%E5%8A%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大数据组件数据同步能力
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-08-16 23:19:28" itemprop="dateCreated datePublished" datetime="2025-08-16T23:19:28+08:00">2025-08-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>.</p>
<h3 id="同步能力视图总览"><a href="#同步能力视图总览" class="headerlink" title="同步能力视图总览"></a>同步能力视图总览</h3><table>
<thead>
<tr>
<th>组件</th>
<th>用途</th>
<th>是否涉及数据</th>
<th>是否容灾关键因素</th>
</tr>
</thead>
<tbody><tr>
<td>yarn</td>
<td>资源管理</td>
<td>不涉及</td>
<td>非</td>
</tr>
<tr>
<td>zookeeper</td>
<td>协同管理</td>
<td>不涉及</td>
<td>非</td>
</tr>
<tr>
<td>kerberos</td>
<td>安全认证</td>
<td>不涉及</td>
<td>非</td>
</tr>
<tr>
<td>Ranger</td>
<td>权限认证</td>
<td>权限policy数据</td>
<td>是</td>
</tr>
<tr>
<td>Kafka</td>
<td>实时数据传输</td>
<td>主题分区数据</td>
<td>是</td>
</tr>
<tr>
<td>Loader</td>
<td>数据加载</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Flume</td>
<td>日志采集</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDFS</td>
<td>文件管理</td>
<td>所有hadoop数据</td>
<td>是</td>
</tr>
<tr>
<td>hudi</td>
<td>湖格式</td>
<td>否（在HDFS层完成）</td>
<td>否</td>
</tr>
<tr>
<td>Alluxio</td>
<td>缓存数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>MemartsCC</td>
<td>缓存数据</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mapreduce</td>
<td>批量计算框架</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>Spark</td>
<td>批量数据加工</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>Flink</td>
<td>实时数据加工</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>Hive</td>
<td>HQL服务</td>
<td>元数据</td>
<td>是</td>
</tr>
<tr>
<td>Phoenix</td>
<td>HBase二级索引</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>HetuEngine</td>
<td>交互式分析</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>ElasticSearch</td>
<td>检索引擎</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>Clickhouse</td>
<td>实时数据接入实时查询</td>
<td>是</td>
<td>是</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>组件</th>
<th>同步工具</th>
<th>同步原理</th>
<th>时效性</th>
<th>是否支持异步</th>
<th>触发方式</th>
<th>一致性评估</th>
<th>适用场景</th>
<th>特性</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>DistCp</td>
<td>生成MapReduce任务传输数据</td>
<td>批量</td>
<td>是</td>
<td>一过性任务</td>
<td>最终一致性</td>
<td>HDFS—&gt;HDFS</td>
<td>文件拷贝，支持增全量拷贝</td>
</tr>
<tr>
<td>HBase</td>
<td>Replication</td>
<td>主备集群分别启动ReplicationSource、ReplicationSink线程进行数据传输</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>HBase—&gt;HBase</td>
<td>WAL拷贝，支持增全量拷贝</td>
</tr>
<tr>
<td>Kafka</td>
<td>MirrorMaker</td>
<td>从源集群中消费消息，然后将消息发送到目标集群中</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>Kafka—&gt;Kafka</td>
<td>消息传输</td>
</tr>
<tr>
<td>ElasticSearch</td>
<td>CCR</td>
<td>批量拉取主集群变更记录并行写入备集群,备集群拉取</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>ElasticSearch—&gt;ElasticSearch</td>
<td>变更索引拷贝</td>
</tr>
<tr>
<td>Hive</td>
<td>DistCp</td>
<td>hive数据表通过distcp同步，元数据通过dump或者数据库的同步能力完成</td>
<td>批量</td>
<td>是</td>
<td>一过性任务</td>
<td>最终一致性</td>
<td>Hive—&gt;Hive</td>
<td>数据库同步能力</td>
</tr>
<tr>
<td>Clickhouse</td>
<td>ReplicatedMergeTree</td>
<td>通过ReplicatedMergeTree引擎（Replicated 系列引擎）实现了副本机制</td>
<td>实时</td>
<td>是</td>
<td>配置开启，常驻任务</td>
<td>最终一致性</td>
<td>Clickhouse—&gt;Clickhouse</td>
<td>表副本机制</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="一、HDFS组件"><a href="#一、HDFS组件" class="headerlink" title="一、HDFS组件"></a>一、HDFS组件</h3><h4 id="DistCp-分布式拷贝"><a href="#DistCp-分布式拷贝" class="headerlink" title="DistCp 分布式拷贝"></a>DistCp 分布式拷贝</h4><h5 id="1、定义："><a href="#1、定义：" class="headerlink" title="1、定义："></a><strong>1、定义</strong>：</h5><p><strong>DistCp</strong>（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。 它使用Map&#x2F;Reduce实现文件分发，错误处理和恢复，以及报告生成。 它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝。 由于使用了Map&#x2F;Reduce方法，这个工具在语义和执行上都会有特殊的地方。<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html">^1</a></p>
<h5 id="2、同步原理："><a href="#2、同步原理：" class="headerlink" title="2、同步原理："></a><strong>2、同步原理</strong>：</h5><p>distcp 命令通过提交 mapreduce 程序在 map 阶段进⾏数据传输，基于 block 流读⼀次写⼀次⼤幅度提升拷贝速度。<a target="_blank" rel="noopener" href="https://yampery.github.io/2019/01/29/distcp/">^3</a><br>![[Pasted image 20250317185307.png]]</p>
<h5 id="3、适用场景："><a href="#3、适用场景：" class="headerlink" title="3、适用场景："></a><strong>3、适用场景</strong>：</h5><p>Hadoop集群之间，同步HDFS层的数据</p>
<h5 id="4、常用指令："><a href="#4、常用指令：" class="headerlink" title="4、常用指令："></a><strong>4、常用指令</strong>：</h5><p>（1） 集群间拷贝</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash$ hadoop distcp hdfs://nn1:8020/foo/bar hdfs://nn2:8020/bar/foo</span><br></pre></td></tr></table></figure>
<p>执行过程：这条命令会把nn1集群的&#x2F;foo&#x2F;bar目录下的所有文件或目录名展开并存储到一个临时文件中，这些文件内容的拷贝工作被分配给多个map任务， 然后每个TaskTracker分别执行从nn1到nn2的拷贝操作。注意DistCp使用绝对路径进行操作。<br>（2）指定多个原集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bash$ hadoop distcp hdfs://nn1:8020/foo/a \  </span><br><span class="line">                    hdfs://nn1:8020/foo/b \  </span><br><span class="line">                    hdfs://nn2:8020/bar/foo</span><br></pre></td></tr></table></figure>
<p>执行过程：指定需拷贝的多个源集群地址。注：当从多个源拷贝时，如果两个源冲突，DistCp会停止拷贝并提示出错信息， 如果在目的位置发生冲突，会根据<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html#options">选项设置</a>解决。</p>
<h5 id="5、可选参数"><a href="#5、可选参数" class="headerlink" title="5、可选参数"></a><strong>5、可选参数</strong></h5><table>
<thead>
<tr>
<th>标识</th>
<th>描述</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>-p[rbugp]</td>
<td>Preserve  <br>  r: replication<br>number  <br>  b: block size  <br>  u: user  <br>  g: group  <br>  p: permission</td>
<td>修改次数不会被保留。并且当指定 -update 时，更新的状态<strong>不</strong>会 被同步，除非文件大小不同（比如文件被重新创建）。</td>
</tr>
<tr>
<td>-i</td>
<td>忽略失败</td>
<td>这个选项会比默认情况提供关于拷贝的更精确的统计， 同时它还将保留失败拷贝操作的日志，这些日志信息可以用于调试。最后，如果一个map失败了，但并没完成所有分块任务的尝试，这不会导致整个作业的失败。</td>
</tr>
<tr>
<td>-log <logdir></td>
<td>记录日志到 <logdir></td>
<td>DistCp为每个文件的每次尝试拷贝操作都记录日志，并把日志作为map的输出。 如果一个map失败了，当重新执行时这个日志不会被保留。</td>
</tr>
<tr>
<td>-m <num_maps></td>
<td>同时拷贝的最大数目</td>
<td>指定了拷贝数据时map的数目。请注意并不是map数越多吞吐量越大。</td>
</tr>
<tr>
<td>-overwrite</td>
<td>覆盖目标</td>
<td>如果一个map失败并且没有使用-i选项，不仅仅那些拷贝失败的文件，这个分块任务中的所有文件都会被重新拷贝。 就像下面提到的，它会改变生成目标路径的语义，所以 用户要小心使用这个选项</td>
</tr>
<tr>
<td>-update</td>
<td>如果源和目标的大小不一样则进行覆盖</td>
<td>像之前提到的，这不是”同步”操作。 执行覆盖的唯一标准是源文件和目标文件大小是否相同；如果不同，则源文件替换目标文件。</td>
</tr>
<tr>
<td>-f <urilist_uri></td>
<td>使用<urilist_uri> 作为源文件列表</td>
<td>这等价于把所有文件名列在命令行中。 urilist_uri 列表应该是完整合法的URI。</td>
</tr>
</tbody></table>
<h5 id="6、附录"><a href="#6、附录" class="headerlink" title="6、附录"></a><strong>6、附录</strong></h5><p>（1）Map数目<br>DistCp会尝试着均分需要拷贝的内容，这样每个map拷贝差不多相等大小的内容。 但因为文件是最小的拷贝粒度，所以配置增加同时拷贝（如map）的数目不一定会增加实际同时拷贝的数目以及总吞吐量。<br>如果没使用-m选项，DistCp会尝试在调度工作时指定map的数目 为 min (total_bytes &#x2F; bytes.per.map, 20 * num_task_trackers)， 其中bytes.per.map默认是256MB。<br>建议对于长时间运行或定期运行的作业，根据源和目标集群大小、拷贝数量大小以及带宽调整map的数目。<br>（2）不同HDFS版本间的拷贝<br>对于不同Hadoop版本间的拷贝，用户应该使用HftpFileSystem。 这是一个只读文件系统，所以DistCp必须运行在目标端集群上（更确切的说是在能够写入目标集群的TaskTracker上）。<br>（3）Map&#x2F;Reduce和副效应<br>像前面提到的，map拷贝输入文件失败时，会带来一些副效应。</p>
<ul>
<li>除非使用了-i，任务产生的日志会被新的尝试替换掉。</li>
<li>除非使用了-overwrite，文件被之前的map成功拷贝后当又一次执行拷贝时会被标记为 “被忽略”。</li>
<li>如果map失败了mapred.map.max.attempts次，剩下的map任务会被终止（除非使用了-i)。</li>
<li>如果mapred.speculative.execution被设置为 final和true，则拷贝的结果是未定义的。</li>
</ul>
<hr>
<h3 id="二、HBase组件"><a href="#二、HBase组件" class="headerlink" title="二、HBase组件"></a>二、HBase组件</h3><h4 id="Replication-分布式拷贝"><a href="#Replication-分布式拷贝" class="headerlink" title="Replication 分布式拷贝"></a>Replication 分布式拷贝</h4><h5 id="1、定义：-1"><a href="#1、定义：-1" class="headerlink" title="1、定义："></a><strong>1、定义</strong>：</h5><p><strong>Replication</strong> (TM) 提供了一种在 HBase 部署之间复制数据的方法。它可以用作灾难恢复解决方案，并有助于在 HBase 层提供更高的可用性。它还可以提供更实际的功能；例如，作为一种将编辑内容从面向 Web 的集群轻松复制到“MapReduce”集群的方法，该集群将处理新旧数据并自动发回结果。<a target="_blank" rel="noopener" href="https://svn-master.apache.org/repos/asf/hbase/hbase.apache.org/trunk/0.94/replication.html">^2</a></p>
<h5 id="2、同步原理"><a href="#2、同步原理" class="headerlink" title="2、同步原理"></a><strong>2、同步原理</strong></h5><p>HBase 的复制方式是 master-push 方式，即主集群推的方式，主要是因为每个RegionServer都有自己的WAL。 一个master集群可以复制给多个从集群，复制是异步的，运行集群分布在不同的地方，这也意味着从集群和主集群的数据不是完全一致的，它的目标就是最终一致性。</p>
<p>每个RegionServer的 HLog 是 HBase 复制的基础，并且该日志复制时必须将其保存在 HDFS 中。每个 RegionServer 都会从需要复制的最旧的日志中读取，并在 ZooKeeper 中保存当前位置以简化故障恢复。该位置对于每个从属集群可能不同，对于要处理的 HLog 队列也一样。</p>
<p>参与复制的集群可以是不对称大小，主集群将尽“最大努力”通过随机化来平衡从属集群上的复制流。</p>
<p>从 0.92 版本开始，Apache HBase 支持主&#x2F;主和循环复制以及到多个从属的复制。</p>
<p>![[Pasted image 20250317110926.png]]</p>
<p>按照同步方式可以分类如下<a target="_blank" rel="noopener" href="https://www.cnblogs.com/caoweixiong/p/13606732.html">^4</a>：</p>
<p><strong>（1）异步Replication</strong><br>后台线程异步的读取WAL并复制到备集群，即做异步Replication，正常情况下备集群收到最新写入数据的延迟在<strong>秒</strong>级别。</p>
<ul>
<li><strong>主集群启动线程</strong>：主集群的每个RegionServer进程内部起了一个叫做ReplicationSource的线程来负责Replication</li>
<li><strong>备集群启动线程</strong>：的每个RegionServer内部起了一个ReplicationSink的线程来负责接收Replication数据</li>
<li><strong>确定同步内容</strong>ReplicationSource记录需要同步的WAL队列，然后不断读取WAL中的内容，同时可以根据Replication的配置做一些过滤，比如是否要复制这个表的数据等</li>
<li><strong>RPC调用</strong>：通过replicateWALEntry这个Rpc调用来发送给备集群的RegionServer，备集群的ReplicationSink线程则负责将收到的数据转换为put&#x2F;delete操作，以batch的形式写入到备集群中</li>
</ul>
<p><strong>（2）串行Replication（HBase 2.1引入）</strong><br>对于某个Region来说，严格按照主集群的写入顺序复制到备集群，其是一种特殊的Replication。</p>
<p>【注】当源集群发生Region move 或 RegionServer failure 时，在Region move或RegionServer failure之前未推送的HLog条目将由原始RegionServer（用于Region move）或另一个RegionServer（用于RegionServer failure）推送 ，并由现在服务于该区域的RS推送相同区域的新HLog条目，但它们在没有协调的情况下同时推送同一区域的 HLog 条目。<br>解决方案：确保移动后的Region Server写入操作必须在原Region Server的写入操作复制完成后再进行。</p>
<p><strong>（3）同步Replication</strong><br>异步Replication的最大问题在于复制是存在延迟的，所以在主集群整集群挂掉的情况下，备集群是没有已经写入的完整数据的，会丢失数据。</p>
<p>同步Replication的核心思路就是在写入主集群WAL的同时，在备集群上写入一份RemoteWAL，只有同时在主集群的WAL和备集群的RemoteWAL写入成功了，才会返回给Client说写入成功。</p>
<p>【注】同步Replication是在异步Replication的基础之上的，也就是说异步Replication的复制链路还会继续保留，同时增加了新的写Remote WAL的步骤。<br>![[Pasted image 20250317150012.png]]</p>
<p>对比异步复制来看，同步复制主要是影响的写路径，从我们的测试结果上来看，大概会有14%的性能下降，后续计划在HBase-20422中进行优化。</p>
<h5 id="3、适用场景：-1"><a href="#3、适用场景：-1" class="headerlink" title="3、适用场景："></a><strong>3、适用场景</strong>：</h5><p>HBase到HBase集群之间</p>
<h5 id="4、常用指令：-1"><a href="#4、常用指令：-1" class="headerlink" title="4、常用指令："></a><strong>4、常用指令</strong>：</h5><p>（1） 主集群添加复制关系</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_peer &#x27;100&#x27;, CLUSTER_KEY =&gt; &quot;172.16.10.60:2181:/hbase&quot;</span><br></pre></td></tr></table></figure>

<p>（2）建表，并对指定列簇开启Replication</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;tt&#x27;, &#123;NAME=&gt;&#x27;cf&#x27;, REPLICATION_SCOPE=&gt;&#x27;1&#x27;&#125;</span><br></pre></td></tr></table></figure>

<p>（3）备集群建表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create &#x27;tt&#x27;, &#123;NAME=&gt;&#x27;cf&#x27;&#125;     </span><br></pre></td></tr></table></figure>

<p>（4）通过HBase自带的VerifyReplication工具验证数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication -mappers 10 -bandwidth 1024 1 tt</span><br></pre></td></tr></table></figure>

<h5 id="5、可选参数-1"><a href="#5、可选参数-1" class="headerlink" title="5、可选参数"></a><strong>5、可选参数</strong></h5><table>
<thead>
<tr>
<th>参数</th>
<th>配置</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>zookeeper.znode.replication.rs</td>
<td>&#x2F;hyperbase1&#x2F;replication&#x2F;rs</td>
<td>包含主集群 RegionServers 列表 ( &#x2F;hbase&#x2F;replication&#x2F;rs&#x2F;<region server> )；对每个 RegionServer 节点，都有它要 Replication 数据过去的一个 Per Peer 子节点。<br>在 Peer 子节点内， Hlogs 等待被 Repication ，以这个路径表示: ( &#x2F;hbase&#x2F;replication&#x2F;rs&#x2F;<region server>&#x2F;<ClusterId>&#x2F;<hlogName> )</td>
</tr>
<tr>
<td>zookeeper.znode.replication.peers</td>
<td>&#x2F;hyperbase1&#x2F;replication&#x2F;peers</td>
<td>每个 Peer 有一个子节点(例如： &#x2F;hbase&#x2F;replication&#x2F;peers&#x2F;<ClusterID> )，包含能够连接到 peer 的 zookeeper 地址。 一个hbase 表可以同时replication到多个peer。</td>
</tr>
<tr>
<td>zookeeper.znode.replication</td>
<td>&#x2F;hyperbase1&#x2F;replication</td>
<td>包含 HBase replication state information 的根节点</td>
</tr>
<tr>
<td>zookeeper.znode.parent</td>
<td>&#x2F;hyperbase{num.}</td>
<td>Hyperbase在zookeeper上znode的名字</td>
</tr>
<tr>
<td>replication.sleep.before.failover</td>
<td>1</td>
<td>重新尝试同步已经死掉的 region server的WAL队列的时间，单位：ms</td>
</tr>
<tr>
<td>replication.executor.workers</td>
<td>1</td>
<td>每个 region server 应尝试同时进行故障切换的 region server 的数量</td>
</tr>
</tbody></table>
<h5 id="6、附录-1"><a href="#6、附录-1" class="headerlink" title="6、附录"></a><strong>6、附录</strong></h5><p>（1）replication不会根据实际插入的顺序来进行，只保证和master集群最终一致性。<br>（2）主集群对于同步的数据大小和个数采用默认值较大，容易导致备集群内存被压垮。建议配置减少每次同步数据的大小。replication.source.size.capacity4194304&#x2F;replication.source.nb.capacity2000<br>（3）HBase集群间复制时一般通过 CopyTable + Replication共同实现。</p>
<hr>
<h3 id="三、Kafka组件"><a href="#三、Kafka组件" class="headerlink" title="三、Kafka组件"></a>三、Kafka组件</h3><h4 id="MirrorMaker"><a href="#MirrorMaker" class="headerlink" title="MirrorMaker"></a>MirrorMaker</h4><h5 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h5><p><strong>MirrorMaker</strong> ：Apache Kafka中的一个工具，用于在不同的Kafka集群之间进行数据复制和数据同步。它可以将一个Kafka集群中的主题（topic）的数据复制到另一个Kafka集群中的相应主题，从而实现数据的跨集群复制。</p>
<p>MirrorMaker最初是由LinkedIn开发的，作为其内部使用的数据复制工具。LinkedIn是一个职业社交网络平台，使用Kafka作为其核心的消息传递系统。为了实现数据的跨集群复制和数据同步，LinkedIn团队开发了MirrorMaker。<br>MirrorMaker于2012年首次发布，作为LinkedIn的开源项目，成为Apache Kafka的一部分。随着Kafka的快速发展和广泛应用，MirrorMaker也逐渐得到了更多社区的关注和贡献。<br>随着时间的推移，MirrorMaker经历了多个版本的更新和改进。在不同的Kafka版本中，MirrorMaker的功能和性能都得到了不断优化和增强。社区也提供了丰富的文档和示例，以帮助用户更好地理解和使用MirrorMaker。<br>MirrorMaker的历史可以追溯到Kafka的早期发展阶段，它在Kafka生态系统中扮演着重要的角色，为用户提供了可靠的数据复制解决方案。随着时间的推移，MirrorMaker在Kafka社区中得到了广泛的认可和应用，并成为了许多企业在构建分布式数据处理系统中的重要组成部分。<a target="_blank" rel="noopener" href="https://www.ctyun.cn/developer/article/442989040070725">^5</a></p>
<h5 id="2、原理"><a href="#2、原理" class="headerlink" title="2、原理"></a>2、原理</h5><p>（1）配置源集群和目标集群：首先，你需要配置源集群和目标集群的连接信息，包括Kafka集群的地址、主题名称等。MirrorMaker需要同时连接到源集群和目标集群。<br>（2）配置源集群和目标集群：首先，你需要配置源集群和目标集群的连接信息，包括Kafka集群的地址、主题名称等。MirrorMaker需要同时连接到源集群和目标集群。<br>创建消费者和生产者：MirrorMaker会创建一个或多个消费者，从源集群中读取消息。每个消费者会订阅一个或多个源集群的主题。同时，MirrorMaker也会创建一个或多个生产者，将消息写入目标集群的相应主题。<br>（3）复制消息：MirrorMaker的消费者会从源集群中读取消息，并将其转发给生产者，生产者将消息写入目标集群。复制过程是异步进行的，即源集群中的数据变化会延迟一段时间后才会在目标集群中出现。<br>（4）容错和故障处理：MirrorMaker具有一定的容错机制，当源集群或目标集群出现故障或不可用时，它会尽力保证数据的复制和同步。如果源集群的某个分区不可用，MirrorMaker会尝试从其他可用的分区读取消息。如果目标集群的某个分区不可用，MirrorMaker会重试写入操作，直到成功为止。<br>（5）配置选项：MirrorMaker提供了丰富的配置选项，可以根据需要进行配置。你可以选择复制全部主题或只复制特定的主题，还可以配置复制的速率和数据过滤等。</p>
<p>总之，MirrorMaker通过消费者和生产者的组合，实现了从源集群到目标集群的数据复制和同步。它可以在不同版本的Kafka集群之间进行数据复制，并提供了灵活的配置选项和容错机制，以保证数据的可用性和一致性。</p>
<p>![[Pasted image 20250317185721.jpg]]</p>
<h5 id="3、适用场景"><a href="#3、适用场景" class="headerlink" title="3、适用场景"></a><strong>3、适用场景</strong></h5><p>Kafka集群到Kafka集群</p>
<ul>
<li><p>灾难恢复与冗余：如果你有一个重要的Kafka集群运行在一个数据中心，并且你希望为其创建一个备份，可以使用MirrorMaker将数据复制到另一个位于不同数据中心的Kafka集群。这样，如果主数据中心发生故障，你可以立即切换到备份数据中心，确保业务的连续性。</p>
</li>
<li><p>数据聚合：如果你有多个位于不同地区或部门的Kafka集群，每个集群都在生产重要的数据，你可能希望在一个中心位置进行数据聚合和分析。在这种情况下，可以使用MirrorMaker将所有的Kafka集群的数据复制到一个中心集群。</p>
</li>
<li><p>跨地域应用：如果你的应用需要在多个地域部署，并需要访问到相同的数据流，那么可以使用MirrorMaker在各个地域之间复制数据。</p>
</li>
<li><p>数据管道和ETL：可以在源Kafka集群中创建生产者应用，将数据送入管道，然后在目的地Kafka集群中创建消费者应用，对数据进行处理和存储。MirrorMaker可以在这两个集群之间提供数据流。</p>
</li>
</ul>
<h5 id="4、常用指令：-2"><a href="#4、常用指令：-2" class="headerlink" title="4、常用指令："></a><strong>4、常用指令</strong>：</h5><p>（1）官方提供的MirrorMaker脚本，用于启动MirrorMaker进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-mirror-maker.sh --consumer.config consumer.properties --producer.config producer.properties --whitelist=&quot;^topic.*&quot;</span><br></pre></td></tr></table></figure>

<h5 id="5、参数说明"><a href="#5、参数说明" class="headerlink" title="5、参数说明"></a>5、参数说明</h5><table>
<thead>
<tr>
<th>参数名</th>
<th>参数含义</th>
</tr>
</thead>
<tbody><tr>
<td>whitelist</td>
<td>指定一个正则表达式，指定拷贝源集群中的哪些topic。比如 a|b 表示拷贝源集群上连个topic的数据a和b。注意，当使用新版本consumer时必须指定该参数。为了方便使用，可以将|替换为,</td>
</tr>
<tr>
<td>blacklist</td>
<td>指定一个正则表达式，屏蔽指定topic的拷贝。注意，该参数只使用于老版本consumer</td>
</tr>
<tr>
<td>abort.on.send.failure</td>
<td>若设置为true，当发送失败时则关闭MirrorMaker</td>
</tr>
<tr>
<td>consumer.config</td>
<td>指定MirrorMaker下consumer的属性文件。至少指定bootstrap.server和group.id</td>
</tr>
<tr>
<td>producer.config</td>
<td>指定MirrorMaker下producer的属性文件</td>
</tr>
<tr>
<td>consumer.rebalance.listener</td>
<td>指定MirrorMaker使用的consumer rebalance监听器</td>
</tr>
<tr>
<td>rebalance.listener.args</td>
<td>指定MirrorMaker使用的consumer rebalance监听器的参数，与consumer.rebalance.listener一同使用</td>
</tr>
<tr>
<td>message.handler</td>
<td>指定消息处理器类。消息处理器在consumer获取消息与producer发送消息之间调用</td>
</tr>
<tr>
<td>message.handler.args</td>
<td>指定消息处理器类的参数，与message.handler一同使用</td>
</tr>
<tr>
<td>num.streams</td>
<td>指定MirrorMaker线程数。默认是1</td>
</tr>
<tr>
<td>offset.conmmit.interval.ms</td>
<td>指定MirrorMaker位移提交间隔，默认值为1分钟<br>help	打印帮助信息</td>
</tr>
</tbody></table>
<hr>
<h3 id="四、ElasticSearch组件"><a href="#四、ElasticSearch组件" class="headerlink" title="四、ElasticSearch组件"></a>四、ElasticSearch组件</h3><h4 id="CCR"><a href="#CCR" class="headerlink" title="CCR"></a>CCR</h4><h5 id="1、定义-1"><a href="#1、定义-1" class="headerlink" title="1、定义"></a>1、定义</h5><p> CCR（Cross-Cluster Replication），是Elasticsearch 6.7 版本中引入跨集群复制功能，支持将指定的索引从一个 Elasticsearch 集群复制到一个或多个 Elasticsearch 集群。跨集群复制属于 Elastic Stack 的白金版（PLATINUM）付费功能，需要额外付费才可以使用。<a target="_blank" rel="noopener" href="https://www.infvie.com/ops-notes/elasticsearch-multiple-cross-machine-rooms.html">^6</a></p>
<h5 id="2、原理-1"><a href="#2、原理-1" class="headerlink" title="2、原理"></a>2、原理</h5><p>跨集群复制使用主动-被动模型（active-passive model），复制更改的索引称为“追随者索引”（follower Index），被复制的索引称为“领导者索引”（leader index）。当 leader index 收到写入时，follower index 会从远程集群上的 leader index 上基于文档操作实现订阅复制。当配置复制规则时，可以指定特定的索引进行复制；也可以通过 auto-follow pattern 以通配符的形式自动匹配多个索引，创建复制规则后新创建的索引也会自动匹配。</p>
<p>![[Pasted image 20250318142248.png]]</p>
<p>follower index 是被动的，它可以服务于读取请求，但不能接受写入请求，只有 leader index 可以接受写入请求。</p>
<p>复制过程主要分为两个阶段(对应ES写入的两个阶段，复制落地到磁盘的segment和复制写入缓存区还未落地到磁盘的数据)</p>
<ul>
<li>Step1–复制远程leader集群的<strong>segment</strong>到 本地 follower集群</li>
</ul>
<p>![[Pasted image 20250318152607.png]]</p>
<ul>
<li>Step2–复制远程leader集群的 <strong>operator records</strong> (存在内存缓冲区和translog )到 本地follower集群。<br>![[Pasted image 20250318152627.png]]<br>💢当主集群发生宕机时，如果我们想让在备集群中的 follower index 接管服务，允许进行写入请求，需要依次暂停索引的复制，关闭索引，取消跟随 leader index，最后将其重新打开为普通的索引，整套操作下来非常复杂，而且无法进行回切，这也是 CCR 跨集群复制最大的一个问题。<br>![[Pasted image 20250318144030.png]]</li>
</ul>
<p>针对上述问题，这里也提供了一种解决方案，那就是双向复制（CCR bi-directional replication）。如下图所示，我们可以在集群 cluster01 上创建索引 <code>logs-cluster01</code>，并在集群 cluster02 上复制该索引；在集群 cluster02 上创建索引 <code>logs-cluster02</code> ，并在集群 cluster01 上复制该索引。然后在两个集群上创建别名 <code>logs</code>  指向索引 <code>logs-cluster01</code> 和 <code>logs-cluster02</code>，对外可以提供统一的索引名。别名指向的多个索引中，只能有一个索引是允许接收写入请求的，在 cluster01 将索引 <code>logs-cluster01</code> 设置为可写，<code>logs-cluster02</code> 索引中的数据将会通过 CCR 跨集群复制从集群 cluster02 中获取；集群 cluster02 的别名设置相反。通过以上设置，应用程序在读写的时候都往 <code>logs</code>  别名发送请求，假设当集群 cluster01 不可用时，我们可以继续使用集群 cluster02，并且依然是往 <code>logs</code> 别名发送请求，无需手动进行切换操作；当集群 cluster01 恢复后，会从上次记录的 checkpoint 继续从集群 cluster02 复制数据，也无需额外的切换操作。</p>
<h5 id="3、适用场景-1"><a href="#3、适用场景-1" class="headerlink" title="3、适用场景"></a>3、适用场景</h5><p>ElasticSearch实时同步至ElasticSearch</p>
<ul>
<li><strong>灾难恢复（DR）&#x2F;高可用性（HA）</strong>：如果主群集发生故障，则进行灾难恢复。 辅助群集可以用作热备份</li>
<li><strong>地理位置优先</strong>：在 Elasticsearch 中复制数据以更接近用户或应用程序服务器，从而减少延迟。优先就近读取数据，提升性能</li>
<li><strong>集中报告</strong>：将数据从大量较小的集群复制回一个中央集群进行报告<a target="_blank" rel="noopener" href="https://www.cnblogs.com/tgzhu/p/17090475.html">^7</a></li>
</ul>
<h5 id="4、常用指令：-3"><a href="#4、常用指令：-3" class="headerlink" title="4、常用指令："></a>4、常用指令：</h5><p>（1）开启CCR，Elasticsearch 7.0+ 之后版本已默认开启，无需单独配置。</p>
<p>（2）连接到远程集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PUT /_cluster/settings  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;persistent&quot; : &#123;  </span><br><span class="line">    &quot;cluster&quot; : &#123;  </span><br><span class="line">      &quot;remote&quot; : &#123;  </span><br><span class="line">        &quot;es01&quot; : &#123;  </span><br><span class="line">          &quot;seeds&quot; : [  </span><br><span class="line">            &quot;es01:9300&quot;   </span><br><span class="line">          ]  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）创建Follower index</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT /index-1-follower/_ccr/follow?wait_for_active_shards=1  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;remote_cluster&quot; : &quot;es01&quot;,  </span><br><span class="line">  &quot;leader_index&quot; : &quot;index-1&quot;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">_# 返回结果_  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;follow_index_created&quot; : true,  </span><br><span class="line">  &quot;follow_index_shards_acked&quot; : true,  </span><br><span class="line">  &quot;index_following_started&quot; : true  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="5、参数说明-1"><a href="#5、参数说明-1" class="headerlink" title="5、参数说明"></a>5、参数说明</h5><table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>ccr.indices.recovery.max_bytes_per_sec</td>
<td>限制每个节点上的总入站和总出站的远程流量(速度)。(默认值是40mb)，当主集群和从集群都设置这个值后，先达到限制值的先其作用。即如果主集群设置20mb，从集群设置60mb，那么主集群也只会想从集群发送20mb。</td>
</tr>
<tr>
<td>ccr.indices.recovery.max_concurrent_file_chunks</td>
<td>复制文件的并行度，即可以同时复制接个文件，默认值是5，最大值为10.</td>
</tr>
<tr>
<td>ccr.indices.recovery.chunk_size</td>
<td>复制文件一次请求的最大限制，默认值是1mb</td>
</tr>
<tr>
<td>ccr.indices.recovery.recovery_activity_timeout</td>
<td>leader等待follower恢复请求的时间，默认值是60s</td>
</tr>
<tr>
<td>ccr.indices.recovery.internal_action_timeout</td>
<td>在远程恢复过程中单个网络请求的超时值，默认值是60s</td>
</tr>
</tbody></table>
<h5 id="6、附录-2"><a href="#6、附录-2" class="headerlink" title="6、附录"></a>6、附录</h5><ul>
<li>​<strong>分片数量与线程数关系</strong>：分片数量直接影响并行复制的线程数，需合理规划分片数以避免资源争用。</li>
<li>​<strong>版本兼容性</strong>：需确保 leader 和 follower 集群的 Elasticsearch 版本兼容，否则可能引发线程池调度异常</li>
<li>​<strong>网络带宽</strong>：多线程可能加剧跨集群网络负载，需监控带宽使用情况。</li>
</ul>
<h3 id="五、Hive组件"><a href="#五、Hive组件" class="headerlink" title="五、Hive组件"></a>五、Hive组件</h3><p>hive的数据包含两部分，一部分是hive数据表，可以通过distcp同步，另一部分是元数据，可通过dump方式生成文件，再通过distcp同步，或者基于元数据的数据库能力进行同步均可，不再介绍</p>
<h3 id="六、Clickhouse组件"><a href="#六、Clickhouse组件" class="headerlink" title="六、Clickhouse组件"></a>六、Clickhouse组件</h3><h4 id="ReplicatedMergeTree引擎"><a href="#ReplicatedMergeTree引擎" class="headerlink" title="ReplicatedMergeTree引擎"></a>ReplicatedMergeTree引擎</h4><h5 id="1、定义-2"><a href="#1、定义-2" class="headerlink" title="1、定义"></a>1、定义</h5><p> ClickHouse 采用 Multi - Master 的多主架构，集群中的每个节点角色对等，客户端访问任意一个节点都能达到相同的结果。这种多主架构有许多优势，例如对等的角色使系统架构变的更加简单，不再区分主控节点、数据节点和计算节点，集群中所有节点的功能相同。正因如此，ClickHouse 天然规避了单点故障的问题，非常适用于多数据中心、异地多活等场景。<a target="_blank" rel="noopener" href="https://www.dbkuaizi.com/archives/207.html">^8</a></p>
<p>ClickHouse利用ZooKeeper，通过ReplicatedMergeTree引擎（Replicated 系列引擎）实现了副本机制。副本机制是多主架构，可以将INSERT语句发送给任意一个副本，其余副本会进行数据的异步复制。</p>
<h5 id="2、原理-2"><a href="#2、原理-2" class="headerlink" title="2、原理"></a>2、原理</h5><p>副本机制功能：</p>
<ul>
<li>ClickHouse副本机制的设计可以最大限度的减少网络数据传输，用以在不同的数据中心进行同步，可以用来建设多数据中心、异地多活的集群架构。</li>
<li>副本机制是实现：高可用（HA）、负载均衡（Load Balance）、迁移&#x2F;升级（Migration&#x2F;Upgrade）功能的基础。</li>
<li>高可用：系统会监视副本数据的同步情况，识别故障节点，并在节点恢复正常时进行故障恢复，保证服务整体高可用。<br>![[Pasted image 20250318183444.png]]<br>ReplicateMergeTree可以通过和zk结合，把数据同步到对应的副本节点中，而且同步是相互的，也就是说从A节点写入的数据会同步到B节点，从B节点写入的数据也会写入到A节点中，典型的Mul-Master架构。通过一个分片多个副本的形式可以分摊读和写的负载，我们看一下同步的原理：</li>
</ul>
<p>（1）insert数据：假设A节点进行数据插入，首先A节点本地会创建一个新的目录分区，然后他会把这个分区目录的信息推送到zk的log目录节点下，目的是为了通知B节点来获取该分区的数据，B节点会监听zk的log节点的变更通知，让得知是要去A节点同步数据分区数据时，他首先先把这个消息发送到他对应的zk上面的任务执行队列，B本身会按照zk上面的执行队列的顺序顺序执行各个操作，自然当获取到是要去A同步数据分区数据时，他会和A节点建立数据连接，希望从A那里下载到该分区数据，等到A返回对应的分区数据时，B会在本地创建一个名称一模一样的目录分区数据,自此insert的数据完成了同步。<br>![[Pasted image 20250318184230.png]]<br>Insert数据插入操作时多个副本之间是有存在副本一致性问题的，也就是同步期间副本0和副本1的数据是不一致的，所以对于使用multi-master进行写多个副本的操作时，需要意识到在一定的时间内多个副本之间的数据是不一致的，所以选择这种方案需要考虑到数据不一致的问题</p>
<p>b. merge合并数据: 这个操作需要从A和B中通过zk选举出主节点，假设A是主节点，B是副节点，当B执行optimize table操作合并数据分区时，B首先和主节点A直接建立连接，告诉A主副本负责制定merge合并计划，当A收到B的制定merge计划的请求后，A制定了merge计划，比如把2020_0_0_0和2020_2_2_1合并成2020_0_2_2，他会把这个执行计划推送到zk的log节点中，这样A和B监听到zk的log节点执行计划后会分别把这个执行计划推送到各自在zk上的queue任务队列中，然后A和B各自执行各自的任务队列操作时，就会各自按照执行计划merge各自的分区<br>![[Pasted image 20250318184300.png]]<br>c. update&#x2F;delete数据：假设A节点进行数据删除操作Alter table XX delete id&#x3D;100，首先A节点会把这个操作组合成一个消息（包含mutationid）发送到zk中，此后节点A和B会监听zk中的mutation节点的变更，假设此时B节点是主节点，所以B节点会响应这个数据变更的消息并指定具体的数据更新计划，比如目录文件从202209_0_0_1在进行了delete具体操作后变成202209_0_0_1_mutationid,然后B节点会发送这个具体的数据更新消息到zk中，此时A和B节点会同时监听到具体的数据变更消息，然后在各自的本地磁盘中进行数据的修改&#x2F;删除操作,自此update&#x2F;delete的数据完成了同步。<br>![[Pasted image 20250318184309.png]]<br>update&#x2F;delete数据修改操作时多个副本之间是有存在副本一致性问题的，也就是同步期间副本0和副本1的数据是不一致的，所以对于使用multi-master进行修改删除多个副本的操作时，需要意识到在一定的时间内多个副本之间的数据是不一致的，所以选择这种方案需要考虑到数据不一致的问题</p>
<p>整个执行过程中zk只是作为消息通知的手段，clickhouse表数据的传输并没有通过zk进行，zk的压力其实不大，此外，对于ReplicateMergeTree表的查询操作并不需要zk的参与。</p>
<h5 id="3、适用场景-2"><a href="#3、适用场景-2" class="headerlink" title="3、适用场景"></a>3、适用场景</h5><p>Clickhouse多主架构</p>
<h5 id="4、常用指令-9"><a href="#4、常用指令-9" class="headerlink" title="4、常用指令^9"></a>4、常用指令<a target="_blank" rel="noopener" href="https://blog.csdn.net/nazeniwaresakini/article/details/105858390">^9</a></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS test.events_local ON CLUSTER &#x27;&#123;cluster&#125;&#x27; (</span><br><span class="line">  ts_date Date,</span><br><span class="line">  ts_date_time DateTime,</span><br><span class="line">  uzser_id Int64,</span><br><span class="line">  event_type String,</span><br><span class="line">  site_id Int64,</span><br><span class="line">  groupon_id Int64,</span><br><span class="line">  category_id Int64,</span><br><span class="line">  merchandise_id Int64,</span><br><span class="line">  search_text String</span><br><span class="line">  -- A lot more columns...</span><br><span class="line">)</span><br><span class="line">ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/&#123;shard&#125;/test/events_local&#x27;,&#x27;&#123;replica&#125;&#x27;)</span><br><span class="line">PARTITION BY ts_date</span><br><span class="line">ORDER BY (ts_date,toStartOfHour(ts_date_time),site_id,event_type)</span><br><span class="line">SETTINGS index_granularity = 8192;</span><br></pre></td></tr></table></figure>

<h5 id="5、参数说明-2"><a href="#5、参数说明-2" class="headerlink" title="5、参数说明"></a>5、参数说明</h5><table>
<thead>
<tr>
<th>参数</th>
<th>介绍</th>
</tr>
</thead>
<tbody><tr>
<td><code>zoo_path</code></td>
<td>ZooKeeper 路径。相同的 ZooKeeper 路径对应于相同的数据库。</td>
</tr>
<tr>
<td><code>shard_name</code></td>
<td>分片名称。数据库副本按 <code>shard_name</code> 分组到分片中。</td>
</tr>
<tr>
<td><code>replica_name</code></td>
<td>副本名称。相同分片的所有副本名称必须不同。</td>
</tr>
<tr>
<td>对于<a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/replication">ReplicatedMergeTree</a>表，如果没有提供参数，则使用默认参数：<code>/clickhouse/tables/&#123;uuid&#125;/&#123;shard&#125;</code>和<code>&#123;replica&#125;</code>。这些可以在服务器设置中更改 <a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/operations/server-configuration-parameters/settings#default_replica_path">default_replica_path</a> 和 <a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/operations/server-configuration-parameters/settings#default_replica_name">default_replica_name</a>。宏 <code>&#123;uuid&#125;</code> 被展开为表的 uuid，<code>&#123;shard&#125;</code> 和<code>&#123;replica&#125;</code> 被展开为来自服务器配置的值，而不是数据库引擎参数中的值。但在将来，可以使用副本数据库的 <code>shard_name</code> 和 <code>replica_name</code>。<a target="_blank" rel="noopener" href="https://clickhouse.com/docs/zh/engines/database-engines/replicated">^10</a></td>
<td></td>
</tr>
</tbody></table>
<h5 id="6、附录-3"><a href="#6、附录-3" class="headerlink" title="6、附录"></a>6、附录</h5><ul>
<li>ClickHouse容灾保护的范围是基于复制表创建的分布式表和物化视图，即对分布式表、物化视图及相关的复制表可以完成容灾保护同步数据到容灾集群。</li>
<li>![[计算机基础&#x2F;assets&#x2F;大数据组件数据同步能力&#x2F;1751852687392.png|assets&#x2F;大数据组件数据同步能力&#x2F;1751852687392.png]]</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/08/16/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90Kubernetes/" rel="prev" title="深入剖析Kubernetes">
      <i class="fa fa-chevron-left"></i> 深入剖析Kubernetes
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/08/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E7%9F%A5%E5%BD%95/" rel="next" title="大数据日知录">
      大数据日知录 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E8%83%BD%E5%8A%9B%E8%A7%86%E5%9B%BE%E6%80%BB%E8%A7%88"><span class="nav-number">1.</span> <span class="nav-text">同步能力视图总览</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81HDFS%E7%BB%84%E4%BB%B6"><span class="nav-number">2.</span> <span class="nav-text">一、HDFS组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DistCp-%E5%88%86%E5%B8%83%E5%BC%8F%E6%8B%B7%E8%B4%9D"><span class="nav-number">2.1.</span> <span class="nav-text">DistCp 分布式拷贝</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1%E3%80%81%E5%AE%9A%E4%B9%89%EF%BC%9A"><span class="nav-number">2.1.1.</span> <span class="nav-text">1、定义：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2%E3%80%81%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86%EF%BC%9A"><span class="nav-number">2.1.2.</span> <span class="nav-text">2、同步原理：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3%E3%80%81%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9A"><span class="nav-number">2.1.3.</span> <span class="nav-text">3、适用场景：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4%E3%80%81%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%EF%BC%9A"><span class="nav-number">2.1.4.</span> <span class="nav-text">4、常用指令：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5%E3%80%81%E5%8F%AF%E9%80%89%E5%8F%82%E6%95%B0"><span class="nav-number">2.1.5.</span> <span class="nav-text">5、可选参数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6%E3%80%81%E9%99%84%E5%BD%95"><span class="nav-number">2.1.6.</span> <span class="nav-text">6、附录</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81HBase%E7%BB%84%E4%BB%B6"><span class="nav-number">3.</span> <span class="nav-text">二、HBase组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Replication-%E5%88%86%E5%B8%83%E5%BC%8F%E6%8B%B7%E8%B4%9D"><span class="nav-number">3.1.</span> <span class="nav-text">Replication 分布式拷贝</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1%E3%80%81%E5%AE%9A%E4%B9%89%EF%BC%9A-1"><span class="nav-number">3.1.1.</span> <span class="nav-text">1、定义：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2%E3%80%81%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86"><span class="nav-number">3.1.2.</span> <span class="nav-text">2、同步原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3%E3%80%81%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9A-1"><span class="nav-number">3.1.3.</span> <span class="nav-text">3、适用场景：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4%E3%80%81%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%EF%BC%9A-1"><span class="nav-number">3.1.4.</span> <span class="nav-text">4、常用指令：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5%E3%80%81%E5%8F%AF%E9%80%89%E5%8F%82%E6%95%B0-1"><span class="nav-number">3.1.5.</span> <span class="nav-text">5、可选参数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6%E3%80%81%E9%99%84%E5%BD%95-1"><span class="nav-number">3.1.6.</span> <span class="nav-text">6、附录</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81Kafka%E7%BB%84%E4%BB%B6"><span class="nav-number">4.</span> <span class="nav-text">三、Kafka组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MirrorMaker"><span class="nav-number">4.1.</span> <span class="nav-text">MirrorMaker</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1%E3%80%81%E5%AE%9A%E4%B9%89"><span class="nav-number">4.1.1.</span> <span class="nav-text">1、定义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2%E3%80%81%E5%8E%9F%E7%90%86"><span class="nav-number">4.1.2.</span> <span class="nav-text">2、原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3%E3%80%81%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">4.1.3.</span> <span class="nav-text">3、适用场景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4%E3%80%81%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%EF%BC%9A-2"><span class="nav-number">4.1.4.</span> <span class="nav-text">4、常用指令：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5%E3%80%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E"><span class="nav-number">4.1.5.</span> <span class="nav-text">5、参数说明</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81ElasticSearch%E7%BB%84%E4%BB%B6"><span class="nav-number">5.</span> <span class="nav-text">四、ElasticSearch组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CCR"><span class="nav-number">5.1.</span> <span class="nav-text">CCR</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1%E3%80%81%E5%AE%9A%E4%B9%89-1"><span class="nav-number">5.1.1.</span> <span class="nav-text">1、定义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2%E3%80%81%E5%8E%9F%E7%90%86-1"><span class="nav-number">5.1.2.</span> <span class="nav-text">2、原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3%E3%80%81%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF-1"><span class="nav-number">5.1.3.</span> <span class="nav-text">3、适用场景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4%E3%80%81%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%EF%BC%9A-3"><span class="nav-number">5.1.4.</span> <span class="nav-text">4、常用指令：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5%E3%80%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E-1"><span class="nav-number">5.1.5.</span> <span class="nav-text">5、参数说明</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6%E3%80%81%E9%99%84%E5%BD%95-2"><span class="nav-number">5.1.6.</span> <span class="nav-text">6、附录</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94%E3%80%81Hive%E7%BB%84%E4%BB%B6"><span class="nav-number">6.</span> <span class="nav-text">五、Hive组件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AD%E3%80%81Clickhouse%E7%BB%84%E4%BB%B6"><span class="nav-number">7.</span> <span class="nav-text">六、Clickhouse组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReplicatedMergeTree%E5%BC%95%E6%93%8E"><span class="nav-number">7.1.</span> <span class="nav-text">ReplicatedMergeTree引擎</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1%E3%80%81%E5%AE%9A%E4%B9%89-2"><span class="nav-number">7.1.1.</span> <span class="nav-text">1、定义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2%E3%80%81%E5%8E%9F%E7%90%86-2"><span class="nav-number">7.1.2.</span> <span class="nav-text">2、原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3%E3%80%81%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF-2"><span class="nav-number">7.1.3.</span> <span class="nav-text">3、适用场景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4%E3%80%81%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-9"><span class="nav-number">7.1.4.</span> <span class="nav-text">4、常用指令^9</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5%E3%80%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E-2"><span class="nav-number">7.1.5.</span> <span class="nav-text">5、参数说明</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6%E3%80%81%E9%99%84%E5%BD%95-3"><span class="nav-number">7.1.6.</span> <span class="nav-text">6、附录</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
